{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/2104.12259.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26811d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "vers = torch.__version__\n",
    "print(\"Torch vers: \", vers)\n",
    "\n",
    "# PyG installation\n",
    "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html\n",
    "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html\n",
    "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git\n",
    "\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import UPFD\n",
    "train_data = UPFD(root=\"/content/drive/MyDrive/Colab Notebooks/FakeNews/\", name=\"gossipcop\", feature=\"bert\", split=\"train\")\n",
    "test_data = UPFD(root=\"/content/drive/MyDrive/Colab Notebooks/FakeNews/\", name=\"gossipcop\", feature=\"bert\", split=\"test\")\n",
    "print(\"Train Samples: \", len(train_data))\n",
    "print(\"Test Samples: \", len(test_data))\n",
    "# feature=\"content\" --> Spacy Word2Vec + Profile features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Propogation Graph\n",
    "sample_id=1\n",
    "train_data[sample_id].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083781dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# From PyG utils\n",
    "def to_networkx(data, node_attrs=None, edge_attrs=None, to_undirected=False,\n",
    "                remove_self_loops=False):\n",
    "    if to_undirected:\n",
    "        G = nx.Graph()\n",
    "    else:\n",
    "        G = nx.DiGraph()\n",
    "    G.add_nodes_from(range(data.num_nodes))\n",
    "    node_attrs, edge_attrs = node_attrs or [], edge_attrs or []\n",
    "    values = {}\n",
    "    for key, item in data(*(node_attrs + edge_attrs)):\n",
    "        if torch.is_tensor(item):\n",
    "            values[key] = item.squeeze().tolist()\n",
    "        else:\n",
    "            values[key] = item\n",
    "        if isinstance(values[key], (list, tuple)) and len(values[key]) == 1:\n",
    "            values[key] = item[0]\n",
    "    for i, (u, v) in enumerate(data.edge_index.t().tolist()):\n",
    "        if to_undirected and v > u:\n",
    "            continue\n",
    "        if remove_self_loops and u == v:\n",
    "            continue\n",
    "        G.add_edge(u, v)\n",
    "        for key in edge_attrs:\n",
    "            G[u][v][key] = values[key][i]\n",
    "    for key in node_attrs:\n",
    "        for i, feat_dict in G.nodes(data=True):\n",
    "            feat_dict.update({key: values[key][i]})\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5814a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(to_networkx(train_data[sample_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node Fatures\n",
    "print(train_data[sample_id].x.shape)\n",
    "train_data[sample_id].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "labels = [data.y.item() for i, data in enumerate(train_data)]\n",
    "df = pd.DataFrame(labels, columns=[\"Labels\"])\n",
    "df[\"Labels\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ed6c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "# Because it is a directed graph, it will only share information from the root\n",
    "from torch_geometric.nn import global_max_pool as gmp\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.nn import Linear\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Graph Convolutions\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GATConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "\n",
    "        # Readout\n",
    "        self.lin_news = Linear(in_channels, hidden_channels)\n",
    "        self.lin0 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin1 = Linear(2*hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Graph Convolutions\n",
    "        h = self.conv1(x, edge_index).relu()\n",
    "        h = self.conv2(h, edge_index).relu()\n",
    "        h = self.conv3(h, edge_index).relu()\n",
    "\n",
    "        # Pooling\n",
    "        h = gmp(h, batch)\n",
    "\n",
    "        # Readout\n",
    "        h = self.lin0(h).relu()\n",
    "\n",
    "        # According to UPFD paper: Include raw word2vec embeddings of news \n",
    "        # This is done per graph in the batch\n",
    "        root = (batch[1:] - batch[:-1]).nonzero(as_tuple=False).view(-1)\n",
    "        root = torch.cat([root.new_zeros(1), root + 1], dim=0)\n",
    "        # root is e.g. [   0,   14,   94,  171,  230,  302, ... ]\n",
    "        news = x[root]\n",
    "        news = self.lin_news(news).relu()\n",
    "        \n",
    "        out = self.lin1(torch.cat([h, news], dim=-1))\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "GNN(train_data.num_features, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf3961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GNN(train_data.num_features, 256, 1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "loss_fnc = torch.nn.BCELoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = loss_fnc(torch.reshape(out, (-1,)), data.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = loss_fnc(torch.reshape(out, (-1,)), data.y.float())\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        all_preds.append(torch.reshape(out, (-1,)))\n",
    "        all_labels.append(data.y.float())\n",
    "\n",
    "    # Calculate Metrics\n",
    "    accuracy, f1 = metrics(all_preds, all_labels)\n",
    "\n",
    "    return total_loss / len(test_loader.dataset), accuracy, f1\n",
    "\n",
    "\n",
    "def metrics(preds, gts):\n",
    "    preds = torch.round(torch.cat(preds))\n",
    "    gts = torch.cat(gts)\n",
    "    acc = accuracy_score(preds, gts)\n",
    "    f1 = f1_score(preds, gts)\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(80):\n",
    "    train_loss = train(epoch)\n",
    "    test_loss, test_acc, test_f1 = test(epoch)\n",
    "    print(f'Epoch: {epoch:02d} |  TrainLoss: {train_loss:.2f} | '\n",
    "          f'TestLoss: {test_loss:.2f} | TestAcc: {test_acc:.2f} | TestF1: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ad981",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in test_loader:\n",
    "    data = data.to(device)\n",
    "    pred = model(data.x, data.edge_index, data.batch)\n",
    "    df = pd.DataFrame()\n",
    "    df[\"pred_logit\"] = pred.detach().numpy()[:,0]\n",
    "    df[\"pred\"] = torch.round(pred).detach().numpy()[:,0]\n",
    "    df[\"true\"] = data.y.numpy()\n",
    "    print(df.head(10))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
