{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/2104.12259.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_7tEz_UNXiW",
    "outputId": "0e9cfecb-5566-4cad-d583-64d655cc7be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch vers:  2.0.0+cu118\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "vers = torch.__version__\n",
    "print(\"Torch vers: \", vers)\n",
    "\n",
    "# PyG installation\n",
    "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html\n",
    "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html\n",
    "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git\n",
    "\n",
    "import torch_geometric  # handling graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optuna library used for the hyperparameter optimization\n",
    "# different samplers like grid search , random search ,evolutonary algo are used to find the optimal parameters.\n",
    "# Grid Search: searches in the predetermined subset of whole hyperparameter space of target algorithm.\n",
    "# Bayesian Search : Used probability distribution to select a value of each hyper-parameter\n",
    "# Random Search: Randomly search the space untill the stopping criteria are met \n",
    "# Evolutionary Algo: fitness function used to find the value of the hyperparameter\n",
    "# optuna has to componenets : study and trial\n",
    "# single execution of optimization function called trial\n",
    "# collection of trials is called study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nawGCOiiSEU9",
    "outputId": "7a1af302-bfb7-4cbd-9be6-0315088e5b56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting optuna\n",
      "  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cmaes>=0.9.1\n",
      "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (2.0.9)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.10.3-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
      "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 alembic-1.10.3 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader iterable object provides interface for batching and iterating over the object.(mini-batches)\n",
    "# during the testing the shufffling is necesary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T7SVmqHISIn0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import UPFD\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pwm4YDSKSMcB"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import ReLU, LeakyReLU, Softmax, Linear, SELU, GELU, ELU\n",
    "from torch_geometric.nn import SAGEConv, global_max_pool, TopKPooling,GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "G5eKCNkPSQDd"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score, f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9534JfVxST1b",
    "outputId": "cf72d2ee-12fd-430f-b0ad-d3a69677be28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://docs.google.com/uc?export=download&id=1VskhAQ92PrT4sWEKQ2v2-AJhEcpp4A81&confirm=t\n",
      "Extracting ./gossipcop/raw/uc\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test_data_gos = UPFD(root=\".\", name=\"gossipcop\", feature=\"bert\",split=\"test\")\n",
    "train_data_gos = UPFD(root=\".\", name=\"gossipcop\", feature=\"bert\", split=\"train\")\n",
    "val_data_gos = UPFD(root=\".\", name=\"gossipcop\", feature=\"bert\", split=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oTuLkumhSVs_"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data_gos, batch_size=32, shuffle=True) # shuffle reduces the bias the due to order\n",
    "test_loader = DataLoader(test_data_gos, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data_gos, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "g0tEmqEvSY86"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels[0])\n",
    "        self.leaky1 = LeakyReLU()\n",
    "        self.conv2 = SAGEConv(hidden_channels[0], hidden_channels[1])\n",
    "        self.leaky2 = LeakyReLU()\n",
    "        self.conv3 = SAGEConv(hidden_channels[1], hidden_channels[2])\n",
    "        self.leaky3 = LeakyReLU() \n",
    "        \n",
    "        self.full1 = Linear(hidden_channels[2],hidden_channels[3])\n",
    "        self.ge1 = GELU()\n",
    "        self.full2 = Linear(hidden_channels[3],hidden_channels[4])\n",
    "        self.ge2 = GELU()\n",
    "        self.full3 = Linear(hidden_channels[4],out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        h = self.leaky1(self.conv1(x, edge_index))\n",
    "        h = self.leaky2(self.conv2(h, edge_index))\n",
    "        h = self.leaky3(self.conv3(h, edge_index))\n",
    "\n",
    "        h = global_max_pool(h,batch)\n",
    "\n",
    "        h = self.ge1(self.full1(h))\n",
    "        h = self.ge2(self.full2(h))\n",
    "        h = self.full3(h)\n",
    "\n",
    "        return torch.sigmoid(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XdB5W8lMSbQv"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "E21fL2_pShuU"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "  \n",
    "  model = Net(768,[trial.suggest_int(name=\"layer_size1\",low=256,high=512,step=128),\n",
    "                   trial.suggest_int(name=\"layer_size2\",low=256,high=512,step=128),\n",
    "                   trial.suggest_int(name=\"layer_size3\",low=256,high=512,step=128),\n",
    "                   trial.suggest_int(name=\"layer_size4\",low=64,high=256,step=64),\n",
    "                   trial.suggest_int(name=\"layer_size5\",low=64,high=256,step=64),\n",
    "  \n",
    "  ],1).to(device)\n",
    "  optimizer = torch.optim.Adam(model.parameters(),lr=trial.suggest_loguniform('learning_rate', 1e-6, 1e-3),betas=(trial.suggest_loguniform('b1', 1-1e-1,1-1e-3),0.99))\n",
    "  lossff = torch.nn.BCELoss()\n",
    "\n",
    "  total_loss = 0\n",
    "  weighted_loss = 0\n",
    "  exp_param = 0.8\n",
    "\n",
    "  wloss = []\n",
    "\n",
    "  for i in range(400):\n",
    "    print(\"Epoch:\", i)\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "          data = data.to(device)\n",
    "          optimizer.zero_grad()\n",
    "          out = model(data.x, data.edge_index, data.batch)\n",
    "          loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          total_loss += float(loss) * data.num_graphs\n",
    "    print(\"Train: \",total_loss / len(train_loader.dataset))\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for data in val_loader:\n",
    "          data = data.to(device)\n",
    "          out = model(data.x, data.edge_index, data.batch)\n",
    "          loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
    "          total_loss += float(loss) * data.num_graphs\n",
    "          \n",
    "    print(\"Test\", total_loss / len(val_loader.dataset))\n",
    "\n",
    "    weighted_loss = exp_param*(weighted_loss) + (1-exp_param)*(total_loss/ len(val_loader.dataset))\n",
    "    print(weighted_loss/(1-exp_param**(i+1)))\n",
    "    wloss.append(weighted_loss/(1-exp_param**(i+1)))\n",
    "\n",
    "    if(i-30>=0 and wloss[i-20]-weighted_loss<0.01):\n",
    "      break\n",
    "\n",
    "  return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPE : iterative process that uses history or evaluated hyperparametes to create prob. model which suggest next hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jthzNJs0S2_F",
    "outputId": "a0c70996-6b51-4a4d-915d-8b50eec6b2d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:38:13,088]\u001b[0m A new study created in memory with name: no-name-06030083-3fc0-43d3-9a99-3c4a897919a4\u001b[0m\n",
      "<ipython-input-11-543a82f29da4>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  optimizer = torch.optim.Adam(model.parameters(),lr=trial.suggest_loguniform('learning_rate', 1e-6, 1e-3),betas=(trial.suggest_loguniform('b1', 1-1e-1,1-1e-3),0.99))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train:  0.693031710364443\n",
      "Test 0.6947778860727946\n",
      "0.6947778860727944\n",
      "Epoch: 1\n",
      "Train:  1.0397571995581463\n",
      "Test 0.6940625399460286\n",
      "0.6943804715579247\n",
      "Epoch: 2\n",
      "Train:  1.0387913008312604\n",
      "Test 0.6932288877693288\n",
      "0.6939085109888281\n",
      "Epoch: 3\n",
      "Train:  1.037541572100077\n",
      "Test 0.6921464466786647\n",
      "0.6933116057347075\n",
      "Epoch: 4\n",
      "Train:  1.0358875031436319\n",
      "Test 0.6907368040346837\n",
      "0.6925456604407929\n",
      "Epoch: 5\n",
      "Train:  1.0336406151235322\n",
      "Test 0.6889143059978555\n",
      "0.6915613614873555\n",
      "Epoch: 6\n",
      "Train:  1.0305389975890136\n",
      "Test 0.686090465867039\n",
      "0.6901768237560675\n",
      "Epoch: 7\n",
      "Train:  1.0261699441588406\n",
      "Test 0.6824093699018597\n",
      "0.6883101585278992\n",
      "Epoch: 8\n",
      "Train:  1.0201969201311523\n",
      "Test 0.6777031076696766\n",
      "0.6858598771577992\n",
      "Epoch: 9\n",
      "Train:  1.0123780950521812\n",
      "Test 0.6708581962864915\n",
      "0.6824986297962468\n",
      "Epoch: 10\n",
      "Train:  1.0014727128731025\n",
      "Test 0.6608651479085287\n",
      "0.6777653475715466\n",
      "Epoch: 11\n",
      "Train:  0.9852253805586707\n",
      "Test 0.6472040995573386\n",
      "0.671202073187348\n",
      "Epoch: 12\n",
      "Train:  0.96342543280605\n",
      "Test 0.62812757339233\n",
      "0.6620860124916212\n",
      "Epoch: 13\n",
      "Train:  0.9336961615871597\n",
      "Test 0.6028418977618654\n",
      "0.6496920994871894\n",
      "Epoch: 14\n",
      "Train:  0.8946817135199522\n",
      "Test 0.5711912886127011\n",
      "0.6334193923287361\n",
      "Epoch: 15\n",
      "Train:  0.8467707564105917\n",
      "Test 0.5322162528614421\n",
      "0.6125925406769119\n",
      "Epoch: 16\n",
      "Train:  0.7874834256949442\n",
      "Test 0.48496724244875783\n",
      "0.586479466884271\n",
      "Epoch: 17\n",
      "Train:  0.7186305152845907\n",
      "Test 0.4341617403449593\n",
      "0.5554570717884336\n",
      "Epoch: 18\n",
      "Train:  0.6486463843684493\n",
      "Test 0.3852998734393836\n",
      "0.5209280159814531\n",
      "Epoch: 19\n",
      "Train:  0.5813682528533342\n",
      "Test 0.33962138346481674\n",
      "0.48424374867150194\n",
      "Epoch: 20\n",
      "Train:  0.5205861230418359\n",
      "Test 0.302084424447664\n",
      "0.4474727310510471\n",
      "Epoch: 21\n",
      "Train:  0.47172124192609893\n",
      "Test 0.27290221917760243\n",
      "0.4122990930369231\n",
      "Epoch: 22\n",
      "Train:  0.433095388960489\n",
      "Test 0.2536514975922012\n",
      "0.3803811637486367\n",
      "Epoch: 23\n",
      "Train:  0.4053853720890515\n",
      "Test 0.23280130064749455\n",
      "0.3507251445372691\n",
      "Epoch: 24\n",
      "Train:  0.3776050580890624\n",
      "Test 0.21764314829648196\n",
      "0.3240078100532084\n",
      "Epoch: 25\n",
      "Train:  0.3552867395619115\n",
      "Test 0.20496942446782038\n",
      "0.3001279605194561\n",
      "Epoch: 26\n",
      "Train:  0.33675830835824483\n",
      "Test 0.1952066470360581\n",
      "0.27909283801735346\n",
      "Epoch: 27\n",
      "Train:  0.3214916051280149\n",
      "Test 0.1854234061070851\n",
      "0.26032264480135103\n",
      "Epoch: 28\n",
      "Train:  0.3072214710898015\n",
      "Test 0.17803997838453495\n",
      "0.2438406067995235\n",
      "Epoch: 29\n",
      "Train:  0.2954155585486374\n",
      "Test 0.1725366759103733\n",
      "0.22956214474181277\n",
      "Epoch: 30\n",
      "Train:  0.2858240623641145\n",
      "Test 0.1670509139041761\n",
      "0.21704750467507278\n",
      "Epoch: 31\n",
      "Train:  0.27686070648086814\n",
      "Test 0.16365670682964745\n",
      "0.20636087828826669\n",
      "Epoch: 32\n",
      "Train:  0.2707680717874796\n",
      "Test 0.16041850877222996\n",
      "0.19716657680416183\n",
      "Epoch: 33\n",
      "Train:  0.2640646874440677\n",
      "Test 0.15759080860613686\n",
      "0.1892474076687537\n",
      "Epoch: 34\n",
      "Train:  0.25956043005057855\n",
      "Test 0.1557037901174236\n",
      "0.18253596167255312\n",
      "Epoch: 35\n",
      "Train:  0.2561499894470413\n",
      "Test 0.15454112151603558\n",
      "0.17693517608241055\n",
      "Epoch: 36\n",
      "Train:  0.25271160660427566\n",
      "Test 0.15157800352016648\n",
      "0.1718624246083846\n",
      "Epoch: 37\n",
      "Train:  0.2489122397201511\n",
      "Test 0.15067602573951958\n",
      "0.1676242646032164\n",
      "Epoch: 38\n",
      "Train:  0.24536562354846314\n",
      "Test 0.15133185995804085\n",
      "0.16436524217620016\n",
      "Epoch: 39\n",
      "Train:  0.24328391540509003\n",
      "Test 0.14870357471125903\n",
      "0.16123249226932393\n",
      "Epoch: 40\n",
      "Train:  0.24010145108150693\n",
      "Test 0.14913004736378516\n",
      "0.15881174587030542\n",
      "Epoch: 41\n",
      "Train:  0.23986490420833395\n",
      "Test 0.14667556130569495\n",
      "0.15638430245333546\n",
      "Epoch: 42\n",
      "Train:  0.23641417349514726\n",
      "Test 0.1472302561646307\n",
      "0.15455336858869267\n",
      "Epoch: 43\n",
      "Train:  0.2335393843872152\n",
      "Test 0.14521601955805505\n",
      "0.15268579710230182\n",
      "Epoch: 44\n",
      "Train:  0.23153421215221778\n",
      "Test 0.1465161487105347\n",
      "0.1514518136763899\n",
      "Epoch: 45\n",
      "Train:  0.23008091060697158\n",
      "Test 0.14423935212563355\n",
      "0.1500092711009661\n",
      "Epoch: 46\n",
      "Train:  0.22763616023516972\n",
      "Test 0.1436757167303191\n",
      "0.14874252491510678\n",
      "Epoch: 47\n",
      "Train:  0.22974045628224646\n",
      "Test 0.1463441256119873\n",
      "0.14826283435702597\n",
      "Epoch: 48\n",
      "Train:  0.22451402171218132\n",
      "Test 0.1421054363994426\n",
      "0.14703133279478725\n",
      "Epoch: 49\n",
      "Train:  0.22677531318684474\n",
      "Test 0.1472793949065191\n",
      "0.1470809459252359\n",
      "Epoch: 50\n",
      "Train:  0.22882455737490356\n",
      "Test 0.1415188050532079\n",
      "0.1459685050490009\n",
      "Epoch: 51\n",
      "Train:  0.22051198545829717\n",
      "Test 0.14070202859166342\n",
      "0.14491520013624057\n",
      "Epoch: 52\n",
      "Train:  0.2175365626443546\n",
      "Test 0.14096567317700157\n",
      "0.14412528897211047\n",
      "Epoch: 53\n",
      "Train:  0.21595804783133551\n",
      "Test 0.1402488547367054\n",
      "0.14334999759267095\n",
      "Epoch: 54\n",
      "Train:  0.21497281455185824\n",
      "Test 0.14060421648261312\n",
      "0.14280083880235067\n",
      "Epoch: 55\n",
      "Train:  0.21681088348338892\n",
      "Test 0.13843646328964512\n",
      "0.14192796043398384\n",
      "Epoch: 56\n",
      "Train:  0.2129444073025997\n",
      "Test 0.13867677589912555\n",
      "0.14127772158074628\n",
      "Epoch: 57\n",
      "Train:  0.20900684016528148\n",
      "Test 0.1375808963627169\n",
      "0.14053835476670865\n",
      "Epoch: 58\n",
      "Train:  0.20688658824442943\n",
      "Test 0.13746003498879325\n",
      "0.13992268963174545\n",
      "Epoch: 59\n",
      "Train:  0.20525259216530964\n",
      "Test 0.1382571904759704\n",
      "0.13958958929011567\n",
      "Epoch: 60\n",
      "Train:  0.20422385652095842\n",
      "Test 0.13689199735448038\n",
      "0.13905007024154017\n",
      "Epoch: 61\n",
      "Train:  0.20775607667672327\n",
      "Test 0.13640642541054732\n",
      "0.13852134075676523\n",
      "Epoch: 62\n",
      "Train:  0.20464261960845453\n",
      "Test 0.14685490313276048\n",
      "0.14018805453973077\n",
      "Epoch: 63\n",
      "Train:  0.21319014614877793\n",
      "Test 0.13460325051249164\n",
      "0.13907109303315485\n",
      "Epoch: 64\n",
      "Train:  0.19776621189364146\n",
      "Test 0.137830422079061\n",
      "0.13882295871773093\n",
      "Epoch: 65\n",
      "Train:  0.19817556104462444\n",
      "Test 0.1338651497599297\n",
      "0.13783139652782594\n",
      "Epoch: 66\n",
      "Train:  0.19445770704306853\n",
      "Test 0.13606396271086438\n",
      "0.13747790965082732\n",
      "Epoch: 67\n",
      "Train:  0.19428183532732746\n",
      "Test 0.13372744156573063\n",
      "0.1367278158409513\n",
      "Epoch: 68\n",
      "Train:  0.19219441524614672\n",
      "Test 0.1330400060575742\n",
      "0.13599025373256815\n",
      "Epoch: 69\n",
      "Train:  0.19058105612221438\n",
      "Test 0.13473054346024663\n",
      "0.13573831163664668\n",
      "Epoch: 70\n",
      "Train:  0.19058659171426307\n",
      "Test 0.13251177982799026\n",
      "0.13509300518996703\n",
      "Epoch: 71\n",
      "Train:  0.18923256383106904\n",
      "Test 0.13169771487459594\n",
      "0.13441394705537965\n",
      "Epoch: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:39:10,374]\u001b[0m Trial 0 finished with value: 0.13482499771436204 and parameters: {'layer_size1': 512, 'layer_size2': 256, 'layer_size3': 256, 'layer_size4': 192, 'layer_size5': 192, 'learning_rate': 9.138773262152432e-06, 'b1': 0.9650265253690663}. Best is trial 0 with value: 0.13482499771436204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.18604317064577844\n",
      "Test 0.13646925697205486\n",
      "0.13482500907334657\n",
      "Epoch: 0\n",
      "Train:  0.6903570905709878\n",
      "Test 0.681168719962403\n",
      "0.6811687199624031\n",
      "Epoch: 1\n",
      "Train:  0.9847739910904741\n",
      "Test 0.5366530889993185\n",
      "0.6008822583162451\n",
      "Epoch: 2\n",
      "Train:  0.6830578332855588\n",
      "Test 0.2761192712045851\n",
      "0.4677826734344172\n",
      "Epoch: 3\n",
      "Train:  0.3843477311042639\n",
      "Test 0.161328371436823\n",
      "0.36397024050840293\n",
      "Epoch: 4\n",
      "Train:  0.2644373882739317\n",
      "Test 0.14856876129959964\n",
      "0.2998931703011197\n",
      "Epoch: 5\n",
      "Train:  0.25920980015680906\n",
      "Test 0.1635670108454568\n",
      "0.2629412015007948\n",
      "Epoch: 6\n",
      "Train:  0.24634623663984376\n",
      "Test 0.14683097937304676\n",
      "0.23355680181912358\n",
      "Epoch: 7\n",
      "Train:  0.22901001370992963\n",
      "Test 0.14678980636618513\n",
      "0.2127050611580713\n",
      "Epoch: 8\n",
      "Train:  0.22466764925218327\n",
      "Test 0.1360586561781146\n",
      "0.19499936136292545\n",
      "Epoch: 9\n",
      "Train:  0.2194440903299021\n",
      "Test 0.14112842813366172\n",
      "0.18292914511618807\n",
      "Epoch: 10\n",
      "Train:  0.20436600161266033\n",
      "Test 0.14643792295828462\n",
      "0.17494507421654953\n",
      "Epoch: 11\n",
      "Train:  0.20675614176764948\n",
      "Test 0.13382013284707026\n",
      "0.1661131615238321\n",
      "Epoch: 12\n",
      "Train:  0.1892761410625085\n",
      "Test 0.1238826362641303\n",
      "0.1571757151620199\n",
      "Epoch: 13\n",
      "Train:  0.17995610537055212\n",
      "Test 0.12319532652887014\n",
      "0.15006699250666192\n",
      "Epoch: 14\n",
      "Train:  0.1719192139661083\n",
      "Test 0.12319142095771901\n",
      "0.14449586144877707\n",
      "Epoch: 15\n",
      "Train:  0.16159274368359275\n",
      "Test 0.1195304606386184\n",
      "0.13935816807445703\n",
      "Epoch: 16\n",
      "Train:  0.1515576263400129\n",
      "Test 0.118360053246411\n",
      "0.1350617994890463\n",
      "Epoch: 17\n",
      "Train:  0.14550571043842606\n",
      "Test 0.15162381224143198\n",
      "0.13843496763473945\n",
      "Epoch: 18\n",
      "Train:  0.15341644264048054\n",
      "Test 0.12823402360184016\n",
      "0.136364946682271\n",
      "Epoch: 19\n",
      "Train:  0.1362085917362459\n",
      "Test 0.11578855272587184\n",
      "0.13220166856224883\n",
      "Epoch: 20\n",
      "Train:  0.1247082219583634\n",
      "Test 0.14188039143341202\n",
      "0.13415543343679193\n",
      "Epoch: 21\n",
      "Train:  0.14567278834501615\n",
      "Test 0.1388072690247616\n",
      "0.13509271648257393\n",
      "Epoch: 22\n",
      "Train:  0.12974809011915228\n",
      "Test 0.14583741046058443\n",
      "0.13725441569807773\n",
      "Epoch: 23\n",
      "Train:  0.13032758939796343\n",
      "Test 0.13127571879374375\n",
      "0.13605300280523366\n",
      "Epoch: 24\n",
      "Train:  0.1101964426669548\n",
      "Test 0.13057731233891987\n",
      "0.1349537117076235\n",
      "Epoch: 25\n",
      "Train:  0.10933213067606037\n",
      "Test 0.11858149051057318\n",
      "0.13166934106704195\n",
      "Epoch: 26\n",
      "Train:  0.09201035330020021\n",
      "Test 0.12363281891759717\n",
      "0.1300581409944163\n",
      "Epoch: 27\n",
      "Train:  0.0940709222780179\n",
      "Test 0.12646186473500495\n",
      "0.12933749180427345\n",
      "Epoch: 28\n",
      "Train:  0.08882481441801096\n",
      "Test 0.13440120842430617\n",
      "0.13035180470146476\n",
      "Epoch: 29\n",
      "Train:  0.09001235300060975\n",
      "Test 0.14110040309883298\n",
      "0.13250418890352206\n",
      "Epoch: 30\n",
      "Train:  0.08840777072586432\n",
      "Test 0.13317555097706152\n",
      "0.13263859442701317\n",
      "Epoch: 31\n",
      "Train:  0.08021075757401194\n",
      "Test 0.15202386717045732\n",
      "0.13651872313037686\n",
      "Epoch: 32\n",
      "Train:  0.09336590995107955\n",
      "Test 0.16433631222108344\n",
      "0.1420857694833436\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:39:32,911]\u001b[0m Trial 1 finished with value: 0.14163589020703352 and parameters: {'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 256, 'layer_size4': 64, 'layer_size5': 256, 'learning_rate': 8.026461115689728e-05, 'b1': 0.9003918746833378}. Best is trial 0 with value: 0.13482499771436204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.10253122502736638\n",
      "Test 0.1401966033237321\n",
      "0.14170774457001797\n",
      "Epoch: 0\n",
      "Train:  0.6911767033430246\n",
      "Test 0.6881131545091287\n",
      "0.6881131545091286\n",
      "Epoch: 1\n",
      "Train:  1.0198635013548882\n",
      "Test 0.6520861904699724\n",
      "0.6680981744873752\n",
      "Epoch: 2\n",
      "Train:  0.9016765210873041\n",
      "Test 0.40664562113555797\n",
      "0.5609454886874501\n",
      "Epoch: 3\n",
      "Train:  0.528077224344561\n",
      "Test 0.2219203450740912\n",
      "0.44609957282926616\n",
      "Epoch: 4\n",
      "Train:  0.35670470296244916\n",
      "Test 0.17643235110756242\n",
      "0.3658796710795923\n",
      "Epoch: 5\n",
      "Train:  0.2780092451653201\n",
      "Test 0.1470581030425353\n",
      "0.30656685989772026\n",
      "Epoch: 6\n",
      "Train:  0.24902851304428264\n",
      "Test 0.14481340043055704\n",
      "0.26563137449621355\n",
      "Epoch: 7\n",
      "Train:  0.23286221715393085\n",
      "Test 0.1398614430493051\n",
      "0.23540649486543638\n",
      "Epoch: 8\n",
      "Train:  0.2225327554257798\n",
      "Test 0.1389399740722153\n",
      "0.21312224998932483\n",
      "Epoch: 9\n",
      "Train:  0.21901768901054458\n",
      "Test 0.13340501634629218\n",
      "0.19526096207422328\n",
      "Epoch: 10\n",
      "Train:  0.20825286100417267\n",
      "Test 0.13434552848884912\n",
      "0.18193301327263695\n",
      "Epoch: 11\n",
      "Train:  0.19836411386516778\n",
      "Test 0.13482868328908862\n",
      "0.1718169786714934\n",
      "Epoch: 12\n",
      "Train:  0.195512505411938\n",
      "Test 0.15386082663204206\n",
      "0.16801683304862372\n",
      "Epoch: 13\n",
      "Train:  0.20016162315786104\n",
      "Test 0.12674184340383216\n",
      "0.15938207441901361\n",
      "Epoch: 14\n",
      "Train:  0.1913765670796481\n",
      "Test 0.12638897748302408\n",
      "0.15254282016534448\n",
      "Epoch: 15\n",
      "Train:  0.18658883860437098\n",
      "Test 0.1495289894122794\n",
      "0.15192259626391033\n",
      "Epoch: 16\n",
      "Train:  0.183893292985819\n",
      "Test 0.12499239673026097\n",
      "0.14641247955949663\n",
      "Epoch: 17\n",
      "Train:  0.15677497513087352\n",
      "Test 0.1238605728400223\n",
      "0.14181935585478167\n",
      "Epoch: 18\n",
      "Train:  0.17766377024673224\n",
      "Test 0.13209264513937544\n",
      "0.1398455684372099\n",
      "Epoch: 19\n",
      "Train:  0.15886265427665613\n",
      "Test 0.12224554175156213\n",
      "0.13628450685531035\n",
      "Epoch: 20\n",
      "Train:  0.1407290452301516\n",
      "Test 0.12235452039610772\n",
      "0.13347257406116678\n",
      "Epoch: 21\n",
      "Train:  0.1343603923289112\n",
      "Test 0.12822024027335938\n",
      "0.13241429860903534\n",
      "Epoch: 22\n",
      "Train:  0.13189265224656205\n",
      "Test 0.1299433141209922\n",
      "0.1319171671653426\n",
      "Epoch: 23\n",
      "Train:  0.128875497298745\n",
      "Test 0.12426820787645522\n",
      "0.13038011679240147\n",
      "Epoch: 24\n",
      "Train:  0.11259742133104457\n",
      "Test 0.12784239613781972\n",
      "0.1298706479425888\n",
      "Epoch: 25\n",
      "Train:  0.10901042686531409\n",
      "Test 0.12819059061196944\n",
      "0.12953361786555964\n",
      "Epoch: 26\n",
      "Train:  0.10372940071768062\n",
      "Test 0.1740365302174833\n",
      "0.13845577278283655\n",
      "Epoch: 27\n",
      "Train:  0.12916888676872887\n",
      "Test 0.13899563579485777\n",
      "0.13856395463938415\n",
      "Epoch: 28\n",
      "Train:  0.09692094341174601\n",
      "Test 0.13509341719604673\n",
      "0.13786877140676881\n",
      "Epoch: 29\n",
      "Train:  0.09014705329921929\n",
      "Test 0.13823778283033492\n",
      "0.13794266516752712\n",
      "Epoch: 30\n",
      "Train:  0.08969631459416426\n",
      "Test 0.14211618313105306\n",
      "0.13877819623011747\n",
      "Epoch: 31\n",
      "Train:  0.09504663298970886\n",
      "Test 0.21511775850861645\n",
      "0.1540582147637333\n",
      "Epoch: 32\n",
      "Train:  0.12561254155228935\n",
      "Test 0.1472444954522691\n",
      "0.1526946066120945\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:39:56,365]\u001b[0m Trial 2 finished with value: 0.1550413183397691 and parameters: {'layer_size1': 512, 'layer_size2': 384, 'layer_size3': 384, 'layer_size4': 192, 'layer_size5': 192, 'learning_rate': 6.161501225457653e-05, 'b1': 0.9518508061804145}. Best is trial 0 with value: 0.13482499771436204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.08776160539085243\n",
      "Test 0.16481529206991444\n",
      "0.15511997351078044\n",
      "Epoch: 0\n",
      "Train:  0.6930590900746021\n",
      "Test 0.6922601077146145\n",
      "0.6922601077146145\n",
      "Epoch: 1\n",
      "Train:  1.0370687143706576\n",
      "Test 0.690568840110695\n",
      "0.6913205146013259\n",
      "Epoch: 2\n",
      "Train:  1.0334010392754942\n",
      "Test 0.6867863350298815\n",
      "0.6894622442851602\n",
      "Epoch: 3\n",
      "Train:  1.0262398377006308\n",
      "Test 0.6797249945965442\n",
      "0.6861637179678783\n",
      "Epoch: 4\n",
      "Train:  1.0129081154917623\n",
      "Test 0.6669544544848767\n",
      "0.6804493963701268\n",
      "Epoch: 5\n",
      "Train:  0.9904012444255116\n",
      "Test 0.6452958644964756\n",
      "0.6709208347338045\n",
      "Epoch: 6\n",
      "Train:  0.9524377239492786\n",
      "Test 0.6084415921361455\n",
      "0.6551090052268573\n",
      "Epoch: 7\n",
      "Train:  0.8926946274090163\n",
      "Test 0.5557063405330365\n",
      "0.6312206756334083\n",
      "Epoch: 8\n",
      "Train:  0.8063427667259734\n",
      "Test 0.4772834264751756\n",
      "0.5956604073912255\n",
      "Epoch: 9\n",
      "Train:  0.685143259091255\n",
      "Test 0.38182073209311934\n",
      "0.5477479067483343\n",
      "Epoch: 10\n",
      "Train:  0.5493339532133423\n",
      "Test 0.288093300201954\n",
      "0.4909369624858098\n",
      "Epoch: 11\n",
      "Train:  0.43074775257935893\n",
      "Test 0.22356339050081622\n",
      "0.43351633243807963\n",
      "Epoch: 12\n",
      "Train:  0.3552779560506126\n",
      "Test 0.18617576948834427\n",
      "0.381170475954662\n",
      "Epoch: 13\n",
      "Train:  0.3064610616887336\n",
      "Test 0.1627911817514416\n",
      "0.33548536467111806\n",
      "Epoch: 14\n",
      "Train:  0.2840420802024913\n",
      "Test 0.15303674940661197\n",
      "0.2976649542245111\n",
      "Epoch: 15\n",
      "Train:  0.2631454882604299\n",
      "Test 0.14734370536733787\n",
      "0.2667299618266019\n",
      "Epoch: 16\n",
      "Train:  0.26211582825454327\n",
      "Test 0.1561359019980735\n",
      "0.24410160455399157\n",
      "Epoch: 17\n",
      "Train:  0.2512097877233661\n",
      "Test 0.15047294946708084\n",
      "0.22503235242956215\n",
      "Epoch: 18\n",
      "Train:  0.24762433127332956\n",
      "Test 0.1549488000380687\n",
      "0.21081068614005707\n",
      "Epoch: 19\n",
      "Train:  0.24903733497519634\n",
      "Test 0.15080306103159657\n",
      "0.1986691790723986\n",
      "Epoch: 20\n",
      "Train:  0.24030987969548492\n",
      "Test 0.16237341680806197\n",
      "0.1913424494665632\n",
      "Epoch: 21\n",
      "Train:  0.23889741974272133\n",
      "Test 0.14717881168637956\n",
      "0.18244406341042785\n",
      "Epoch: 22\n",
      "Train:  0.22902079501049422\n",
      "Test 0.14699210709595417\n",
      "0.17531156933382486\n",
      "Epoch: 23\n",
      "Train:  0.22469719107716513\n",
      "Test 0.1428785029211979\n",
      "0.16879417854347534\n",
      "Epoch: 24\n",
      "Train:  0.21679013180836434\n",
      "Test 0.1386141787528746\n",
      "0.16273528874687612\n",
      "Epoch: 25\n",
      "Train:  0.2095768207491413\n",
      "Test 0.14357391152626428\n",
      "0.15889139584932455\n",
      "Epoch: 26\n",
      "Train:  0.21263281444271842\n",
      "Test 0.1365712179014316\n",
      "0.15441654072394573\n",
      "Epoch: 27\n",
      "Train:  0.20650985821290113\n",
      "Test 0.14331931019740882\n",
      "0.1521927932654882\n",
      "Epoch: 28\n",
      "Train:  0.20298752734171494\n",
      "Test 0.13551428278178085\n",
      "0.14885192141996711\n",
      "Epoch: 29\n",
      "Train:  0.19556631018226836\n",
      "Test 0.1360236550105613\n",
      "0.14628308807643572\n",
      "Epoch: 30\n",
      "Train:  0.1959956598755112\n",
      "Test 0.13313350965517945\n",
      "0.14365056526787323\n",
      "Epoch: 31\n",
      "Train:  0.19814168661747522\n",
      "Test 0.13228626674784846\n",
      "0.14137590339105985\n",
      "Epoch: 32\n",
      "Train:  0.19377287982147692\n",
      "Test 0.14213876566771186\n",
      "0.14152857261200502\n",
      "Epoch: 33\n",
      "Train:  0.19516741090723666\n",
      "Test 0.13731910458905794\n",
      "0.1406862519000732\n",
      "Epoch: 34\n",
      "Train:  0.19126849790059386\n",
      "Test 0.1477173792297232\n",
      "0.14209304803031003\n",
      "Epoch: 35\n",
      "Train:  0.18626531131903304\n",
      "Test 0.13426046531934005\n",
      "0.1405260229594065\n",
      "Epoch: 36\n",
      "Train:  0.1796750301297331\n",
      "Test 0.1329546567912285\n",
      "0.13901135649587487\n",
      "Epoch: 37\n",
      "Train:  0.1803584036420717\n",
      "Test 0.1304704607464373\n",
      "0.13730282249735884\n",
      "Epoch: 38\n",
      "Train:  0.1858592775962469\n",
      "Test 0.12833083592928374\n",
      "0.1355081269888046\n",
      "Epoch: 39\n",
      "Train:  0.17453906333053504\n",
      "Test 0.15520870365584508\n",
      "0.13944876612299853\n",
      "Epoch: 40\n",
      "Train:  0.18417678118065928\n",
      "Test 0.14603228502712406\n",
      "0.1407656099346765\n",
      "Epoch: 41\n",
      "Train:  0.18038718113778057\n",
      "Test 0.15686794568958518\n",
      "0.14398635107601293\n",
      "Epoch: 42\n",
      "Train:  0.18039645391410633\n",
      "Test 0.12877064454795678\n",
      "0.14094300265084062\n",
      "Epoch: 43\n",
      "Train:  0.16205443667022737\n",
      "Test 0.1284190042749484\n",
      "0.1384380665939709\n",
      "Epoch: 44\n",
      "Train:  0.16313531912433413\n",
      "Test 0.12789115088654088\n",
      "0.13632859157188926\n",
      "Epoch: 45\n",
      "Train:  0.16110104191434252\n",
      "Test 0.12697465790456142\n",
      "0.1344577396487486\n",
      "Epoch: 46\n",
      "Train:  0.15769865623958437\n",
      "Test 0.14092288545636467\n",
      "0.13575080485566893\n",
      "Epoch: 47\n",
      "Train:  0.1599949627241372\n",
      "Test 0.1320261958706783\n",
      "0.13500586644598914\n",
      "Epoch: 48\n",
      "Train:  0.1506651732814754\n",
      "Test 0.14759996145854504\n",
      "0.13752473038653468\n",
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:40:29,557]\u001b[0m Trial 3 finished with value: 0.13662358199603428 and parameters: {'layer_size1': 256, 'layer_size2': 512, 'layer_size3': 256, 'layer_size4': 192, 'layer_size5': 256, 'learning_rate': 2.9819313294632825e-05, 'b1': 0.9919807667716276}. Best is trial 0 with value: 0.13482499771436204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.161608341330792\n",
      "Test 0.1330288025267395\n",
      "0.1366255319807871\n",
      "Epoch: 0\n",
      "Train:  0.6926837122484004\n",
      "Test 0.692406972249349\n",
      "0.692406972249349\n",
      "Epoch: 1\n",
      "Train:  1.0378630137268876\n",
      "Test 0.6917291032525646\n",
      "0.6920303783622467\n",
      "Epoch: 2\n",
      "Train:  1.03605667247877\n",
      "Test 0.6899621460463975\n",
      "0.6911827421672264\n",
      "Epoch: 3\n",
      "Train:  1.0328191278618335\n",
      "Test 0.6868278432241727\n",
      "0.6897075053978993\n",
      "Epoch: 4\n",
      "Train:  1.026889586295837\n",
      "Test 0.6809137542169172\n",
      "0.6870915632331616\n",
      "Epoch: 5\n",
      "Train:  1.0157972837324107\n",
      "Test 0.6702180891246586\n",
      "0.6825179136027452\n",
      "Epoch: 6\n",
      "Train:  0.9957845540710422\n",
      "Test 0.6494975046360449\n",
      "0.6741613289976254\n",
      "Epoch: 7\n",
      "Train:  0.9593885080281631\n",
      "Test 0.6112202925559802\n",
      "0.6590354143342454\n",
      "Epoch: 8\n",
      "Train:  0.8926299819142827\n",
      "Test 0.5450101660721468\n",
      "0.632695016303527\n",
      "Epoch: 9\n",
      "Train:  0.7827542739691752\n",
      "Test 0.4417105985211802\n",
      "0.5899034200900439\n",
      "Epoch: 10\n",
      "Train:  0.6239559524880224\n",
      "Test 0.3177397445444659\n",
      "0.5303555630065155\n",
      "Epoch: 11\n",
      "Train:  0.4582119707441155\n",
      "Test 0.22904325743297954\n",
      "0.4656463163194956\n",
      "Epoch: 12\n",
      "Train:  0.3538118502868837\n",
      "Test 0.17897899727244954\n",
      "0.40497755191479806\n",
      "Epoch: 13\n",
      "Train:  0.29667643811076116\n",
      "Test 0.1655736771913675\n",
      "0.35489408269965556\n",
      "Epoch: 14\n",
      "Train:  0.2824175939673469\n",
      "Test 0.1516596100705884\n",
      "0.3127648993096495\n",
      "Epoch: 15\n",
      "Train:  0.2593004260853533\n",
      "Test 0.15221992458452235\n",
      "0.27972594034408643\n",
      "Epoch: 16\n",
      "Train:  0.25103377554251816\n",
      "Test 0.1479888058680318\n",
      "0.25277155464185264\n",
      "Epoch: 17\n",
      "Train:  0.24798883589141535\n",
      "Test 0.146291608894892\n",
      "0.23108489333330823\n",
      "Epoch: 18\n",
      "Train:  0.24147879143139764\n",
      "Test 0.14752262997894716\n",
      "0.2141280670414134\n",
      "Epoch: 19\n",
      "Train:  0.23974790510417887\n",
      "Test 0.1455437177485162\n",
      "0.20025120788950765\n",
      "Epoch: 20\n",
      "Train:  0.23405111570170511\n",
      "Test 0.14243041290031686\n",
      "0.18857939542294597\n",
      "Epoch: 21\n",
      "Train:  0.22983388593863874\n",
      "Test 0.1424883967299601\n",
      "0.17929267175845998\n",
      "Epoch: 22\n",
      "Train:  0.22895629944846088\n",
      "Test 0.14081887600622772\n",
      "0.1715522210517892\n",
      "Epoch: 23\n",
      "Train:  0.22593400110200648\n",
      "Test 0.1427218748645468\n",
      "0.1657587931244758\n",
      "Epoch: 24\n",
      "Train:  0.22821926748577928\n",
      "Test 0.14589317492294662\n",
      "0.16177060252608266\n",
      "Epoch: 25\n",
      "Train:  0.22210832203537118\n",
      "Test 0.13760773608317742\n",
      "0.15692337940453893\n",
      "Epoch: 26\n",
      "Train:  0.21430379788190018\n",
      "Test 0.14208927837920277\n",
      "0.15394936848228824\n",
      "Epoch: 27\n",
      "Train:  0.216291816843735\n",
      "Test 0.13544303944655062\n",
      "0.15024092951094406\n",
      "Epoch: 28\n",
      "Train:  0.20886823197403726\n",
      "Test 0.13375876150725088\n",
      "0.14693938702065526\n",
      "Epoch: 29\n",
      "Train:  0.204383590173372\n",
      "Test 0.13696147709566375\n",
      "0.14494133156280498\n",
      "Epoch: 30\n",
      "Train:  0.20567007272439453\n",
      "Test 0.13221432874490927\n",
      "0.14239340765761038\n",
      "Epoch: 31\n",
      "Train:  0.2026044574562774\n",
      "Test 0.1340065493279106\n",
      "0.14071470598718286\n",
      "Epoch: 32\n",
      "Train:  0.19824683527724865\n",
      "Test 0.136219648596568\n",
      "0.13981512433144694\n",
      "Epoch: 33\n",
      "Train:  0.20103993916358703\n",
      "Test 0.1310472920700744\n",
      "0.13806066826425778\n",
      "Epoch: 34\n",
      "Train:  0.1943603597936176\n",
      "Test 0.146963430616336\n",
      "0.13984194330567357\n",
      "Epoch: 35\n",
      "Train:  0.20738463643460703\n",
      "Test 0.13274473159304467\n",
      "0.13842204017823856\n",
      "Epoch: 36\n",
      "Train:  0.1879542106182584\n",
      "Test 0.13310351482022814\n",
      "0.13735805888129918\n",
      "Epoch: 37\n",
      "Train:  0.18802326134552722\n",
      "Test 0.12805927136141956\n",
      "0.1354979150405624\n",
      "Epoch: 38\n",
      "Train:  0.18293645717681217\n",
      "Test 0.1296710927353237\n",
      "0.13433235691795375\n",
      "Epoch: 39\n",
      "Train:  0.18155230160788957\n",
      "Test 0.125830677007035\n",
      "0.13263179489230467\n",
      "Epoch: 40\n",
      "Train:  0.17507612004521347\n",
      "Test 0.12419524389035973\n",
      "0.13094430524723738\n",
      "Epoch: 41\n",
      "Train:  0.17217083408364228\n",
      "Test 0.12436710366290131\n",
      "0.12962875301556337\n",
      "Epoch: 42\n",
      "Train:  0.1712624474186382\n",
      "Test 0.12447624334267207\n",
      "0.12859818094388434\n",
      "Epoch: 43\n",
      "Train:  0.16823682481006824\n",
      "Test 0.12276307774550749\n",
      "0.12743109676210213\n",
      "Epoch: 44\n",
      "Train:  0.16683222636607759\n",
      "Test 0.12944373480238758\n",
      "0.12783364190347293\n",
      "Epoch: 45\n",
      "Train:  0.16558419637409322\n",
      "Test 0.12386170256159681\n",
      "0.1270392263537559\n",
      "Epoch: 46\n",
      "Train:  0.1628037802329212\n",
      "Test 0.12348573362870967\n",
      "0.12632850799681042\n",
      "Epoch: 47\n",
      "Train:  0.16380208834405346\n",
      "Test 0.14648481109435416\n",
      "0.13035985851843995\n",
      "Epoch: 48\n",
      "Train:  0.17589785047250736\n",
      "Test 0.1218709948876934\n",
      "0.12866205550247267\n",
      "Epoch: 49\n",
      "Train:  0.1557363219684563\n",
      "Test 0.11898487697154174\n",
      "0.12672659217243076\n",
      "Epoch: 50\n",
      "Train:  0.1507293441616026\n",
      "Test 0.11794600639860708\n",
      "0.12497045496612381\n",
      "Epoch: 51\n",
      "Train:  0.14833398445103413\n",
      "Test 0.11979987270679775\n",
      "0.12393632906815427\n",
      "Epoch: 52\n",
      "Train:  0.1478548011326337\n",
      "Test 0.11781216993579989\n",
      "0.12271148829114939\n",
      "Epoch: 53\n",
      "Train:  0.1459400018740227\n",
      "Test 0.12042271637872899\n",
      "0.12225373123261454\n",
      "Epoch: 54\n",
      "Train:  0.14443848987584149\n",
      "Test 0.11850592499469226\n",
      "0.12150416647946172\n",
      "Epoch: 55\n",
      "Train:  0.14681298480942273\n",
      "Test 0.1275833758351567\n",
      "0.12272001289962226\n",
      "Epoch: 56\n",
      "Train:  0.14898928321024654\n",
      "Test 0.13505772323835463\n",
      "0.12518756235312758\n",
      "Epoch: 57\n",
      "Train:  0.14674201266560363\n",
      "Test 0.11799542019109586\n",
      "0.12374913047636119\n",
      "Epoch: 58\n",
      "Train:  0.13263126958038782\n",
      "Test 0.11682914369722534\n",
      "0.12236513046931671\n",
      "Epoch: 59\n",
      "Train:  0.13189420604314178\n",
      "Test 0.11741944177983663\n",
      "0.1213759912155692\n",
      "Epoch: 60\n",
      "Train:  0.1290162105689801\n",
      "Test 0.11804043477053171\n",
      "0.12070887910868464\n",
      "Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:41:09,932]\u001b[0m Trial 4 finished with value: 0.12012299756208797 and parameters: {'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 256, 'learning_rate': 1.6864191696897905e-05, 'b1': 0.9652220612376727}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.12964543910362783\n",
      "Test 0.11778006333032207\n",
      "0.12012311537849672\n",
      "Epoch: 0\n",
      "Train:  0.6925740715784904\n",
      "Test 0.6906582883426121\n",
      "0.6906582883426121\n",
      "Epoch: 1\n",
      "Train:  1.0315223182295705\n",
      "Test 0.6773878080504281\n",
      "0.6832857992913989\n",
      "Epoch: 2\n",
      "Train:  0.9955286341054099\n",
      "Test 0.6146488176597343\n",
      "0.6551558887866183\n",
      "Epoch: 3\n",
      "Train:  0.8417328412716205\n",
      "Test 0.376708916255406\n",
      "0.5608310335931183\n",
      "Epoch: 4\n",
      "Train:  0.5221946121026309\n",
      "Test 0.24095513587032918\n",
      "0.4656751858650158\n",
      "Epoch: 5\n",
      "Train:  0.3741599343607932\n",
      "Test 0.17843008630878324\n",
      "0.3878157933666876\n",
      "Epoch: 6\n",
      "Train:  0.28691367439297966\n",
      "Test 0.1724199957449685\n",
      "0.3333048632256247\n",
      "Epoch: 7\n",
      "Train:  0.2541470176782527\n",
      "Test 0.14596748723215236\n",
      "0.28828416889425684\n",
      "Epoch: 8\n",
      "Train:  0.24472306338531194\n",
      "Test 0.1547879846050189\n",
      "0.25744588804545754\n",
      "Epoch: 9\n",
      "Train:  0.23632592057652307\n",
      "Test 0.1524992336420131\n",
      "0.23393174531415853\n",
      "Epoch: 10\n",
      "Train:  0.2246372362482788\n",
      "Test 0.13851097913888785\n",
      "0.2130542269031675\n",
      "Epoch: 11\n",
      "Train:  0.2039776618077314\n",
      "Test 0.1432063890409557\n",
      "0.19805384063557854\n",
      "Epoch: 12\n",
      "Train:  0.2035479302425961\n",
      "Test 0.15902968999612463\n",
      "0.18979497454261485\n",
      "Epoch: 13\n",
      "Train:  0.2206227650777215\n",
      "Test 0.13083393218834977\n",
      "0.17746028049034043\n",
      "Epoch: 14\n",
      "Train:  0.19209140657546211\n",
      "Test 0.1468462114505497\n",
      "0.17111418323524716\n",
      "Epoch: 15\n",
      "Train:  0.21383539806273613\n",
      "Test 0.16151485201943624\n",
      "0.1691387124322586\n",
      "Epoch: 16\n",
      "Train:  0.2137842812125943\n",
      "Test 0.12568284076512296\n",
      "0.16024732178070578\n",
      "Epoch: 17\n",
      "Train:  0.18053304844436954\n",
      "Test 0.12968402142865043\n",
      "0.15402252575402994\n",
      "Epoch: 18\n",
      "Train:  0.20639907392577675\n",
      "Test 0.13412301671851576\n",
      "0.14998442883726426\n",
      "Epoch: 19\n",
      "Train:  0.1789838598253062\n",
      "Test 0.12400065878262886\n",
      "0.14472706150781986\n",
      "Epoch: 20\n",
      "Train:  0.15740846993995236\n",
      "Test 0.13019413816241118\n",
      "0.1417934187602541\n",
      "Epoch: 21\n",
      "Train:  0.15443318170382753\n",
      "Test 0.12186476424500182\n",
      "0.13777805973709795\n",
      "Epoch: 22\n",
      "Train:  0.1500079454956474\n",
      "Test 0.12875632562200393\n",
      "0.13596299868473155\n",
      "Epoch: 23\n",
      "Train:  0.14052484476437363\n",
      "Test 0.12483699423271222\n",
      "0.1337272397211342\n",
      "Epoch: 24\n",
      "Train:  0.1342423507848229\n",
      "Test 0.12510637301762312\n",
      "0.13199652793617217\n",
      "Epoch: 25\n",
      "Train:  0.12920325015430192\n",
      "Test 0.12227990730723619\n",
      "0.13004731266872294\n",
      "Epoch: 26\n",
      "Train:  0.1208913047736572\n",
      "Test 0.12609541315189648\n",
      "0.12925501711224768\n",
      "Epoch: 27\n",
      "Train:  0.11786012303752777\n",
      "Test 0.13332410484224885\n",
      "0.13007041186107196\n",
      "Epoch: 28\n",
      "Train:  0.11282192217697809\n",
      "Test 0.13840513264900245\n",
      "0.1317399394875274\n",
      "Epoch: 29\n",
      "Train:  0.11047305587309007\n",
      "Test 0.13090724866468828\n",
      "0.13157319490316227\n",
      "Epoch: 30\n",
      "Train:  0.09984973218332935\n",
      "Test 0.13580971288805208\n",
      "0.1324213384608355\n",
      "Epoch: 31\n",
      "Train:  0.09953544161200606\n",
      "Test 0.14392745466309048\n",
      "0.1347243863638219\n",
      "Epoch: 32\n",
      "Train:  0.09770393232200802\n",
      "Test 0.14924034732564492\n",
      "0.1376294198399013\n",
      "Epoch: 33\n",
      "Train:  0.09958110242995055\n",
      "Test 0.14766882813020504\n",
      "0.1396383201314262\n",
      "Epoch: 34\n",
      "Train:  0.10785159491507453\n",
      "Test 0.17150053693043008\n",
      "0.14601334951036898\n",
      "Epoch: 35\n",
      "Train:  0.11803208101001797\n",
      "Test 0.1576962158425699\n",
      "0.14835068128433587\n",
      "Epoch: 36\n",
      "Train:  0.11512456613457625\n",
      "Test 0.14276895809009493\n",
      "0.1472340467505886\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:41:35,844]\u001b[0m Trial 5 finished with value: 0.14605211950398053 and parameters: {'layer_size1': 256, 'layer_size2': 256, 'layer_size3': 512, 'layer_size4': 192, 'layer_size5': 256, 'learning_rate': 6.0083509296563365e-05, 'b1': 0.9616149914929458}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.09535929684976249\n",
      "Test 0.1414773070932308\n",
      "0.14608245964383237\n",
      "Epoch: 0\n",
      "Train:  0.6758082124776456\n",
      "Test 0.5825934069497245\n",
      "0.5825934069497245\n",
      "Epoch: 1\n",
      "Train:  0.6614895062896359\n",
      "Test 0.31280786380335523\n",
      "0.4327125496461861\n",
      "Epoch: 2\n",
      "Train:  0.37230666943795077\n",
      "Test 0.1685769310282482\n",
      "0.32446024693391645\n",
      "Epoch: 3\n",
      "Train:  0.281808405630154\n",
      "Test 0.16885979316664704\n",
      "0.27175006611844577\n",
      "Epoch: 4\n",
      "Train:  0.26760914680913034\n",
      "Test 0.17642519659884684\n",
      "0.24339307256787496\n",
      "Epoch: 5\n",
      "Train:  0.2526918781013825\n",
      "Test 0.15190921908060273\n",
      "0.21859586186896568\n",
      "Epoch: 6\n",
      "Train:  0.2318071618389625\n",
      "Test 0.14762394485019503\n",
      "0.20063476302997224\n",
      "Epoch: 7\n",
      "Train:  0.2223458322713445\n",
      "Test 0.14655053047906785\n",
      "0.18763730489377134\n",
      "Epoch: 8\n",
      "Train:  0.21195014487037728\n",
      "Test 0.14004740737132973\n",
      "0.1766438024713883\n",
      "Epoch: 9\n",
      "Train:  0.18586704375788624\n",
      "Test 0.1306644034855095\n",
      "0.16634174799810328\n",
      "Epoch: 10\n",
      "Train:  0.16070657784985753\n",
      "Test 0.12797315151263505\n",
      "0.15794691832279045\n",
      "Epoch: 11\n",
      "Train:  0.13926563083088442\n",
      "Test 0.13920119367949255\n",
      "0.15392112283474632\n",
      "Epoch: 12\n",
      "Train:  0.1375337822546998\n",
      "Test 0.14869637629307206\n",
      "0.15281538494294614\n",
      "Epoch: 13\n",
      "Train:  0.17211622536146584\n",
      "Test 0.16504288262145206\n",
      "0.15537338658041816\n",
      "Epoch: 14\n",
      "Train:  0.16946323412801428\n",
      "Test 0.18043106635640146\n",
      "0.1605676805058251\n",
      "Epoch: 15\n",
      "Train:  0.15733581036968913\n",
      "Test 0.13473092104588044\n",
      "0.15525066801719542\n",
      "Epoch: 16\n",
      "Train:  0.11368622422267789\n",
      "Test 0.15448204172099686\n",
      "0.1550934014292207\n",
      "Epoch: 17\n",
      "Train:  0.11254993953781318\n",
      "Test 0.1758355066142277\n",
      "0.15931792471215347\n",
      "Epoch: 18\n",
      "Train:  0.11880043225613211\n",
      "Test 0.204029166739489\n",
      "0.16839092888794122\n",
      "Epoch: 19\n",
      "Train:  0.11974511631085276\n",
      "Test 0.19084793837031439\n",
      "0.17293471709578792\n",
      "Epoch: 20\n",
      "Train:  0.13944056208960579\n",
      "Test 0.23129188712607837\n",
      "0.18471480321878456\n",
      "Epoch: 21\n",
      "Train:  0.1450450407770111\n",
      "Test 0.19039490830746816\n",
      "0.1858592689027506\n",
      "Epoch: 22\n",
      "Train:  0.11816673853687068\n",
      "Test 0.20512100310839249\n",
      "0.1897344910176654\n",
      "Epoch: 23\n",
      "Train:  0.11060066409171311\n",
      "Test 0.25876762837360595\n",
      "0.2036066278026527\n",
      "Epoch: 24\n",
      "Train:  0.13250199846424282\n",
      "Test 0.27715844475244594\n",
      "0.21837277612374142\n",
      "Epoch: 25\n",
      "Train:  0.13906105657761578\n",
      "Test 0.2851457301399972\n",
      "0.23176785105684836\n",
      "Epoch: 26\n",
      "Train:  0.14279721794536848\n",
      "Test 0.30641941015431523\n",
      "0.24673434964949748\n",
      "Epoch: 27\n",
      "Train:  0.15337554548721097\n",
      "Test 0.316326086472928\n",
      "0.2606796711890187\n",
      "Epoch: 28\n",
      "Train:  0.1582539802284756\n",
      "Test 0.3222549034468142\n",
      "0.2730138037863179\n",
      "Epoch: 29\n",
      "Train:  0.1611803300621397\n",
      "Test 0.3391774782843231\n",
      "0.28626294032252303\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:41:54,042]\u001b[0m Trial 6 finished with value: 0.29661349438175905 and parameters: {'layer_size1': 256, 'layer_size2': 256, 'layer_size3': 256, 'layer_size4': 128, 'layer_size5': 64, 'learning_rate': 0.00039282631085194096, 'b1': 0.9519435038364575}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.16963604850916705\n",
      "Test 0.3394332160410583\n",
      "0.2969075373645344\n",
      "Epoch: 0\n",
      "Train:  0.6949165079183194\n",
      "Test 0.6924862538501894\n",
      "0.6924862538501892\n",
      "Epoch: 1\n",
      "Train:  1.0406516777290094\n",
      "Test 0.6922064731409262\n",
      "0.6923308201228211\n",
      "Epoch: 2\n",
      "Train:  1.0400087326874226\n",
      "Test 0.6919167779740834\n",
      "0.6921611307176008\n",
      "Epoch: 3\n",
      "Train:  1.0393607055311238\n",
      "Test 0.6916262317489792\n",
      "0.6919799318799918\n",
      "Epoch: 4\n",
      "Train:  1.0387649509932968\n",
      "Test 0.6913070418895819\n",
      "0.6917797623207314\n",
      "Epoch: 5\n",
      "Train:  1.0381040272913573\n",
      "Test 0.6909478841683804\n",
      "0.6915542770899138\n",
      "Epoch: 6\n",
      "Train:  1.037411710936508\n",
      "Test 0.6905538865498134\n",
      "0.6913011049322054\n",
      "Epoch: 7\n",
      "Train:  1.0365050238567395\n",
      "Test 0.6900933531177786\n",
      "0.6910108594594206\n",
      "Epoch: 8\n",
      "Train:  1.0356096893876463\n",
      "Test 0.6895916614777002\n",
      "0.6906830176849658\n",
      "Epoch: 9\n",
      "Train:  1.0346415213176183\n",
      "Test 0.6889900375198532\n",
      "0.6903036918506169\n",
      "Epoch: 10\n",
      "Train:  1.033696724381639\n",
      "Test 0.6883029313314528\n",
      "0.6898659368812414\n",
      "Epoch: 11\n",
      "Train:  1.0324441917213327\n",
      "Test 0.6874970935639881\n",
      "0.6893572086821482\n",
      "Epoch: 12\n",
      "Train:  1.0310947801167274\n",
      "Test 0.6866027555622898\n",
      "0.6887742707039093\n",
      "Epoch: 13\n",
      "Train:  1.0294637777211466\n",
      "Test 0.6855101190207206\n",
      "0.6880914077363511\n",
      "Epoch: 14\n",
      "Train:  1.0276394181854123\n",
      "Test 0.6843000698438931\n",
      "0.6873054880678096\n",
      "Epoch: 15\n",
      "Train:  1.0257344831040491\n",
      "Test 0.6828937078570272\n",
      "0.6863975765894298\n",
      "Epoch: 16\n",
      "Train:  1.0234056221041488\n",
      "Test 0.6814169610812987\n",
      "0.6853785060595096\n",
      "Epoch: 17\n",
      "Train:  1.0208451054690084\n",
      "Test 0.679618565590827\n",
      "0.6842053848935903\n",
      "Epoch: 18\n",
      "Train:  1.0179529731526917\n",
      "Test 0.6774848647170014\n",
      "0.6828416270362626\n",
      "Epoch: 19\n",
      "Train:  1.014570571782388\n",
      "Test 0.6748910958950336\n",
      "0.6812329743047406\n",
      "Epoch: 20\n",
      "Train:  1.0105112112048782\n",
      "Test 0.6720067291032701\n",
      "0.6793705474082891\n",
      "Epoch: 21\n",
      "Train:  1.0058898767490527\n",
      "Test 0.6685577914828346\n",
      "0.6771919207961798\n",
      "Epoch: 22\n",
      "Train:  1.0004374107598386\n",
      "Test 0.6643458639745747\n",
      "0.674607453429272\n",
      "Epoch: 23\n",
      "Train:  0.99413936151253\n",
      "Test 0.6596802112820385\n",
      "0.6716078397246047\n",
      "Epoch: 24\n",
      "Train:  0.9869829840930827\n",
      "Test 0.6542623763556009\n",
      "0.6681255914889213\n",
      "Epoch: 25\n",
      "Train:  0.9787349777343946\n",
      "Test 0.6478099779331641\n",
      "0.6640501515162467\n",
      "Epoch: 26\n",
      "Train:  0.9689976374308268\n",
      "Test 0.6403682996065189\n",
      "0.6593023015374471\n",
      "Epoch: 27\n",
      "Train:  0.9578343889652154\n",
      "Test 0.6317351366574074\n",
      "0.6537781833628923\n",
      "Epoch: 28\n",
      "Train:  0.9451119570068387\n",
      "Test 0.6219716390847286\n",
      "0.6474070156026753\n",
      "Epoch: 29\n",
      "Train:  0.9305943327072339\n",
      "Test 0.6108056119073442\n",
      "0.640077661562781\n",
      "Epoch: 30\n",
      "Train:  0.9136512602641905\n",
      "Test 0.5971858789632608\n",
      "0.6314908010281028\n",
      "Epoch: 31\n",
      "Train:  0.8942706429914677\n",
      "Test 0.5828358744963621\n",
      "0.6217520999278202\n",
      "Epoch: 32\n",
      "Train:  0.8729144145935883\n",
      "Test 0.5653763031348203\n",
      "0.6104697895554626\n",
      "Epoch: 33\n",
      "Train:  0.8478645853725545\n",
      "Test 0.5462409222955669\n",
      "0.5976174992180593\n",
      "Epoch: 34\n",
      "Train:  0.8203071091637943\n",
      "Test 0.5247919050765125\n",
      "0.5830464696779604\n",
      "Epoch: 35\n",
      "Train:  0.7905277172069409\n",
      "Test 0.5030991280035222\n",
      "0.5670518107795006\n",
      "Epoch: 36\n",
      "Train:  0.760115636137379\n",
      "Test 0.48044873233679886\n",
      "0.5497266972343287\n",
      "Epoch: 37\n",
      "Train:  0.729528145530285\n",
      "Test 0.4584127992064088\n",
      "0.5314601238098724\n",
      "Epoch: 38\n",
      "Train:  0.6993098964184632\n",
      "Test 0.4364258723381238\n",
      "0.5124501149360232\n",
      "Epoch: 39\n",
      "Train:  0.6698475750811371\n",
      "Test 0.4157931399651063\n",
      "0.49311615001709586\n",
      "Epoch: 40\n",
      "Train:  0.6416801275896938\n",
      "Test 0.3959784837432833\n",
      "0.4736865506529397\n",
      "Epoch: 41\n",
      "Train:  0.6154368604932513\n",
      "Test 0.377561975311447\n",
      "0.45445999997059766\n",
      "Epoch: 42\n",
      "Train:  0.5917013778791322\n",
      "Test 0.36165622084132043\n",
      "0.43589798087918397\n",
      "Epoch: 43\n",
      "Train:  0.5717847334159599\n",
      "Test 0.3487870264730174\n",
      "0.41847484139200763\n",
      "Epoch: 44\n",
      "Train:  0.5543806655230102\n",
      "Test 0.33676006298362116\n",
      "0.40213117384320995\n",
      "Epoch: 45\n",
      "Train:  0.5386742182594516\n",
      "Test 0.3260985220963265\n",
      "0.3869241136051214\n",
      "Epoch: 46\n",
      "Train:  0.5243140212891303\n",
      "Test 0.3160787646150414\n",
      "0.3727546488200757\n",
      "Epoch: 47\n",
      "Train:  0.5114802048974858\n",
      "Test 0.3069687362337287\n",
      "0.3595971728812879\n",
      "Epoch: 48\n",
      "Train:  0.4990296905839836\n",
      "Test 0.29873592125408815\n",
      "0.3474247053917712\n",
      "Epoch: 49\n",
      "Train:  0.4886365957803779\n",
      "Test 0.2912698847688598\n",
      "0.33619358097122476\n",
      "Epoch: 50\n",
      "Train:  0.4777898404187772\n",
      "Test 0.2842802132442321\n",
      "0.32581078887529774\n",
      "Epoch: 51\n",
      "Train:  0.4683158339270742\n",
      "Test 0.27769557121909144\n",
      "0.31618765744266686\n",
      "Epoch: 52\n",
      "Train:  0.4596001725821268\n",
      "Test 0.27261688115395905\n",
      "0.307473438505699\n",
      "Epoch: 53\n",
      "Train:  0.4504990986524484\n",
      "Test 0.2661282667965243\n",
      "0.29920435582275257\n",
      "Epoch: 54\n",
      "Train:  0.4416321559976309\n",
      "Test 0.26066434383392334\n",
      "0.2914963173759921\n",
      "Epoch: 55\n",
      "Train:  0.4335576817666218\n",
      "Test 0.2551442020651185\n",
      "0.28422586711183345\n",
      "Epoch: 56\n",
      "Train:  0.42503385963566576\n",
      "Test 0.25050820792332673\n",
      "0.2774823150896333\n",
      "Epoch: 57\n",
      "Train:  0.41816181061796215\n",
      "Test 0.24593756399748526\n",
      "0.271173349764233\n",
      "Epoch: 58\n",
      "Train:  0.41317942350993664\n",
      "Test 0.2408206494518252\n",
      "0.26510279807288467\n",
      "Epoch: 59\n",
      "Train:  0.4022581846395255\n",
      "Test 0.23648587521506753\n",
      "0.25937940473024645\n",
      "Epoch: 60\n",
      "Train:  0.3960348702148422\n",
      "Test 0.2319071739366203\n",
      "0.25388495183534154\n",
      "Epoch: 61\n",
      "Train:  0.3882129906980328\n",
      "Test 0.22789294471889188\n",
      "0.24868654531346934\n",
      "Epoch: 62\n",
      "Train:  0.381091456137079\n",
      "Test 0.22432115182771786\n",
      "0.2438134627927147\n",
      "Epoch: 63\n",
      "Train:  0.3750381002496014\n",
      "Test 0.2191843175407731\n",
      "0.23888763065033142\n",
      "Epoch: 64\n",
      "Train:  0.366962785303811\n",
      "Test 0.21578601291983118\n",
      "0.23426730478405094\n",
      "Epoch: 65\n",
      "Train:  0.3599521300240314\n",
      "Test 0.2113104495373401\n",
      "0.22967593189019583\n",
      "Epoch: 66\n",
      "Train:  0.3534495437538231\n",
      "Test 0.20749948246083855\n",
      "0.22524064057887672\n",
      "Epoch: 67\n",
      "Train:  0.3470870242164139\n",
      "Test 0.2041656263036169\n",
      "0.22102563664010477\n",
      "Epoch: 68\n",
      "Train:  0.34075784298417333\n",
      "Test 0.19975755658451017\n",
      "0.2167720197540676\n",
      "Epoch: 69\n",
      "Train:  0.3344792619265698\n",
      "Test 0.1964636826376011\n",
      "0.21271035166242494\n",
      "Epoch: 70\n",
      "Train:  0.3277098367454641\n",
      "Test 0.19326285755896305\n",
      "0.20882085232971748\n",
      "Epoch: 71\n",
      "Train:  0.3221519159037115\n",
      "Test 0.1898161374823951\n",
      "0.20501990895996694\n",
      "Epoch: 72\n",
      "Train:  0.31608378128472703\n",
      "Test 0.18641902869328475\n",
      "0.20129973259320627\n",
      "Epoch: 73\n",
      "Train:  0.310620019055439\n",
      "Test 0.1843141386142144\n",
      "0.19790261356844252\n",
      "Epoch: 74\n",
      "Train:  0.30548248562839003\n",
      "Test 0.1811916839617949\n",
      "0.19456042746690266\n",
      "Epoch: 75\n",
      "Train:  0.300964746092047\n",
      "Test 0.17922400579456882\n",
      "0.19149314300012577\n",
      "Epoch: 76\n",
      "Train:  0.2966658791916056\n",
      "Test 0.17651124806194515\n",
      "0.18849676390908843\n",
      "Epoch: 77\n",
      "Train:  0.29220280580686564\n",
      "Test 0.17472702526784206\n",
      "0.18574281610481097\n",
      "Epoch: 78\n",
      "Train:  0.28840402292681266\n",
      "Test 0.17303114791056176\n",
      "0.18320048240981218\n",
      "Epoch: 79\n",
      "Train:  0.2859204174070568\n",
      "Test 0.17080827545879523\n",
      "0.1807220409758185\n",
      "Epoch: 80\n",
      "Train:  0.2815011205499644\n",
      "Test 0.1688206319802956\n",
      "0.17834175914306918\n",
      "Epoch: 81\n",
      "Train:  0.278625502285203\n",
      "Test 0.167283561421838\n",
      "0.1761301195738141\n",
      "Epoch: 82\n",
      "Train:  0.27540816628670955\n",
      "Test 0.1660534217953682\n",
      "0.17411477999989364\n",
      "Epoch: 83\n",
      "Train:  0.27257284594379066\n",
      "Test 0.1646084530012948\n",
      "0.1722135145864144\n",
      "Epoch: 84\n",
      "Train:  0.27027044865565425\n",
      "Test 0.16329310337702432\n",
      "0.17042943233420724\n",
      "Epoch: 85\n",
      "Train:  0.2686019764169232\n",
      "Test 0.1619738145516469\n",
      "0.16873830876986243\n",
      "Epoch: 86\n",
      "Train:  0.26521749819045537\n",
      "Test 0.16075169988276758\n",
      "0.1671409869865248\n",
      "Epoch: 87\n",
      "Train:  0.26389444672635626\n",
      "Test 0.16128139541699335\n",
      "0.1659690686691446\n",
      "Epoch: 88\n",
      "Train:  0.2644498381531719\n",
      "Test 0.16162862574115341\n",
      "0.16510098008148774\n",
      "Epoch: 89\n",
      "Train:  0.2614198066021278\n",
      "Test 0.15915760291474207\n",
      "0.16391230464588355\n",
      "Epoch: 90\n",
      "Train:  0.2584338382077523\n",
      "Test 0.15744547682367402\n",
      "0.1626189390794787\n",
      "Epoch: 91\n",
      "Train:  0.25646675015789466\n",
      "Test 0.1567161935808021\n",
      "0.16143838997830998\n",
      "Epoch: 92\n",
      "Train:  0.254714697599411\n",
      "Test 0.15642551123249882\n",
      "0.1604358142281739\n",
      "Epoch: 93\n",
      "Train:  0.25393424169825657\n",
      "Test 0.15546046967034813\n",
      "0.1594407453158355\n",
      "Epoch: 94\n",
      "Train:  0.2533220235435736\n",
      "Test 0.15727880215033507\n",
      "0.1590083566824666\n",
      "Epoch: 95\n",
      "Train:  0.25192348669955145\n",
      "Test 0.15489240282730304\n",
      "0.1581851659110245\n",
      "Epoch: 96\n",
      "Train:  0.24923490409503926\n",
      "Test 0.15517478537210178\n",
      "0.1575830898030004\n",
      "Epoch: 97\n",
      "Train:  0.2491154746039883\n",
      "Test 0.15349687955209187\n",
      "0.15676584775255856\n",
      "Epoch: 98\n",
      "Train:  0.24666878193507702\n",
      "Test 0.15396500436841568\n",
      "0.15620567907558736\n",
      "Epoch: 99\n",
      "Train:  0.24715983876173858\n",
      "Test 0.15260958924016235\n",
      "0.15548646110835587\n",
      "Epoch: 100\n",
      "Train:  0.24472009085780588\n",
      "Test 0.1524156201016772\n",
      "0.15487229290692003\n",
      "Epoch: 101\n",
      "Train:  0.2436510869148341\n",
      "Test 0.1520135434883418\n",
      "0.15430054302312987\n",
      "Epoch: 102\n",
      "Train:  0.24315800616046884\n",
      "Test 0.15178506324688593\n",
      "0.1537974470678286\n",
      "Epoch: 103\n",
      "Train:  0.24197624079309976\n",
      "Test 0.15215726375525251\n",
      "0.15346941040528603\n",
      "Epoch: 104\n",
      "Train:  0.24196931910138209\n",
      "Test 0.15103198773476667\n",
      "0.1529819258711496\n",
      "Epoch: 105\n",
      "Train:  0.23998697803461508\n",
      "Test 0.15055577394180683\n",
      "0.15249669548525516\n",
      "Epoch: 106\n",
      "Train:  0.23901105934119488\n",
      "Test 0.1505399037138883\n",
      "0.15210533713096505\n",
      "Epoch: 107\n",
      "Train:  0.2381583227479196\n",
      "Test 0.14978463231371\n",
      "0.15164119616749822\n",
      "Epoch: 108\n",
      "Train:  0.2374332847189663\n",
      "Test 0.14941865602856155\n",
      "0.15119668813969875\n",
      "Epoch: 109\n",
      "Train:  0.2367121560546832\n",
      "Test 0.14875832210966955\n",
      "0.15070901493368224\n",
      "Epoch: 110\n",
      "Train:  0.23489832572447947\n",
      "Test 0.15043331071352348\n",
      "0.15065387408964953\n",
      "Epoch: 111\n",
      "Train:  0.2384054881721844\n",
      "Test 0.1486928542536912\n",
      "0.15026167012245237\n",
      "Epoch: 112\n",
      "Train:  0.23405202922339624\n",
      "Test 0.1503582139782635\n",
      "0.1502809788936148\n",
      "Epoch: 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:43:07,857]\u001b[0m Trial 7 finished with value: 0.1498634347382495 and parameters: {'layer_size1': 384, 'layer_size2': 384, 'layer_size3': 512, 'layer_size4': 256, 'layer_size5': 64, 'learning_rate': 3.586319317239496e-06, 'b1': 0.9103745514875704}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.2343974109848231\n",
      "Test 0.1481932581235201\n",
      "0.14986343473959213\n",
      "Epoch: 0\n",
      "Train:  0.6930742501775861\n",
      "Test 0.6896744735075004\n",
      "0.6896744735075004\n",
      "Epoch: 1\n",
      "Train:  1.0273273626526633\n",
      "Test 0.6661848144216852\n",
      "0.6766246629042699\n",
      "Epoch: 2\n",
      "Train:  0.9409730175694266\n",
      "Test 0.4874888197842972\n",
      "0.5991099731010023\n",
      "Epoch: 3\n",
      "Train:  0.6522844784207397\n",
      "Test 0.27653144894938764\n",
      "0.4898354052989648\n",
      "Epoch: 4\n",
      "Train:  0.5112483288560595\n",
      "Test 0.2612767465439908\n",
      "0.42184437163791827\n",
      "Epoch: 5\n",
      "Train:  0.4367737493481173\n",
      "Test 0.24123484158253933\n",
      "0.3728891472972939\n",
      "Epoch: 6\n",
      "Train:  0.3792419612626016\n",
      "Test 0.2058454757563142\n",
      "0.33061485034992\n",
      "Epoch: 7\n",
      "Train:  0.3252627412983022\n",
      "Test 0.21567133568472915\n",
      "0.30299176226260227\n",
      "Epoch: 8\n",
      "Train:  0.2855387648137716\n",
      "Test 0.15533406871469904\n",
      "0.2688821025194415\n",
      "Epoch: 9\n",
      "Train:  0.23454200106608125\n",
      "Test 0.15142493229700532\n",
      "0.24256487801024168\n",
      "Epoch: 10\n",
      "Train:  0.23007809619791122\n",
      "Test 0.14908773951478058\n",
      "0.22211261422982867\n",
      "Epoch: 11\n",
      "Train:  0.2220905682433656\n",
      "Test 0.16275918538317138\n",
      "0.20936598690026048\n",
      "Epoch: 12\n",
      "Train:  0.23267238769994114\n",
      "Test 0.1468486113971843\n",
      "0.19613513820008588\n",
      "Epoch: 13\n",
      "Train:  0.2056965587230829\n",
      "Test 0.14536874625497523\n",
      "0.18551477112756432\n",
      "Epoch: 14\n",
      "Train:  0.19958646001290845\n",
      "Test 0.1618844917787737\n",
      "0.18061636802023692\n",
      "Epoch: 15\n",
      "Train:  0.20568899396847892\n",
      "Test 0.1441680058673188\n",
      "0.17311556680491383\n",
      "Epoch: 16\n",
      "Train:  0.18568709132435557\n",
      "Test 0.1517991747522911\n",
      "0.16875407636069242\n",
      "Epoch: 17\n",
      "Train:  0.18946133855382327\n",
      "Test 0.15545904735826474\n",
      "0.166046291443633\n",
      "Epoch: 18\n",
      "Train:  0.1795169217059996\n",
      "Test 0.14084952737412829\n",
      "0.1609332519651236\n",
      "Epoch: 19\n",
      "Train:  0.16510150103655818\n",
      "Test 0.14356458345393994\n",
      "0.15741900171603948\n",
      "Epoch: 20\n",
      "Train:  0.15747608047152695\n",
      "Test 0.17411319851438642\n",
      "0.16078892311450182\n",
      "Epoch: 21\n",
      "Train:  0.17345154431781598\n",
      "Test 0.1486905736800952\n",
      "0.15835126649651182\n",
      "Epoch: 22\n",
      "Train:  0.15007176269323397\n",
      "Test 0.16023957099247\n",
      "0.15873116994987205\n",
      "Epoch: 23\n",
      "Train:  0.14685206737662682\n",
      "Test 0.15449144694810876\n",
      "0.15787920204484018\n",
      "Epoch: 24\n",
      "Train:  0.13520256269317216\n",
      "Test 0.16650678550111533\n",
      "0.15961126227463562\n",
      "Epoch: 25\n",
      "Train:  0.13951892266433769\n",
      "Test 0.194594478342109\n",
      "0.1666291156484851\n",
      "Epoch: 26\n",
      "Train:  0.17635439025773753\n",
      "Test 0.21139516203831404\n",
      "0.1756040249255584\n",
      "Epoch: 27\n",
      "Train:  0.1537977481131261\n",
      "Test 0.16649296266050675\n",
      "0.17377828097013573\n",
      "Epoch: 28\n",
      "Train:  0.12238501210359264\n",
      "Test 0.21620663988229993\n",
      "0.18227710404428143\n",
      "Epoch: 29\n",
      "Train:  0.15345539074841436\n",
      "Test 0.17632552893446835\n",
      "0.1810853136572803\n",
      "Epoch: 30\n",
      "Train:  0.1291493276725165\n",
      "Test 0.17376050189301206\n",
      "0.17961889903772926\n",
      "Epoch: 31\n",
      "Train:  0.11871365564892362\n",
      "Test 0.18372364602846541\n",
      "0.18044049937472673\n",
      "Epoch: 32\n",
      "Train:  0.1256469171443074\n",
      "Test 0.18488195969961113\n",
      "0.1813293548187722\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:43:30,932]\u001b[0m Trial 8 finished with value: 0.18173638064955783 and parameters: {'layer_size1': 256, 'layer_size2': 512, 'layer_size3': 256, 'layer_size4': 64, 'layer_size5': 128, 'learning_rate': 9.864171820940007e-05, 'b1': 0.9508020373822809}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.11423207180957896\n",
      "Test 0.18382420850365044\n",
      "0.18182857869232502\n",
      "Epoch: 0\n",
      "Train:  0.674140507921631\n",
      "Test 0.5661038439789098\n",
      "0.5661038439789098\n",
      "Epoch: 1\n",
      "Train:  0.6021135962353303\n",
      "Test 0.15995218473803866\n",
      "0.340464033289537\n",
      "Epoch: 2\n",
      "Train:  0.2705552641698074\n",
      "Test 0.15792497179228746\n",
      "0.2656529425119757\n",
      "Epoch: 3\n",
      "Train:  0.24546779024895732\n",
      "Test 0.15633827229559202\n",
      "0.22862222766902726\n",
      "Epoch: 4\n",
      "Train:  0.2340414576955658\n",
      "Test 0.18121500673529867\n",
      "0.21451965123705183\n",
      "Epoch: 5\n",
      "Train:  0.2184967277213358\n",
      "Test 0.1311828074533315\n",
      "0.19193073313278208\n",
      "Epoch: 6\n",
      "Train:  0.1699961045357798\n",
      "Test 0.13653059739060017\n",
      "0.17791043671757029\n",
      "Epoch: 7\n",
      "Train:  0.15994472559132092\n",
      "Test 0.12345997823040673\n",
      "0.16482496760200607\n",
      "Epoch: 8\n",
      "Train:  0.14912878895424062\n",
      "Test 0.12299066276635784\n",
      "0.1551610356439148\n",
      "Epoch: 9\n",
      "Train:  0.13119599198340012\n",
      "Test 0.13054720365063666\n",
      "0.1496461084464342\n",
      "Epoch: 10\n",
      "Train:  0.13036078289867595\n",
      "Test 0.14401452677945295\n",
      "0.14841395055619636\n",
      "Epoch: 11\n",
      "Train:  0.10894416060789928\n",
      "Test 0.13834289258393723\n",
      "0.1462511096676182\n",
      "Epoch: 12\n",
      "Train:  0.08859506084591376\n",
      "Test 0.18142852108565674\n",
      "0.15369587209391297\n",
      "Epoch: 13\n",
      "Train:  0.182068932754791\n",
      "Test 0.1285908761035119\n",
      "0.14844388820148824\n",
      "Epoch: 14\n",
      "Train:  0.1109231104221427\n",
      "Test 0.1314105687342284\n",
      "0.14491299194017104\n",
      "Epoch: 15\n",
      "Train:  0.07928059733666364\n",
      "Test 0.15869763124753458\n",
      "0.14774976794770925\n",
      "Epoch: 16\n",
      "Train:  0.08343156813065261\n",
      "Test 0.2063698378845934\n",
      "0.15974386498993617\n",
      "Epoch: 17\n",
      "Train:  0.10506430141381144\n",
      "Test 0.2062084572321493\n",
      "0.16920726082215334\n",
      "Epoch: 18\n",
      "Train:  0.11558494727628735\n",
      "Test 0.17664502277260735\n",
      "0.17071656457161588\n",
      "Epoch: 19\n",
      "Train:  0.09244943675482872\n",
      "Test 0.2373915547232106\n",
      "0.18420709786131795\n",
      "Epoch: 20\n",
      "Train:  0.11896711860662679\n",
      "Test 0.26611543889722494\n",
      "0.200741266860499\n",
      "Epoch: 21\n",
      "Train:  0.13317245663156158\n",
      "Test 0.2820305842381122\n",
      "0.2171199839368872\n",
      "Epoch: 22\n",
      "Train:  0.1410782616496202\n",
      "Test 0.2873992278580864\n",
      "0.231259296490746\n",
      "Epoch: 23\n",
      "Train:  0.14374085783755652\n",
      "Test 0.29194207991028553\n",
      "0.24345343838160666\n",
      "Epoch: 24\n",
      "Train:  0.14599817239399027\n",
      "Test 0.29676630942893495\n",
      "0.2541564474159761\n",
      "Epoch: 25\n",
      "Train:  0.14840411950338273\n",
      "Test 0.30284605477398613\n",
      "0.2639238891688948\n",
      "Epoch: 26\n",
      "Train:  0.15143941194105015\n",
      "Test 0.3071366619350044\n",
      "0.27258739078369754\n",
      "Epoch: 27\n",
      "Train:  0.1535808479590244\n",
      "Test 0.31202509653100036\n",
      "0.2804902182245841\n",
      "Epoch: 28\n",
      "Train:  0.15602247726038324\n",
      "Test 0.4692625891410927\n",
      "0.31830320517106836\n",
      "Epoch: 29\n",
      "Train:  0.2346392922903077\n",
      "Test 0.47370960437635384\n",
      "0.3494230094638742\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:43:51,502]\u001b[0m Trial 9 finished with value: 0.37468602195559353 and parameters: {'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 512, 'layer_size4': 256, 'layer_size5': 256, 'learning_rate': 0.0002709964788220436, 'b1': 0.9348731890512867}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.23686109014228085\n",
      "Test 0.4774683308587222\n",
      "0.3750574608738723\n",
      "Epoch: 0\n",
      "Train:  0.6931732949756441\n",
      "Test 0.6930671548232054\n",
      "0.6930671548232054\n",
      "Epoch: 1\n",
      "Train:  1.0395864740614489\n",
      "Test 0.6930024807269757\n",
      "0.6930312247697445\n",
      "Epoch: 2\n",
      "Train:  1.0394632122018834\n",
      "Test 0.692945278607882\n",
      "0.6929960009329156\n",
      "Epoch: 3\n",
      "Train:  1.03931894778332\n",
      "Test 0.6928898163767525\n",
      "0.6929600305548115\n",
      "Epoch: 4\n",
      "Train:  1.0391804900143173\n",
      "Test 0.6928339751212151\n",
      "0.6929225319132133\n",
      "Epoch: 5\n",
      "Train:  1.0390482206484337\n",
      "Test 0.6927783078763075\n",
      "0.6928834391805107\n",
      "Epoch: 6\n",
      "Train:  1.0389284640004783\n",
      "Test 0.6927211568469093\n",
      "0.6928423698511749\n",
      "Epoch: 7\n",
      "Train:  1.0388123085210612\n",
      "Test 0.6926609530990377\n",
      "0.6927987719940935\n",
      "Epoch: 8\n",
      "Train:  1.0386998921960264\n",
      "Test 0.6926012410349025\n",
      "0.6927531413625643\n",
      "Epoch: 9\n",
      "Train:  1.038576983925187\n",
      "Test 0.6925403536894382\n",
      "0.6927054645714765\n",
      "Epoch: 10\n",
      "Train:  1.038455884426068\n",
      "Test 0.6924758025141426\n",
      "0.6926552158256062\n",
      "Epoch: 11\n",
      "Train:  1.038322606693694\n",
      "Test 0.6924064818756047\n",
      "0.6926017982046451\n",
      "Epoch: 12\n",
      "Train:  1.038200325363285\n",
      "Test 0.6923376120927133\n",
      "0.6925458872447314\n",
      "Epoch: 13\n",
      "Train:  1.0380782382392184\n",
      "Test 0.6922686984250833\n",
      "0.6924878991368462\n",
      "Epoch: 14\n",
      "Train:  1.037949847323554\n",
      "Test 0.6922018113153758\n",
      "0.6924285949935064\n",
      "Epoch: 15\n",
      "Train:  1.0378159216908744\n",
      "Test 0.6921348178779686\n",
      "0.6923681378531824\n",
      "Epoch: 16\n",
      "Train:  1.0376774539877645\n",
      "Test 0.6920652673358009\n",
      "0.6923061683198704\n",
      "Epoch: 17\n",
      "Train:  1.037560420158582\n",
      "Test 0.6919936535559295\n",
      "0.6922425187585192\n",
      "Epoch: 18\n",
      "Train:  1.0374346742263207\n",
      "Test 0.691919785279494\n",
      "0.692177028244946\n",
      "Epoch: 19\n",
      "Train:  1.0372847667980543\n",
      "Test 0.691845701291011\n",
      "0.6921099899553014\n",
      "Epoch: 20\n",
      "Train:  1.0371369330874294\n",
      "Test 0.6917660817121848\n",
      "0.6920405680021768\n",
      "Epoch: 21\n",
      "Train:  1.036994993250012\n",
      "Test 0.6916859529830597\n",
      "0.6919691177888336\n",
      "Epoch: 22\n",
      "Train:  1.0368306621527061\n",
      "Test 0.6916010707289308\n",
      "0.691895071283434\n",
      "Epoch: 23\n",
      "Train:  1.0366786956350444\n",
      "Test 0.6915128639329484\n",
      "0.6918182671159103\n",
      "Epoch: 24\n",
      "Train:  1.0365128345760233\n",
      "Test 0.6914230903863033\n",
      "0.6917389320505862\n",
      "Epoch: 25\n",
      "Train:  1.036349484772036\n",
      "Test 0.6913306835370187\n",
      "0.6916570348287074\n",
      "Epoch: 26\n",
      "Train:  1.036166990196312\n",
      "Test 0.6912300866165441\n",
      "0.6915714382263896\n",
      "Epoch: 27\n",
      "Train:  1.0359889338741373\n",
      "Test 0.691126993724278\n",
      "0.691482377056611\n",
      "Epoch: 28\n",
      "Train:  1.0358163120545747\n",
      "Test 0.6910208179837182\n",
      "0.6913899221750327\n",
      "Epoch: 29\n",
      "Train:  1.0356022355320689\n",
      "Test 0.6909048382615869\n",
      "0.6912927851425217\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:44:11,789]\u001b[0m Trial 10 finished with value: 0.6905066313532724 and parameters: {'layer_size1': 512, 'layer_size2': 384, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 128, 'learning_rate': 1.4694277623649185e-06, 'b1': 0.9977778680779769}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  1.0354020228752723\n",
      "Test 0.6907851322666629\n",
      "0.691191153916659\n",
      "Epoch: 0\n",
      "Train:  0.6933173159539918\n",
      "Test 0.6922873223657573\n",
      "0.6922873223657573\n",
      "Epoch: 1\n",
      "Train:  1.0385337991592212\n",
      "Test 0.6918352444966634\n",
      "0.6920361679940386\n",
      "Epoch: 2\n",
      "Train:  1.0374386598775676\n",
      "Test 0.6911089839516106\n",
      "0.6916561745340272\n",
      "Epoch: 3\n",
      "Train:  1.0363885513592115\n",
      "Test 0.6904772648881207\n",
      "0.6912568148978799\n",
      "Epoch: 4\n",
      "Train:  1.0347146207378024\n",
      "Test 0.689354596557198\n",
      "0.6906909479474154\n",
      "Epoch: 5\n",
      "Train:  1.0326335663760537\n",
      "Test 0.6877109083063874\n",
      "0.6898831915176978\n",
      "Epoch: 6\n",
      "Train:  1.0297913760929318\n",
      "Test 0.6855187926973615\n",
      "0.6887786786078364\n",
      "Epoch: 7\n",
      "Train:  1.0258947473305922\n",
      "Test 0.682415838206644\n",
      "0.6872495684061894\n",
      "Epoch: 8\n",
      "Train:  1.020384478481698\n",
      "Test 0.6782123435547937\n",
      "0.6851619246316135\n",
      "Epoch: 9\n",
      "Train:  1.0133656376884097\n",
      "Test 0.6725010747437948\n",
      "0.6823251592954148\n",
      "Epoch: 10\n",
      "Train:  1.0038209556441604\n",
      "Test 0.6650051507321033\n",
      "0.678535640387184\n",
      "Epoch: 11\n",
      "Train:  0.9915814017638181\n",
      "Test 0.6551923909030117\n",
      "0.673522489376067\n",
      "Epoch: 12\n",
      "Train:  0.9755495162237258\n",
      "Test 0.6417530045841203\n",
      "0.6667989626255868\n",
      "Epoch: 13\n",
      "Train:  0.9535445129915034\n",
      "Test 0.6239040245066633\n",
      "0.6578253095665191\n",
      "Epoch: 14\n",
      "Train:  0.9244171936651726\n",
      "Test 0.5989033494676862\n",
      "0.6456111707415917\n",
      "Epoch: 15\n",
      "Train:  0.885400462936569\n",
      "Test 0.5663542131801228\n",
      "0.6293006797212899\n",
      "Epoch: 16\n",
      "Train:  0.8352343854886708\n",
      "Test 0.5256189640625056\n",
      "0.608086638856873\n",
      "Epoch: 17\n",
      "Train:  0.7736021531370533\n",
      "Test 0.478540715717134\n",
      "0.5817021535969861\n",
      "Epoch: 18\n",
      "Train:  0.7037746607165634\n",
      "Test 0.4275789861277346\n",
      "0.5504267946798881\n",
      "Epoch: 19\n",
      "Train:  0.6326080038870647\n",
      "Test 0.37822706293273756\n",
      "0.5155851515340714\n",
      "Epoch: 20\n",
      "Train:  0.562433143347611\n",
      "Test 0.33077623414032625\n",
      "0.47827928214276805\n",
      "Epoch: 21\n",
      "Train:  0.4989393072905558\n",
      "Test 0.2907725256004613\n",
      "0.440499162756953\n",
      "Epoch: 22\n",
      "Train:  0.44536191809090064\n",
      "Test 0.25838988416251685\n",
      "0.4038610336972324\n",
      "Epoch: 23\n",
      "Train:  0.4036657504955709\n",
      "Test 0.23221702486167461\n",
      "0.3693693495569993\n",
      "Epoch: 24\n",
      "Train:  0.36867727380204984\n",
      "Test 0.21326320217205927\n",
      "0.3380297223157957\n",
      "Epoch: 25\n",
      "Train:  0.34136552213530835\n",
      "Test 0.19853660965085904\n",
      "0.31004652576073144\n",
      "Epoch: 26\n",
      "Train:  0.3205984546956453\n",
      "Test 0.1871020515814369\n",
      "0.28539803452994567\n",
      "Epoch: 27\n",
      "Train:  0.3052658665884327\n",
      "Test 0.17896387597798427\n",
      "0.2640699483009531\n",
      "Epoch: 28\n",
      "Train:  0.29386779537676894\n",
      "Test 0.17321650503755925\n",
      "0.2458710982919054\n",
      "Epoch: 29\n",
      "Train:  0.2851074125631388\n",
      "Test 0.16869241635113846\n",
      "0.23041622970312406\n",
      "Epoch: 30\n",
      "Train:  0.2751208853399579\n",
      "Test 0.16393045090384536\n",
      "0.2171058920233081\n",
      "Epoch: 31\n",
      "Train:  0.2678067803573914\n",
      "Test 0.16140189146684422\n",
      "0.20595625826205924\n",
      "Epoch: 32\n",
      "Train:  0.2652236321572583\n",
      "Test 0.16076188845621361\n",
      "0.19691165160035834\n",
      "Epoch: 33\n",
      "Train:  0.2583533167538844\n",
      "Test 0.15655515664990569\n",
      "0.18883625789919886\n",
      "Epoch: 34\n",
      "Train:  0.25559453757636713\n",
      "Test 0.1563905460330156\n",
      "0.18234448214886576\n",
      "Epoch: 35\n",
      "Train:  0.2532136495678853\n",
      "Test 0.1539041568958388\n",
      "0.17665457061639941\n",
      "Epoch: 36\n",
      "Train:  0.2526834142042986\n",
      "Test 0.15426768831935994\n",
      "0.17217603146175234\n",
      "Epoch: 37\n",
      "Train:  0.249232784814232\n",
      "Test 0.15194239748484922\n",
      "0.1681284640195031\n",
      "Epoch: 38\n",
      "Train:  0.2463079649313684\n",
      "Test 0.15394577168392173\n",
      "0.16529145417327284\n",
      "Epoch: 39\n",
      "Train:  0.2435937894869855\n",
      "Test 0.15085131801910454\n",
      "0.16240304300674058\n",
      "Epoch: 40\n",
      "Train:  0.23999442325925435\n",
      "Test 0.15136470536500107\n",
      "0.1601951406939474\n",
      "Epoch: 41\n",
      "Train:  0.24031339175043961\n",
      "Test 0.1494367425040011\n",
      "0.1580432779957251\n",
      "Epoch: 42\n",
      "Train:  0.23581453133715596\n",
      "Test 0.1520273724209258\n",
      "0.15684001499092853\n",
      "Epoch: 43\n",
      "Train:  0.23646523271288192\n",
      "Test 0.1494629483178749\n",
      "0.15536452132280137\n",
      "Epoch: 44\n",
      "Train:  0.23350657171641404\n",
      "Test 0.14791947861471566\n",
      "0.15387544792289035\n",
      "Epoch: 45\n",
      "Train:  0.23279436842296206\n",
      "Test 0.1478334998254811\n",
      "0.1526670161957084\n",
      "Epoch: 46\n",
      "Train:  0.2308410320826721\n",
      "Test 0.14649085199030545\n",
      "0.15143174892040187\n",
      "Epoch: 47\n",
      "Train:  0.2271668585153781\n",
      "Test 0.1475100197416522\n",
      "0.15064738559276522\n",
      "Epoch: 48\n",
      "Train:  0.22678810587978407\n",
      "Test 0.1466459988210446\n",
      "0.1498470939607413\n",
      "Epoch: 49\n",
      "Train:  0.2258825569785449\n",
      "Test 0.1477247610988416\n",
      "0.14942262133008555\n",
      "Epoch: 50\n",
      "Train:  0.2268109015451792\n",
      "Test 0.14484466022842532\n",
      "0.14850701865541907\n",
      "Epoch: 51\n",
      "Train:  0.22183427697682118\n",
      "Test 0.15055802764691711\n",
      "0.14891722420069414\n",
      "Epoch: 52\n",
      "Train:  0.22478677269630817\n",
      "Test 0.14392948560007326\n",
      "0.14791966919092855\n",
      "Epoch: 53\n",
      "Train:  0.2201212445621962\n",
      "Test 0.14609896516488804\n",
      "0.1475555262569385\n",
      "Epoch: 54\n",
      "Train:  0.21773234185431795\n",
      "Test 0.14443823664479857\n",
      "0.14693206541870557\n",
      "Epoch: 55\n",
      "Train:  0.2154828848951793\n",
      "Test 0.14564895088146457\n",
      "0.1466754415511135\n",
      "Epoch: 56\n",
      "Train:  0.21526335143644512\n",
      "Test 0.14452545290246552\n",
      "0.14624544253433006\n",
      "Epoch: 57\n",
      "Train:  0.21456838586118632\n",
      "Test 0.14326010172292863\n",
      "0.14564837294235217\n",
      "Epoch: 58\n",
      "Train:  0.21270200829857436\n",
      "Test 0.14517580477636813\n",
      "0.14555385912810284\n",
      "Epoch: 59\n",
      "Train:  0.21069506830075285\n",
      "Test 0.14197958000823035\n",
      "0.14483900220861332\n",
      "Epoch: 60\n",
      "Train:  0.20817021572205063\n",
      "Test 0.14249637194878453\n",
      "0.1443704755822356\n",
      "Epoch: 61\n",
      "Train:  0.20718375433086259\n",
      "Test 0.14213983370707586\n",
      "0.14392434676964178\n",
      "Epoch: 62\n",
      "Train:  0.20586198835800856\n",
      "Test 0.14157072080797328\n",
      "0.14345362120795904\n",
      "Epoch: 63\n",
      "Train:  0.20423129744036295\n",
      "Test 0.14112524811055635\n",
      "0.14298794629616962\n",
      "Epoch: 64\n",
      "Train:  0.20246940331308397\n",
      "Test 0.1411511815142828\n",
      "0.14262059315531922\n",
      "Epoch: 65\n",
      "Train:  0.20210811332373063\n",
      "Test 0.13991274235040058\n",
      "0.142079022776768\n",
      "Epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:44:54,501]\u001b[0m Trial 11 finished with value: 0.14183000176412583 and parameters: {'layer_size1': 512, 'layer_size2': 256, 'layer_size3': 384, 'layer_size4': 128, 'layer_size5': 192, 'learning_rate': 9.576429661010661e-06, 'b1': 0.9716134842808527}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.199278131731182\n",
      "Test 0.14083414602574412\n",
      "0.1418300473465456\n",
      "Epoch: 0\n",
      "Train:  0.6926616554731851\n",
      "Test 0.6925372898360311\n",
      "0.6925372898360311\n",
      "Epoch: 1\n",
      "Train:  1.0380431230251606\n",
      "Test 0.6918312926868816\n",
      "0.6921450691976148\n",
      "Epoch: 2\n",
      "Train:  1.0368355150187845\n",
      "Test 0.6910374575045519\n",
      "0.6916911299791464\n",
      "Epoch: 3\n",
      "Train:  1.035084646263402\n",
      "Test 0.6896191189140627\n",
      "0.6909892292118417\n",
      "Epoch: 4\n",
      "Train:  1.0325029977075346\n",
      "Test 0.687547124785818\n",
      "0.6899652809651664\n",
      "Epoch: 5\n",
      "Train:  1.0289045794979557\n",
      "Test 0.6844697522593068\n",
      "0.6884756871403931\n",
      "Epoch: 6\n",
      "Train:  1.0235442645820505\n",
      "Test 0.6798989202950027\n",
      "0.6863051362591435\n",
      "Epoch: 7\n",
      "Train:  1.0160620257312998\n",
      "Test 0.6739624705943432\n",
      "0.6833389615960127\n",
      "Epoch: 8\n",
      "Train:  1.005382436863232\n",
      "Test 0.6646019499817174\n",
      "0.6790106189583166\n",
      "Epoch: 9\n",
      "Train:  0.9897140742658259\n",
      "Test 0.6505828724675999\n",
      "0.672641153515977\n",
      "Epoch: 10\n",
      "Train:  0.9670363660260435\n",
      "Test 0.6315068951893202\n",
      "0.6636412128326271\n",
      "Epoch: 11\n",
      "Train:  0.9353654658619738\n",
      "Test 0.6035672989520398\n",
      "0.6507398555337462\n",
      "Epoch: 12\n",
      "Train:  0.8920909124852974\n",
      "Test 0.5658022115082094\n",
      "0.6327640990659166\n",
      "Epoch: 13\n",
      "Train:  0.8321699304676755\n",
      "Test 0.5166992405395368\n",
      "0.6084832440643793\n",
      "Epoch: 14\n",
      "Train:  0.7555993665487338\n",
      "Test 0.45264098048210144\n",
      "0.5761781571495503\n",
      "Epoch: 15\n",
      "Train:  0.6624060471306791\n",
      "Test 0.3803385834554176\n",
      "0.5358758328308239\n",
      "Epoch: 16\n",
      "Train:  0.5618907330018696\n",
      "Test 0.31230351339766393\n",
      "0.49013129349260265\n",
      "Epoch: 17\n",
      "Train:  0.4707811628724193\n",
      "Test 0.2587223188890206\n",
      "0.4430004650461702\n",
      "Epoch: 18\n",
      "Train:  0.40384092875125205\n",
      "Test 0.22055633685418538\n",
      "0.3978611127836801\n",
      "Epoch: 19\n",
      "Train:  0.356489664346198\n",
      "Test 0.19841876795222035\n",
      "0.35750739715196217\n",
      "Epoch: 20\n",
      "Train:  0.3240558658163626\n",
      "Test 0.18087896328051012\n",
      "0.32185285527311963\n",
      "Epoch: 21\n",
      "Train:  0.3010565649185862\n",
      "Test 0.1737266460181156\n",
      "0.2920073927787608\n",
      "Epoch: 22\n",
      "Train:  0.2889231000941642\n",
      "Test 0.16406120745390107\n",
      "0.2662662065700623\n",
      "Epoch: 23\n",
      "Train:  0.27480130786274054\n",
      "Test 0.1632735571199721\n",
      "0.24556994133075757\n",
      "Epoch: 24\n",
      "Train:  0.27267166253029207\n",
      "Test 0.15696100352993814\n",
      "0.22778094885713654\n",
      "Epoch: 25\n",
      "Train:  0.2672999406117441\n",
      "Test 0.1552303300303963\n",
      "0.21322683799076877\n",
      "Epoch: 26\n",
      "Train:  0.2568553990203437\n",
      "Test 0.15626479125830717\n",
      "0.20180681672714415\n",
      "Epoch: 27\n",
      "Train:  0.25448362050311907\n",
      "Test 0.1516143608660925\n",
      "0.19174887065782104\n",
      "Epoch: 28\n",
      "Train:  0.24829622180688948\n",
      "Test 0.1564070009882306\n",
      "0.18466954199339675\n",
      "Epoch: 29\n",
      "Train:  0.24984621684725358\n",
      "Test 0.15095654521615076\n",
      "0.1779185853584256\n",
      "Epoch: 30\n",
      "Train:  0.250839684520176\n",
      "Test 0.15483430717072208\n",
      "0.17329715287583766\n",
      "Epoch: 31\n",
      "Train:  0.24508121577620287\n",
      "Test 0.1501680000688567\n",
      "0.16866765444790338\n",
      "Epoch: 32\n",
      "Train:  0.24210952274201117\n",
      "Test 0.1544041168422271\n",
      "0.16581313766180952\n",
      "Epoch: 33\n",
      "Train:  0.2428786869027785\n",
      "Test 0.1484559660866147\n",
      "0.1623399422274597\n",
      "Epoch: 34\n",
      "Train:  0.24171907626665556\n",
      "Test 0.15171849577527344\n",
      "0.16021479087321772\n",
      "Epoch: 35\n",
      "Train:  0.23501641716767144\n",
      "Test 0.14717487144819547\n",
      "0.15760596037431301\n",
      "Epoch: 36\n",
      "Train:  0.23366528342140244\n",
      "Test 0.14672015481816106\n",
      "0.15542823389296423\n",
      "Epoch: 37\n",
      "Train:  0.23127541932594645\n",
      "Test 0.14545813142816663\n",
      "0.15343379917211927\n",
      "Epoch: 38\n",
      "Train:  0.22787493896489833\n",
      "Test 0.14434069225857982\n",
      "0.15161487556888945\n",
      "Epoch: 39\n",
      "Train:  0.2270269221165678\n",
      "Test 0.14418440652608652\n",
      "0.15012858419831887\n",
      "Epoch: 40\n",
      "Train:  0.22351842403289054\n",
      "Test 0.14287225492707975\n",
      "0.14867716400260242\n",
      "Epoch: 41\n",
      "Train:  0.2207315001063622\n",
      "Test 0.14305315473741229\n",
      "0.14755226645386427\n",
      "Epoch: 42\n",
      "Train:  0.21976133037508624\n",
      "Test 0.14230612305166956\n",
      "0.14650296636176155\n",
      "Epoch: 43\n",
      "Train:  0.21838609706405754\n",
      "Test 0.14181045513777507\n",
      "0.1455644130172597\n",
      "Epoch: 44\n",
      "Train:  0.2165228541865399\n",
      "Test 0.1414257226300327\n",
      "0.14473663888516586\n",
      "Epoch: 45\n",
      "Train:  0.21683698862572728\n",
      "Test 0.1394936146125907\n",
      "0.14368799749083125\n",
      "Epoch: 46\n",
      "Train:  0.2111813902868565\n",
      "Test 0.1409323437637462\n",
      "0.14313685138170307\n",
      "Epoch: 47\n",
      "Train:  0.21060353779530788\n",
      "Test 0.13803552018458043\n",
      "0.1421165623890737\n",
      "Epoch: 48\n",
      "Train:  0.2084563547393969\n",
      "Test 0.13980292529208865\n",
      "0.14165382671419638\n",
      "Epoch: 49\n",
      "Train:  0.2063646411315125\n",
      "Test 0.13690045381462945\n",
      "0.14070313856560834\n",
      "Epoch: 50\n",
      "Train:  0.20355491664076408\n",
      "Test 0.13743538929715807\n",
      "0.14004958124961292\n",
      "Epoch: 51\n",
      "Train:  0.20868522827530572\n",
      "Test 0.13587801568141897\n",
      "0.1392152605149671\n",
      "Epoch: 52\n",
      "Train:  0.20303768531040667\n",
      "Test 0.14153912969124624\n",
      "0.13968003774658638\n",
      "Epoch: 53\n",
      "Train:  0.2018935733062007\n",
      "Test 0.13524395298390163\n",
      "0.13879281560734297\n",
      "Epoch: 54\n",
      "Train:  0.19571064652759076\n",
      "Test 0.14003570813808466\n",
      "0.13904139527605\n",
      "Epoch: 55\n",
      "Train:  0.19824099570731105\n",
      "Test 0.13372474910875598\n",
      "0.13797806206418933\n",
      "Epoch: 56\n",
      "Train:  0.19318628186639739\n",
      "Test 0.13644026176519555\n",
      "0.13767050108381276\n",
      "Epoch: 57\n",
      "Train:  0.1927485635500715\n",
      "Test 0.13273042197520044\n",
      "0.13668248289625679\n",
      "Epoch: 58\n",
      "Train:  0.188332809619742\n",
      "Test 0.13423573664447544\n",
      "0.1361931327084918\n",
      "Epoch: 59\n",
      "Train:  0.18899380259775309\n",
      "Test 0.13168681617621536\n",
      "0.1352918680208524\n",
      "Epoch: 60\n",
      "Train:  0.18470686473525488\n",
      "Test 0.13391127235396005\n",
      "0.13501574854895246\n",
      "Epoch: 61\n",
      "Train:  0.18567664163944486\n",
      "Test 0.13171635570871087\n",
      "0.13435586933369648\n",
      "Epoch: 62\n",
      "Train:  0.18146437809089602\n",
      "Test 0.13038082370336676\n",
      "0.13356085958383593\n",
      "Epoch: 63\n",
      "Train:  0.17953783256298567\n",
      "Test 0.13203584231886561\n",
      "0.13325585593938796\n",
      "Epoch: 64\n",
      "Train:  0.17967820735034215\n",
      "Test 0.12949654005549766\n",
      "0.132503992385048\n",
      "Epoch: 65\n",
      "Train:  0.17828893712670593\n",
      "Test 0.13101622685039546\n",
      "0.1322064391585801\n",
      "Epoch: 66\n",
      "Train:  0.17516481660258693\n",
      "Test 0.12849649022787046\n",
      "0.1314644491339718\n",
      "Epoch: 67\n",
      "Train:  0.17348716204010306\n",
      "Test 0.13032604186307817\n",
      "0.13123676762125386\n",
      "Epoch: 68\n",
      "Train:  0.171827055172715\n",
      "Test 0.12818896082731393\n",
      "0.13062720613708634\n",
      "Epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:45:37,271]\u001b[0m Trial 12 finished with value: 0.1316794696794136 and parameters: {'layer_size1': 512, 'layer_size2': 256, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 192, 'learning_rate': 1.0524470697732908e-05, 'b1': 0.9757441788577849}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.17346465625824073\n",
      "Test 0.1358886313225542\n",
      "0.13167949134733392\n",
      "Epoch: 0\n",
      "Train:  0.6932616513290685\n",
      "Test 0.6924635001591274\n",
      "0.6924635001591274\n",
      "Epoch: 1\n",
      "Train:  1.0380427210758894\n",
      "Test 0.6916920647516356\n",
      "0.6920349249327431\n",
      "Epoch: 2\n",
      "Train:  1.0363844824142945\n",
      "Test 0.6905451091654572\n",
      "0.6914243447002488\n",
      "Epoch: 3\n",
      "Train:  1.0337975374508253\n",
      "Test 0.6881448639618172\n",
      "0.6903134094907529\n",
      "Epoch: 4\n",
      "Train:  1.0294846020120405\n",
      "Test 0.6841700801919232\n",
      "0.6884859079144708\n",
      "Epoch: 5\n",
      "Train:  1.0226525317181598\n",
      "Test 0.6778561772007645\n",
      "0.6856046598894616\n",
      "Epoch: 6\n",
      "Train:  1.011636672439156\n",
      "Test 0.6675961345106691\n",
      "0.6810471825398295\n",
      "Epoch: 7\n",
      "Train:  0.9942879168105213\n",
      "Test 0.6517523459462455\n",
      "0.674007082416867\n",
      "Epoch: 8\n",
      "Train:  0.9669081150612115\n",
      "Test 0.6269251824298621\n",
      "0.6631309299453585\n",
      "Epoch: 9\n",
      "Train:  0.9247931012740502\n",
      "Test 0.5865174667302505\n",
      "0.6459650667797381\n",
      "Epoch: 10\n",
      "Train:  0.8633026482858064\n",
      "Test 0.5297181702358819\n",
      "0.6205309100432782\n",
      "Epoch: 11\n",
      "Train:  0.7756081389420199\n",
      "Test 0.4603625665872525\n",
      "0.5861334670698851\n",
      "Epoch: 12\n",
      "Train:  0.6686993998376441\n",
      "Test 0.3727062305251321\n",
      "0.5409648487058424\n",
      "Epoch: 13\n",
      "Train:  0.5461768725197831\n",
      "Test 0.28776743615066613\n",
      "0.4879957610847229\n",
      "Epoch: 14\n",
      "Train:  0.44453536377939984\n",
      "Test 0.22960451474556556\n",
      "0.4344329375018222\n",
      "Epoch: 15\n",
      "Train:  0.37433163008410414\n",
      "Test 0.19580899763019968\n",
      "0.38532590957324514\n",
      "Epoch: 16\n",
      "Train:  0.3297549082791849\n",
      "Test 0.1767971084449754\n",
      "0.3426593846181463\n",
      "Epoch: 17\n",
      "Train:  0.2965852541801257\n",
      "Test 0.16220973890561324\n",
      "0.30590739040588183\n",
      "Epoch: 18\n",
      "Train:  0.2725773895016083\n",
      "Test 0.15777978557588418\n",
      "0.27584867773692173\n",
      "Epoch: 19\n",
      "Train:  0.26260615028304496\n",
      "Test 0.14993508479424886\n",
      "0.25037223577034584\n",
      "Epoch: 20\n",
      "Train:  0.2555498729558873\n",
      "Test 0.15443661984315504\n",
      "0.23100649515443794\n",
      "Epoch: 21\n",
      "Train:  0.24993936556831495\n",
      "Test 0.14760859878290267\n",
      "0.21420292743483135\n",
      "Epoch: 22\n",
      "Train:  0.24397278759942387\n",
      "Test 0.15304075425743183\n",
      "0.2018978564810496\n",
      "Epoch: 23\n",
      "Train:  0.2445289904231226\n",
      "Test 0.14541696354528486\n",
      "0.19054808009028082\n",
      "Epoch: 24\n",
      "Train:  0.23612145260112843\n",
      "Test 0.14866188045713927\n",
      "0.18213907182863737\n",
      "Epoch: 25\n",
      "Train:  0.23599501078327498\n",
      "Test 0.1431993074687846\n",
      "0.17432750995957924\n",
      "Epoch: 26\n",
      "Train:  0.23299728628698285\n",
      "Test 0.1432122573352013\n",
      "0.16808937655362233\n",
      "Epoch: 27\n",
      "Train:  0.2278542787948753\n",
      "Test 0.14172546680157\n",
      "0.16280637579357368\n",
      "Epoch: 28\n",
      "Train:  0.22502354711239592\n",
      "Test 0.14161585342316402\n",
      "0.15856170300649577\n",
      "Epoch: 29\n",
      "Train:  0.22303984814320074\n",
      "Test 0.14178461165273146\n",
      "0.15520212578057987\n",
      "Epoch: 30\n",
      "Train:  0.2210335135118756\n",
      "Test 0.13849004966653747\n",
      "0.15185639710858448\n",
      "Epoch: 31\n",
      "Train:  0.21612602073849338\n",
      "Test 0.13792404477849549\n",
      "0.1490677172227347\n",
      "Epoch: 32\n",
      "Train:  0.2129835145882307\n",
      "Test 0.13647469152583852\n",
      "0.1465475147152448\n",
      "Epoch: 33\n",
      "Train:  0.20997191793814082\n",
      "Test 0.1359888147903886\n",
      "0.14443470340766465\n",
      "Epoch: 34\n",
      "Train:  0.20973330561494652\n",
      "Test 0.13843569418094753\n",
      "0.14323441466736378\n",
      "Epoch: 35\n",
      "Train:  0.2079620104685644\n",
      "Test 0.1332611525670076\n",
      "0.1412391147354445\n",
      "Epoch: 36\n",
      "Train:  0.20132981885511142\n",
      "Test 0.13499368260181321\n",
      "0.13998970394313165\n",
      "Epoch: 37\n",
      "Train:  0.1997739388129841\n",
      "Test 0.13167316897775663\n",
      "0.1383260514229465\n",
      "Epoch: 38\n",
      "Train:  0.19565514316134183\n",
      "Test 0.13218097705325801\n",
      "0.13709683230995154\n",
      "Epoch: 39\n",
      "Train:  0.19382716614357282\n",
      "Test 0.1310276953851456\n",
      "0.1358828435582068\n",
      "Epoch: 40\n",
      "Train:  0.19242153166974094\n",
      "Test 0.12984773157089402\n",
      "0.134675692794457\n",
      "Epoch: 41\n",
      "Train:  0.19251789496836316\n",
      "Test 0.1383151705120946\n",
      "0.1354036502657574\n",
      "Epoch: 42\n",
      "Train:  0.2068579844557322\n",
      "Test 0.13175760292799482\n",
      "0.13467439116740243\n",
      "Epoch: 43\n",
      "Train:  0.1925474077313047\n",
      "Test 0.14156905529106328\n",
      "0.13605339907246644\n",
      "Epoch: 44\n",
      "Train:  0.1928300049723955\n",
      "Test 0.12812432955827688\n",
      "0.13446751609468283\n",
      "Epoch: 45\n",
      "Train:  0.184956007761601\n",
      "Test 0.13513643339603812\n",
      "0.13460130421678954\n",
      "Epoch: 46\n",
      "Train:  0.18156842010662014\n",
      "Test 0.1269102848984383\n",
      "0.13306305747305844\n",
      "Epoch: 47\n",
      "Train:  0.17697634515199032\n",
      "Test 0.12621644919826872\n",
      "0.13169370528052615\n",
      "Epoch: 48\n",
      "Train:  0.1736015417091139\n",
      "Test 0.12593164734351328\n",
      "0.13054127313304703\n",
      "Epoch: 49\n",
      "Train:  0.17000883244551146\n",
      "Test 0.12365215843468359\n",
      "0.12916343052814758\n",
      "Epoch: 50\n",
      "Train:  0.16618078772401634\n",
      "Test 0.1276000849834401\n",
      "0.1288507578491152\n",
      "Epoch: 51\n",
      "Train:  0.16966293678847533\n",
      "Test 0.12519219439927037\n",
      "0.1281190384753396\n",
      "Epoch: 52\n",
      "Train:  0.1700822046920384\n",
      "Test 0.1316239769014465\n",
      "0.12882003128307165\n",
      "Epoch: 53\n",
      "Train:  0.1688865786793577\n",
      "Test 0.12122226727532816\n",
      "0.1273004695981554\n",
      "Epoch: 54\n",
      "Train:  0.16171122024402076\n",
      "Test 0.12030066480866937\n",
      "0.12590050209288284\n",
      "Epoch: 55\n",
      "Train:  0.15586104404672488\n",
      "Test 0.11997375608636783\n",
      "0.12471514845664536\n",
      "Epoch: 56\n",
      "Train:  0.15313034722642913\n",
      "Test 0.11872576077250362\n",
      "0.12351726733437271\n",
      "Epoch: 57\n",
      "Train:  0.14970981974313344\n",
      "Test 0.12300646072424157\n",
      "0.12341510576771815\n",
      "Epoch: 58\n",
      "Train:  0.15446651064289305\n",
      "Test 0.11949213816623985\n",
      "0.12263051074443702\n",
      "Epoch: 59\n",
      "Train:  0.14631114591718156\n",
      "Test 0.11957123849008765\n",
      "0.1220186553559015\n",
      "Epoch: 60\n",
      "Train:  0.14387791263683267\n",
      "Test 0.11818113955822619\n",
      "0.12125115125540915\n",
      "Epoch: 61\n",
      "Train:  0.1406613385557255\n",
      "Test 0.11695564606469193\n",
      "0.12039204937466105\n",
      "Epoch: 62\n",
      "Train:  0.13976997419536769\n",
      "Test 0.13082855579617259\n",
      "0.12247935229673995\n",
      "Epoch: 63\n",
      "Train:  0.14774494120107465\n",
      "Test 0.11682395260412615\n",
      "0.12134827164822637\n",
      "Epoch: 64\n",
      "Train:  0.13540013247739263\n",
      "Test 0.11797699744338955\n",
      "0.12067401646866954\n",
      "Epoch: 65\n",
      "Train:  0.13351762776464332\n",
      "Test 0.1164931074277781\n",
      "0.11983783432456804\n",
      "Epoch: 66\n",
      "Train:  0.13831445845500687\n",
      "Test 0.12694392480201774\n",
      "0.12125905287682001\n",
      "Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:46:21,657]\u001b[0m Trial 13 finished with value: 0.12237343058397307 and parameters: {'layer_size1': 384, 'layer_size2': 384, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 192, 'learning_rate': 1.5949013768007617e-05, 'b1': 0.979930131605874}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.14210904284121106\n",
      "Test 0.1268310972972135\n",
      "0.12237346204742455\n",
      "Epoch: 0\n",
      "Train:  0.692655609422551\n",
      "Test 0.6925722495976822\n",
      "0.6925722495976822\n",
      "Epoch: 1\n",
      "Train:  1.0377918949057332\n",
      "Test 0.6917157980985257\n",
      "0.692096443209262\n",
      "Epoch: 2\n",
      "Train:  1.0357155446167832\n",
      "Test 0.6898418874531002\n",
      "0.6911724449485398\n",
      "Epoch: 3\n",
      "Train:  1.0321657672906532\n",
      "Test 0.6867707166479621\n",
      "0.6896813445757153\n",
      "Epoch: 4\n",
      "Train:  1.0261080473552258\n",
      "Test 0.6803828814090827\n",
      "0.6869152620059175\n",
      "Epoch: 5\n",
      "Train:  1.015004848167573\n",
      "Test 0.6696900517949255\n",
      "0.6822462723355776\n",
      "Epoch: 6\n",
      "Train:  0.9952947726616492\n",
      "Test 0.6496180996790037\n",
      "0.6739889522766384\n",
      "Epoch: 7\n",
      "Train:  0.959836027888588\n",
      "Test 0.615717032453516\n",
      "0.6599851141394468\n",
      "Epoch: 8\n",
      "Train:  0.904455711771717\n",
      "Test 0.5626942229358268\n",
      "0.6375104356088105\n",
      "Epoch: 9\n",
      "Train:  0.8213354440835806\n",
      "Test 0.4902647147466848\n",
      "0.6045188465333288\n",
      "Epoch: 10\n",
      "Train:  0.7142167838611009\n",
      "Test 0.4052291949153383\n",
      "0.5609154094876423\n",
      "Epoch: 11\n",
      "Train:  0.5975066727989322\n",
      "Test 0.31672020780516197\n",
      "0.5084725213175746\n",
      "Epoch: 12\n",
      "Train:  0.4944819396723321\n",
      "Test 0.26535296936829883\n",
      "0.45701997741261136\n",
      "Epoch: 13\n",
      "Train:  0.44083930511068514\n",
      "Test 0.2439038723215952\n",
      "0.41243592921828887\n",
      "Epoch: 14\n",
      "Train:  0.41483316230741174\n",
      "Test 0.23622318740674864\n",
      "0.37590817475124283\n",
      "Epoch: 15\n",
      "Train:  0.399618800518004\n",
      "Test 0.22097564069724782\n",
      "0.34402421423609947\n",
      "Epoch: 16\n",
      "Train:  0.36714642153090826\n",
      "Test 0.21296618300261516\n",
      "0.3172087780472635\n",
      "Epoch: 17\n",
      "Train:  0.3431445265482197\n",
      "Test 0.19276865058657014\n",
      "0.29186418495510197\n",
      "Epoch: 18\n",
      "Train:  0.31938858694591366\n",
      "Test 0.1788383792171548\n",
      "0.2689284855440855\n",
      "Epoch: 19\n",
      "Train:  0.29826761636500937\n",
      "Test 0.17326258313961518\n",
      "0.24957214161148686\n",
      "Epoch: 20\n",
      "Train:  0.27775345502537246\n",
      "Test 0.16377522220541707\n",
      "0.23225301700063433\n",
      "Epoch: 21\n",
      "Train:  0.2616988092169657\n",
      "Test 0.1580263002785844\n",
      "0.21729732009088915\n",
      "Epoch: 22\n",
      "Train:  0.25130402386331785\n",
      "Test 0.15713001089000003\n",
      "0.2051924034348433\n",
      "Epoch: 23\n",
      "Train:  0.24488317865482617\n",
      "Test 0.1531474172741502\n",
      "0.19473401787326375\n",
      "Epoch: 24\n",
      "Train:  0.23616704957443715\n",
      "Test 0.1544539355860525\n",
      "0.18664745123080242\n",
      "Epoch: 25\n",
      "Train:  0.23663141760606687\n",
      "Test 0.14760785475509725\n",
      "0.17881586241082872\n",
      "Epoch: 26\n",
      "Train:  0.22993809631223971\n",
      "Test 0.14760461919036977\n",
      "0.17255848435494722\n",
      "Epoch: 27\n",
      "Train:  0.2262602109230045\n",
      "Test 0.1540184152268228\n",
      "0.16884328428726336\n",
      "Epoch: 28\n",
      "Train:  0.22202659907303887\n",
      "Test 0.14346650324679994\n",
      "0.16376006217394237\n",
      "Epoch: 29\n",
      "Train:  0.2138581286310713\n",
      "Test 0.14450597153778696\n",
      "0.15990447105609137\n",
      "Epoch: 30\n",
      "Train:  0.21168843421730257\n",
      "Test 0.14502019193637503\n",
      "0.1569246641743495\n",
      "Epoch: 31\n",
      "Train:  0.20728288276373466\n",
      "Test 0.1406946483003351\n",
      "0.15367608721171128\n",
      "Epoch: 32\n",
      "Train:  0.2030886609530274\n",
      "Test 0.13996442014371957\n",
      "0.15093201453542535\n",
      "Epoch: 33\n",
      "Train:  0.19922087719534343\n",
      "Test 0.1391549383327638\n",
      "0.1485754043515674\n",
      "Epoch: 34\n",
      "Train:  0.19652490985781063\n",
      "Test 0.1397936771668139\n",
      "0.14681834616714085\n",
      "Epoch: 35\n",
      "Train:  0.19335621375003795\n",
      "Test 0.14151656323354758\n",
      "0.14575764536333147\n",
      "Epoch: 36\n",
      "Train:  0.19001026471374016\n",
      "Test 0.1388402962664845\n",
      "0.14437381628139231\n",
      "Epoch: 37\n",
      "Train:  0.18541521562225843\n",
      "Test 0.13744425807734986\n",
      "0.1429876167382025\n",
      "Epoch: 38\n",
      "Train:  0.1868564389277618\n",
      "Test 0.15057811501261953\n",
      "0.14450596867257323\n",
      "Epoch: 39\n",
      "Train:  0.1891985860936371\n",
      "Test 0.13892666531569792\n",
      "0.14338995965815562\n",
      "Epoch: 40\n",
      "Train:  0.1819106208863276\n",
      "Test 0.13603872355524\n",
      "0.14191955607744414\n",
      "Epoch: 41\n",
      "Train:  0.1725387879384634\n",
      "Test 0.14105484033457172\n",
      "0.141746598215242\n",
      "Epoch: 42\n",
      "Train:  0.1766250418535785\n",
      "Test 0.15220133398042057\n",
      "0.14383768768045224\n",
      "Epoch: 43\n",
      "Train:  0.17976288338816102\n",
      "Test 0.13589555502531456\n",
      "0.14224917466254958\n",
      "Epoch: 44\n",
      "Train:  0.16449744115760995\n",
      "Test 0.13559466909323803\n",
      "0.14091821557724307\n",
      "Epoch: 45\n",
      "Train:  0.1627672958066653\n",
      "Test 0.13696901887082136\n",
      "0.14012834871311547\n",
      "Epoch: 46\n",
      "Train:  0.16035943679961856\n",
      "Test 0.13677047248997967\n",
      "0.1394567547471809\n",
      "Epoch: 47\n",
      "Train:  0.1598052209645728\n",
      "Test 0.14012218103402946\n",
      "0.1395898429725172\n",
      "Epoch: 48\n",
      "Train:  0.16301382159952402\n",
      "Test 0.1710429467779376\n",
      "0.14588057596402815\n",
      "Epoch: 49\n",
      "Train:  0.18579460467952183\n",
      "Test 0.13585437004601125\n",
      "0.14387530616025776\n",
      "Epoch: 50\n",
      "Train:  0.15650127209286332\n",
      "Test 0.1418618559231811\n",
      "0.1434726115148824\n",
      "Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:46:53,281]\u001b[0m Trial 14 finished with value: 0.14675697626912693 and parameters: {'layer_size1': 384, 'layer_size2': 384, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 128, 'learning_rate': 2.1568087865971898e-05, 'b1': 0.9826982413051502}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.15977014358037736\n",
      "Test 0.15990098795662513\n",
      "0.14675831681612891\n",
      "Epoch: 0\n",
      "Train:  0.6927932125308138\n",
      "Test 0.6926676919172098\n",
      "0.6926676919172098\n",
      "Epoch: 1\n",
      "Train:  1.0380244166641446\n",
      "Test 0.6919486273776044\n",
      "0.6922682116174291\n",
      "Epoch: 2\n",
      "Train:  1.0360477365853586\n",
      "Test 0.6901432699336237\n",
      "0.6913973338781646\n",
      "Epoch: 3\n",
      "Train:  1.0328941836461916\n",
      "Test 0.6866218834132939\n",
      "0.6897796338561895\n",
      "Epoch: 4\n",
      "Train:  1.0268204985084115\n",
      "Test 0.6809189310877315\n",
      "0.6871437751078381\n",
      "Epoch: 5\n",
      "Train:  1.01638052882729\n",
      "Test 0.6710552601587205\n",
      "0.6827828930525001\n",
      "Epoch: 6\n",
      "Train:  0.9983150103153327\n",
      "Test 0.6531074828717298\n",
      "0.6752728384036518\n",
      "Epoch: 7\n",
      "Train:  0.9662608626561288\n",
      "Test 0.6205158366825118\n",
      "0.6621137011844163\n",
      "Epoch: 8\n",
      "Train:  0.9098744550685742\n",
      "Test 0.5649740350988758\n",
      "0.639673956406288\n",
      "Epoch: 9\n",
      "Train:  0.8204083682853224\n",
      "Test 0.48660915260349874\n",
      "0.6053785549547964\n",
      "Epoch: 10\n",
      "Train:  0.6985804533565437\n",
      "Test 0.3887727452721788\n",
      "0.5579864414679898\n",
      "Epoch: 11\n",
      "Train:  0.5567672008123153\n",
      "Test 0.2923482737261734\n",
      "0.5009385034716503\n",
      "Epoch: 12\n",
      "Train:  0.4415768968971658\n",
      "Test 0.2382479647358695\n",
      "0.44534405880707145\n",
      "Epoch: 13\n",
      "Train:  0.3778806344602571\n",
      "Test 0.21161800970906738\n",
      "0.39644839494908324\n",
      "Epoch: 14\n",
      "Train:  0.34030003441095136\n",
      "Test 0.19145035293403562\n",
      "0.35395363510385364\n",
      "Epoch: 15\n",
      "Train:  0.3115536836300032\n",
      "Test 0.18033849093517212\n",
      "0.3182249327024846\n",
      "Epoch: 16\n",
      "Train:  0.290210787645258\n",
      "Test 0.19159225552878428\n",
      "0.2923149564712436\n",
      "Epoch: 17\n",
      "Train:  0.2958511381901309\n",
      "Test 0.17615573624005684\n",
      "0.2686569272588248\n",
      "Epoch: 18\n",
      "Train:  0.2695394793027268\n",
      "Test 0.17563906219197717\n",
      "0.24978132819453583\n",
      "Epoch: 19\n",
      "Train:  0.2610068870333088\n",
      "Test 0.1535738474610961\n",
      "0.2303154052359886\n",
      "Epoch: 20\n",
      "Train:  0.23835290089631692\n",
      "Test 0.1591657799542387\n",
      "0.21595301046936588\n",
      "Epoch: 21\n",
      "Train:  0.2431336123387128\n",
      "Test 0.14679646099006738\n",
      "0.2020188848740068\n",
      "Epoch: 22\n",
      "Train:  0.22944014924731884\n",
      "Test 0.1457985260766068\n",
      "0.19070804570479452\n",
      "Epoch: 23\n",
      "Train:  0.2245445967389223\n",
      "Test 0.14137432819757706\n",
      "0.18079448674479234\n",
      "Epoch: 24\n",
      "Train:  0.217748890265877\n",
      "Test 0.1397784055046901\n",
      "0.17256016209779426\n",
      "Epoch: 25\n",
      "Train:  0.21327168585292502\n",
      "Test 0.13890408454701686\n",
      "0.16580854106516227\n",
      "Epoch: 26\n",
      "Train:  0.2086820582374794\n",
      "Test 0.13661217091147934\n",
      "0.15995511431696746\n",
      "Epoch: 27\n",
      "Train:  0.2043801058772883\n",
      "Test 0.13694520471037636\n",
      "0.15534421361659587\n",
      "Epoch: 28\n",
      "Train:  0.20175365659650482\n",
      "Test 0.1341993598055927\n",
      "0.15110868869703858\n",
      "Epoch: 29\n",
      "Train:  0.1959388596125138\n",
      "Test 0.13391286018730958\n",
      "0.14766526023712984\n",
      "Epoch: 30\n",
      "Train:  0.19692026318183967\n",
      "Test 0.1341874597273467\n",
      "0.14496702793533184\n",
      "Epoch: 31\n",
      "Train:  0.19970731611189607\n",
      "Test 0.13665823847219183\n",
      "0.14330395241853067\n",
      "Epoch: 32\n",
      "Train:  0.1918040832825305\n",
      "Test 0.13019405218052776\n",
      "0.14068030943963158\n",
      "Epoch: 33\n",
      "Train:  0.18583578485381472\n",
      "Test 0.12884081231477934\n",
      "0.13831120873789052\n",
      "Epoch: 34\n",
      "Train:  0.19577240308016647\n",
      "Test 0.15838596874322647\n",
      "0.14232779005790847\n",
      "Epoch: 35\n",
      "Train:  0.19493601675871963\n",
      "Test 0.14140320784879692\n",
      "0.14214281358778963\n",
      "Epoch: 36\n",
      "Train:  0.19743107974310933\n",
      "Test 0.1408386719532502\n",
      "0.14188191752839224\n",
      "Epoch: 37\n",
      "Train:  0.18226851042592046\n",
      "Test 0.12510272126300295\n",
      "0.13852538114998267\n",
      "Epoch: 38\n",
      "Train:  0.16930375765325098\n",
      "Test 0.12676372545542736\n",
      "0.13617265909806936\n",
      "Epoch: 39\n",
      "Train:  0.16791859850451185\n",
      "Test 0.12467649226987755\n",
      "0.1338731200712658\n",
      "Epoch: 40\n",
      "Train:  0.16640322635653038\n",
      "Test 0.12857043105706353\n",
      "0.13281246948070863\n",
      "Epoch: 41\n",
      "Train:  0.16367748803322651\n",
      "Test 0.12480199481650586\n",
      "0.13121023824510877\n",
      "Epoch: 42\n",
      "Train:  0.16288129699453985\n",
      "Test 0.1242255241262143\n",
      "0.12981320034385715\n",
      "Epoch: 43\n",
      "Train:  0.15758182469929394\n",
      "Test 0.13058983842968505\n",
      "0.12996853641832307\n",
      "Epoch: 44\n",
      "Train:  0.15696682646229262\n",
      "Test 0.12763334833846288\n",
      "0.12950147845910778\n",
      "Epoch: 45\n",
      "Train:  0.15958787987969011\n",
      "Test 0.1396787543399447\n",
      "0.13153700456300796\n",
      "Epoch: 46\n",
      "Train:  0.16012945665004355\n",
      "Test 0.1312264199385713\n",
      "0.13147488590650522\n",
      "Epoch: 47\n",
      "Train:  0.15418136967243729\n",
      "Test 0.12687006146534457\n",
      "0.13055390047961174\n",
      "Epoch: 48\n",
      "Train:  0.14913363112034378\n",
      "Test 0.1228708260225289\n",
      "0.12901725817358037\n",
      "Epoch: 49\n",
      "Train:  0.14917803140896144\n",
      "Test 0.12170784807194283\n",
      "0.12755535528827766\n",
      "Epoch: 50\n",
      "Train:  0.13951075113218128\n",
      "Test 0.12551793112204626\n",
      "0.12714786580232396\n",
      "Epoch: 51\n",
      "Train:  0.14026715948618265\n",
      "Test 0.12636424351360773\n",
      "0.12699113991298605\n",
      "Epoch: 52\n",
      "Train:  0.13808338441493692\n",
      "Test 0.12170515920380097\n",
      "0.12593393604562314\n",
      "Epoch: 53\n",
      "Train:  0.13221351413786303\n",
      "Test 0.12129360677558423\n",
      "0.12500586476610456\n",
      "Epoch: 54\n",
      "Train:  0.13133141966093154\n",
      "Test 0.12973716113402511\n",
      "0.1259521284651797\n",
      "Epoch: 55\n",
      "Train:  0.1342443108538186\n",
      "Test 0.12582617396345505\n",
      "0.12592693747058406\n",
      "Epoch: 56\n",
      "Train:  0.12816530988029726\n",
      "Test 0.13057519678169718\n",
      "0.12685659211540745\n",
      "Epoch: 57\n",
      "Train:  0.12898849803807672\n",
      "Test 0.1243579325371937\n",
      "0.12635685900314164\n",
      "Epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:47:32,398]\u001b[0m Trial 15 finished with value: 0.12708839054462154 and parameters: {'layer_size1': 384, 'layer_size2': 512, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 256, 'learning_rate': 1.904772491779652e-05, 'b1': 0.9831126793464435}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.12102785163078007\n",
      "Test 0.1300157269688098\n",
      "0.12708863399807765\n",
      "Epoch: 0\n",
      "Train:  0.564430234851418\n",
      "Test 0.489539161745707\n",
      "0.489539161745707\n",
      "Epoch: 1\n",
      "Train:  0.6387613483596634\n",
      "Test 0.3007254015395056\n",
      "0.3846426282978175\n",
      "Epoch: 2\n",
      "Train:  0.4070856100657866\n",
      "Test 0.18418889525499973\n",
      "0.30248945901797414\n",
      "Epoch: 3\n",
      "Train:  0.2624655668419059\n",
      "Test 0.13740547870937395\n",
      "0.24656670146086027\n",
      "Epoch: 4\n",
      "Train:  0.19185088435870223\n",
      "Test 0.12990700390749363\n",
      "0.21186307891404724\n",
      "Epoch: 5\n",
      "Train:  0.17082034358959441\n",
      "Test 0.12195527011651423\n",
      "0.1874930639524469\n",
      "Epoch: 6\n",
      "Train:  0.14593983299590155\n",
      "Test 0.1355727324228147\n",
      "0.17435341315070246\n",
      "Epoch: 7\n",
      "Train:  0.12434761166135906\n",
      "Test 0.15020203175562205\n",
      "0.16854938203463682\n",
      "Epoch: 8\n",
      "Train:  0.1966194453727686\n",
      "Test 0.13291673872606222\n",
      "0.1603180646559011\n",
      "Epoch: 9\n",
      "Train:  0.16368742539605377\n",
      "Test 0.14171056806420287\n",
      "0.1561489052556659\n",
      "Epoch: 10\n",
      "Train:  0.14625915345708557\n",
      "Test 0.1408474408226572\n",
      "0.15280103226931324\n",
      "Epoch: 11\n",
      "Train:  0.14878321928164032\n",
      "Test 0.10842160479380535\n",
      "0.1432701924488981\n",
      "Epoch: 12\n",
      "Train:  0.09972849859422817\n",
      "Test 0.1292786261974237\n",
      "0.14030909092052993\n",
      "Epoch: 13\n",
      "Train:  0.11040818844597801\n",
      "Test 0.11581831447261594\n",
      "0.13518560221467235\n",
      "Epoch: 14\n",
      "Train:  0.09128396970893615\n",
      "Test 0.13538522368822342\n",
      "0.13522698244686931\n",
      "Epoch: 15\n",
      "Train:  0.09777641235535194\n",
      "Test 0.1408876192190125\n",
      "0.13639189929558412\n",
      "Epoch: 16\n",
      "Train:  0.09597750036133328\n",
      "Test 0.17803953324219438\n",
      "0.14491331122280673\n",
      "Epoch: 17\n",
      "Train:  0.10479164858013137\n",
      "Test 0.20566833656854355\n",
      "0.1572872249041314\n",
      "Epoch: 18\n",
      "Train:  0.11251001648300825\n",
      "Test 0.3265728656758619\n",
      "0.19163942036950865\n",
      "Epoch: 19\n",
      "Train:  0.17118294603123047\n",
      "Test 0.3376600427403061\n",
      "0.2211841726461483\n",
      "Epoch: 20\n",
      "Train:  0.1847192542852662\n",
      "Test 0.2898048419000465\n",
      "0.23503606767822424\n",
      "Epoch: 21\n",
      "Train:  0.16530735732506205\n",
      "Test 0.1981942859433946\n",
      "0.22761293830414242\n",
      "Epoch: 22\n",
      "Train:  0.11998160849587614\n",
      "Test 0.29720211811713904\n",
      "0.24161341851485568\n",
      "Epoch: 23\n",
      "Train:  0.1542901876302441\n",
      "Test 0.36329735552165954\n",
      "0.2660656784489597\n",
      "Epoch: 24\n",
      "Train:  0.1966688302678385\n",
      "Test 0.24392486915444966\n",
      "0.26162072402703374\n",
      "Epoch: 25\n",
      "Train:  0.13624262030988502\n",
      "Test 0.3098530204414011\n",
      "0.2712964263257367\n",
      "Epoch: 26\n",
      "Train:  0.16171614607981374\n",
      "Test 0.26676171185660275\n",
      "0.27038728526370276\n",
      "Epoch: 27\n",
      "Train:  0.14026301040408473\n",
      "Test 0.7328906549215862\n",
      "0.3630672282769901\n",
      "Epoch: 28\n",
      "Train:  0.3785130176040497\n",
      "Test 0.7057742766853449\n",
      "0.4317148650313367\n",
      "Epoch: 29\n",
      "Train:  0.45954950009797685\n",
      "Test 0.6067931431963112\n",
      "0.46677392167428944\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:47:52,715]\u001b[0m Trial 16 finished with value: 0.40687068440376367 and parameters: {'layer_size1': 384, 'layer_size2': 384, 'layer_size3': 512, 'layer_size4': 128, 'layer_size5': 192, 'learning_rate': 0.0008298975224367807, 'b1': 0.9826921677705167}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.37553944170235265\n",
      "Test 0.16956908782939978\n",
      "0.40727402906579696\n",
      "Epoch: 0\n",
      "Train:  0.692957905185965\n",
      "Test 0.6932934782443902\n",
      "0.6932934782443901\n",
      "Epoch: 1\n",
      "Train:  1.039310491892881\n",
      "Test 0.6930845910376244\n",
      "0.693177429796187\n",
      "Epoch: 2\n",
      "Train:  1.038979979880127\n",
      "Test 0.6929395609286242\n",
      "0.6930799425553826\n",
      "Epoch: 3\n",
      "Train:  1.0386581281165936\n",
      "Test 0.6927459580557687\n",
      "0.6929668041747545\n",
      "Epoch: 4\n",
      "Train:  1.0382747265882109\n",
      "Test 0.6924400744420705\n",
      "0.6928101139877353\n",
      "Epoch: 5\n",
      "Train:  1.0378082678431557\n",
      "Test 0.6920905877382327\n",
      "0.6926150823692345\n",
      "Epoch: 6\n",
      "Train:  1.0372027643434294\n",
      "Test 0.6917955451832586\n",
      "0.6924076793707266\n",
      "Epoch: 7\n",
      "Train:  1.0366448356118394\n",
      "Test 0.6914477143095527\n",
      "0.6921769817143795\n",
      "Epoch: 8\n",
      "Train:  1.0359389428254013\n",
      "Test 0.6909084612633283\n",
      "0.6918839471970243\n",
      "Epoch: 9\n",
      "Train:  1.0350361977304732\n",
      "Test 0.6900500914989374\n",
      "0.6914730570654756\n",
      "Epoch: 10\n",
      "Train:  1.0337308621231889\n",
      "Test 0.6891328305988521\n",
      "0.6909610288864828\n",
      "Epoch: 11\n",
      "Train:  1.0323217057046437\n",
      "Test 0.6882150413352491\n",
      "0.6903713059227491\n",
      "Epoch: 12\n",
      "Train:  1.0306817347750121\n",
      "Test 0.6868750752110184\n",
      "0.6896313820344608\n",
      "Epoch: 13\n",
      "Train:  1.0286301265269409\n",
      "Test 0.6853405756828113\n",
      "0.6887337421442576\n",
      "Epoch: 14\n",
      "Train:  1.0261788804889163\n",
      "Test 0.6833819380173316\n",
      "0.6876243479818699\n",
      "Epoch: 15\n",
      "Train:  1.023175149937689\n",
      "Test 0.6811904180180895\n",
      "0.6863002931590728\n",
      "Epoch: 16\n",
      "Train:  1.0197434105497576\n",
      "Test 0.678602064485515\n",
      "0.6847251790068154\n",
      "Epoch: 17\n",
      "Train:  1.015698368951078\n",
      "Test 0.6755036556677068\n",
      "0.682847040809043\n",
      "Epoch: 18\n",
      "Train:  1.0108970635103218\n",
      "Test 0.6717850880308466\n",
      "0.6806023001309025\n",
      "Epoch: 19\n",
      "Train:  1.0053000584408478\n",
      "Test 0.6671611802045242\n",
      "0.6778827215392086\n",
      "Epoch: 20\n",
      "Train:  0.998515383773671\n",
      "Test 0.6621412460183923\n",
      "0.674705118217423\n",
      "Epoch: 21\n",
      "Train:  0.9908436177632748\n",
      "Test 0.6561984688371092\n",
      "0.670976274329806\n",
      "Epoch: 22\n",
      "Train:  0.9816856041496054\n",
      "Test 0.6492296500957055\n",
      "0.666601123148868\n",
      "Epoch: 23\n",
      "Train:  0.97084517793341\n",
      "Test 0.6406945715020428\n",
      "0.66139522867794\n",
      "Epoch: 24\n",
      "Train:  0.9582268062965337\n",
      "Test 0.6315145793851915\n",
      "0.6553964360214874\n",
      "Epoch: 25\n",
      "Train:  0.9444049577136616\n",
      "Test 0.6206861647057446\n",
      "0.648433337083111\n",
      "Epoch: 26\n",
      "Train:  0.9285198391138852\n",
      "Test 0.608442098011464\n",
      "0.6404157038210561\n",
      "Epoch: 27\n",
      "Train:  0.9100090982494774\n",
      "Test 0.593921938658634\n",
      "0.6310989295261706\n",
      "Epoch: 28\n",
      "Train:  0.8883212392146771\n",
      "Test 0.5775473401660011\n",
      "0.6203720125541144\n",
      "Epoch: 29\n",
      "Train:  0.8647304943629673\n",
      "Test 0.55964506764115\n",
      "0.6082115696723828\n",
      "Epoch: 30\n",
      "Train:  0.8393774532573127\n",
      "Test 0.5409189964825417\n",
      "0.5947397131539444\n",
      "Epoch: 31\n",
      "Train:  0.8118943312229254\n",
      "Test 0.5196141417209919\n",
      "0.5797026853064936\n",
      "Epoch: 32\n",
      "Train:  0.7811032519454048\n",
      "Test 0.49673881799310116\n",
      "0.5630993882540779\n",
      "Epoch: 33\n",
      "Train:  0.7481001842043775\n",
      "Test 0.4719692573442564\n",
      "0.5448641156904294\n",
      "Epoch: 34\n",
      "Train:  0.7143091441510798\n",
      "Test 0.4485979017975566\n",
      "0.5256030596993146\n",
      "Epoch: 35\n",
      "Train:  0.6817501625626079\n",
      "Test 0.4264865049294063\n",
      "0.5057733136248175\n",
      "Epoch: 36\n",
      "Train:  0.651322175458674\n",
      "Test 0.40442449291110477\n",
      "0.48549828578390664\n",
      "Epoch: 37\n",
      "Train:  0.620789402461314\n",
      "Test 0.38329798463500026\n",
      "0.4650539794378208\n",
      "Epoch: 38\n",
      "Train:  0.5919426597736694\n",
      "Test 0.3631281057993571\n",
      "0.4446654170791429\n",
      "Epoch: 39\n",
      "Train:  0.5652232024914179\n",
      "Test 0.3449114576364175\n",
      "0.42471197292293933\n",
      "Epoch: 40\n",
      "Train:  0.5413645371630952\n",
      "Test 0.32926749620900486\n",
      "0.4056210474847478\n",
      "Epoch: 41\n",
      "Train:  0.5194231352799541\n",
      "Test 0.3149891041574024\n",
      "0.3874931166654771\n",
      "Epoch: 42\n",
      "Train:  0.5012274528597738\n",
      "Test 0.30361235054421337\n",
      "0.3707158216376918\n",
      "Epoch: 43\n",
      "Train:  0.4851945195442591\n",
      "Test 0.2929919704849467\n",
      "0.35517020502326807\n",
      "Epoch: 44\n",
      "Train:  0.471049536497165\n",
      "Test 0.2832341340435294\n",
      "0.3407823641484662\n",
      "Epoch: 45\n",
      "Train:  0.459002469703828\n",
      "Test 0.2755776672136216\n",
      "0.3277409703352466\n",
      "Epoch: 46\n",
      "Train:  0.4483262827763191\n",
      "Test 0.2682288939699585\n",
      "0.3158382232620269\n",
      "Epoch: 47\n",
      "Train:  0.43702426596438926\n",
      "Test 0.26173229837592266\n",
      "0.3050167969589354\n",
      "Epoch: 48\n",
      "Train:  0.4272958953956981\n",
      "Test 0.25632047751447656\n",
      "0.2952773593126698\n",
      "Epoch: 49\n",
      "Train:  0.4196799043224845\n",
      "Test 0.24994659085413476\n",
      "0.2862110762226466\n",
      "Epoch: 50\n",
      "Train:  0.40966168220663246\n",
      "Test 0.24452344423685318\n",
      "0.27787345462667845\n",
      "Epoch: 51\n",
      "Train:  0.4016817553248598\n",
      "Test 0.23942739841265556\n",
      "0.27018417314701465\n",
      "Epoch: 52\n",
      "Train:  0.3932398605696011\n",
      "Test 0.2342269188100165\n",
      "0.2629926697276449\n",
      "Epoch: 53\n",
      "Train:  0.3854549072491817\n",
      "Test 0.22987565627464882\n",
      "0.25636922831636383\n",
      "Epoch: 54\n",
      "Train:  0.37818789577636963\n",
      "Test 0.22583903061164604\n",
      "0.250263160218529\n",
      "Epoch: 55\n",
      "Train:  0.37187049936353067\n",
      "Test 0.22112318857030555\n",
      "0.24443514408368722\n",
      "Epoch: 56\n",
      "Train:  0.36449493579702935\n",
      "Test 0.21745962079191383\n",
      "0.23904002327689783\n",
      "Epoch: 57\n",
      "Train:  0.3587509600015787\n",
      "Test 0.21424486116939412\n",
      "0.23408097898084512\n",
      "Epoch: 58\n",
      "Train:  0.3532434329663441\n",
      "Test 0.21015847089526418\n",
      "0.22929646819842714\n",
      "Epoch: 59\n",
      "Train:  0.34549565744269023\n",
      "Test 0.20668702990144164\n",
      "0.22477457360924674\n",
      "Epoch: 60\n",
      "Train:  0.3392905245770465\n",
      "Test 0.2030710739939859\n",
      "0.22043386836450546\n",
      "Epoch: 61\n",
      "Train:  0.3320920534172665\n",
      "Test 0.19947336985296382\n",
      "0.21624176455059368\n",
      "Epoch: 62\n",
      "Train:  0.3260270001523661\n",
      "Test 0.1966754016585839\n",
      "0.21232848890168804\n",
      "Epoch: 63\n",
      "Train:  0.31986481528524513\n",
      "Test 0.19242653408984997\n",
      "0.20834809544078697\n",
      "Epoch: 64\n",
      "Train:  0.31348577532030286\n",
      "Test 0.1905037067530356\n",
      "0.20477921591105913\n",
      "Epoch: 65\n",
      "Train:  0.30806666214169165\n",
      "Test 0.1861410535080529\n",
      "0.2010515819329387\n",
      "Epoch: 66\n",
      "Train:  0.30617304206331136\n",
      "Test 0.18683053188080534\n",
      "0.19820737100841787\n",
      "Epoch: 67\n",
      "Train:  0.2986361259976641\n",
      "Test 0.18034566584087552\n",
      "0.19463502905642424\n",
      "Epoch: 68\n",
      "Train:  0.29183170952639736\n",
      "Test 0.17779410059730977\n",
      "0.1912668426718056\n",
      "Epoch: 69\n",
      "Train:  0.2875276020141284\n",
      "Test 0.17647578122414947\n",
      "0.1883086298954991\n",
      "Epoch: 70\n",
      "Train:  0.2836390387116771\n",
      "Test 0.17232878002655375\n",
      "0.18511265950099134\n",
      "Epoch: 71\n",
      "Train:  0.278053168923809\n",
      "Test 0.17215897137428815\n",
      "0.18252192160281416\n",
      "Epoch: 72\n",
      "Train:  0.2752261054275673\n",
      "Test 0.16804126805656558\n",
      "0.17962579064956588\n",
      "Epoch: 73\n",
      "Train:  0.269016468617724\n",
      "Test 0.16638075082730025\n",
      "0.17697678250656998\n",
      "Epoch: 74\n",
      "Train:  0.2664136917163164\n",
      "Test 0.1641795701951116\n",
      "0.1744173399062734\n",
      "Epoch: 75\n",
      "Train:  0.26269304299993174\n",
      "Test 0.16340163033523838\n",
      "0.17221419789703185\n",
      "Epoch: 76\n",
      "Train:  0.2594384981981127\n",
      "Test 0.16146737519965504\n",
      "0.17006483328338462\n",
      "Epoch: 77\n",
      "Train:  0.2563975343528466\n",
      "Test 0.16067506602177253\n",
      "0.16818687977921756\n",
      "Epoch: 78\n",
      "Train:  0.25404420727011046\n",
      "Test 0.15894923112167544\n",
      "0.1663393500069054\n",
      "Epoch: 79\n",
      "Train:  0.2519693882323993\n",
      "Test 0.15856744215274468\n",
      "0.16478496840860968\n",
      "Epoch: 80\n",
      "Train:  0.24952746978227472\n",
      "Test 0.15792753614294222\n",
      "0.16341348193609054\n",
      "Epoch: 81\n",
      "Train:  0.24730106035841035\n",
      "Test 0.1564281498228674\n",
      "0.16201641549764811\n",
      "Epoch: 82\n",
      "Train:  0.24791517257417514\n",
      "Test 0.1550248482916163\n",
      "0.16061810204379223\n",
      "Epoch: 83\n",
      "Train:  0.2423839643529374\n",
      "Test 0.15441654659739454\n",
      "0.15937779094553653\n",
      "Epoch: 84\n",
      "Train:  0.24127625158029326\n",
      "Test 0.1550585929058738\n",
      "0.1585139513326027\n",
      "Epoch: 85\n",
      "Train:  0.2401064503426244\n",
      "Test 0.1534910519170701\n",
      "0.1575093714448433\n",
      "Epoch: 86\n",
      "Train:  0.23753518043614705\n",
      "Test 0.15251832423329134\n",
      "0.1565111619988342\n",
      "Epoch: 87\n",
      "Train:  0.2359777758419923\n",
      "Test 0.152427029915345\n",
      "0.15569433557971507\n",
      "Epoch: 88\n",
      "Train:  0.23452904739249975\n",
      "Test 0.15098075719461554\n",
      "0.15475161990045957\n",
      "Epoch: 89\n",
      "Train:  0.2335899796084443\n",
      "Test 0.1528078487941197\n",
      "0.15436286567845406\n",
      "Epoch: 90\n",
      "Train:  0.23385104089429526\n",
      "Test 0.14992204728798988\n",
      "0.15347470199901325\n",
      "Epoch: 91\n",
      "Train:  0.23128288427552024\n",
      "Test 0.14986919868232568\n",
      "0.15275360133480023\n",
      "Epoch: 92\n",
      "Train:  0.2289066466710943\n",
      "Test 0.1494599529729658\n",
      "0.1520948716617935\n",
      "Epoch: 93\n",
      "Train:  0.22777222569063033\n",
      "Test 0.14822985990580184\n",
      "0.15132186930999447\n",
      "Epoch: 94\n",
      "Train:  0.2263521026997339\n",
      "Test 0.1477142408381015\n",
      "0.15060034361516733\n",
      "Epoch: 95\n",
      "Train:  0.22597456356380885\n",
      "Test 0.1470803403305811\n",
      "0.14989634295789997\n",
      "Epoch: 96\n",
      "Train:  0.22385260984369795\n",
      "Test 0.1475503383538662\n",
      "0.14942714203690657\n",
      "Epoch: 97\n",
      "Train:  0.22276946678484752\n",
      "Test 0.14631212134282667\n",
      "0.14880413789789226\n",
      "Epoch: 98\n",
      "Train:  0.2217510058902777\n",
      "Test 0.145635768252633\n",
      "0.14817046396867908\n",
      "Epoch: 99\n",
      "Train:  0.21988280301729402\n",
      "Test 0.14564377455306904\n",
      "0.14766512608545412\n",
      "Epoch: 100\n",
      "Train:  0.2198769278643523\n",
      "Test 0.14781182349383176\n",
      "0.14769446556713445\n",
      "Epoch: 101\n",
      "Train:  0.21865022706461476\n",
      "Test 0.1450881907791445\n",
      "0.1471732106094685\n",
      "Epoch: 102\n",
      "Train:  0.21741432120730153\n",
      "Test 0.14574516679231936\n",
      "0.14688760184600888\n",
      "Epoch: 103\n",
      "Train:  0.21885419512788454\n",
      "Test 0.1470195767094446\n",
      "0.1469139968186982\n",
      "Epoch: 104\n",
      "Train:  0.2189881054525888\n",
      "Test 0.14529811585451657\n",
      "0.1465908206258403\n",
      "Epoch: 105\n",
      "Train:  0.21763035771010558\n",
      "Test 0.1431761180961525\n",
      "0.14590788011986627\n",
      "Epoch: 106\n",
      "Train:  0.21321387674946052\n",
      "Test 0.1433024474525408\n",
      "0.14538679358637893\n",
      "Epoch: 107\n",
      "Train:  0.21324464072210667\n",
      "Test 0.14259623201911922\n",
      "0.1448286812729079\n",
      "Epoch: 108\n",
      "Train:  0.21064511052377166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:49:02,837]\u001b[0m Trial 17 finished with value: 0.14479556990865985 and parameters: {'layer_size1': 384, 'layer_size2': 512, 'layer_size3': 384, 'layer_size4': 192, 'layer_size5': 256, 'learning_rate': 4.250258324440488e-06, 'b1': 0.9366804229874414}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0.14466312447146618\n",
      "0.14479556991261866\n",
      "Epoch: 0\n",
      "Train:  0.6919529365969228\n",
      "Test 0.6910469988326886\n",
      "0.6910469988326885\n",
      "Epoch: 1\n",
      "Train:  1.033846880380924\n",
      "Test 0.6863772987009404\n",
      "0.6884527209817175\n",
      "Epoch: 2\n",
      "Train:  1.0231149266491006\n",
      "Test 0.6726880654310569\n",
      "0.681991796575709\n",
      "Epoch: 3\n",
      "Train:  0.9941102879824656\n",
      "Test 0.6353308613047058\n",
      "0.6661852466871577\n",
      "Epoch: 4\n",
      "Train:  0.9159692715812515\n",
      "Test 0.5346033566600674\n",
      "0.6270426092445439\n",
      "Epoch: 5\n",
      "Train:  0.7358574810482207\n",
      "Test 0.3431280056635539\n",
      "0.5500859663275006\n",
      "Epoch: 6\n",
      "Train:  0.4793431252350301\n",
      "Test 0.21286437760069693\n",
      "0.4647441784741081\n",
      "Epoch: 7\n",
      "Train:  0.3318473959457634\n",
      "Test 0.17053706125584822\n",
      "0.3940406756404947\n",
      "Epoch: 8\n",
      "Train:  0.2767862019593053\n",
      "Test 0.15832416950673847\n",
      "0.33958899332798\n",
      "Epoch: 9\n",
      "Train:  0.26433455896301145\n",
      "Test 0.16230567885842515\n",
      "0.2998672396045181\n",
      "Epoch: 10\n",
      "Train:  0.26254067080770876\n",
      "Test 0.15540196975836387\n",
      "0.26825906402749655\n",
      "Epoch: 11\n",
      "Train:  0.2502692682266017\n",
      "Test 0.15944802040582176\n",
      "0.2448910152165307\n",
      "Epoch: 12\n",
      "Train:  0.2489870281501131\n",
      "Test 0.1615271719493272\n",
      "0.22724832966778813\n",
      "Epoch: 13\n",
      "Train:  0.24086634414918692\n",
      "Test 0.1480877901881169\n",
      "0.21068788574571584\n",
      "Epoch: 14\n",
      "Train:  0.22726108555446614\n",
      "Test 0.14953116146376827\n",
      "0.19801049485097003\n",
      "Epoch: 15\n",
      "Train:  0.2236998303172489\n",
      "Test 0.1495494901410717\n",
      "0.1880375813494321\n",
      "Epoch: 16\n",
      "Train:  0.22967008687896934\n",
      "Test 0.1459153459165177\n",
      "0.17941906247079772\n",
      "Epoch: 17\n",
      "Train:  0.21739679209430848\n",
      "Test 0.1482042955173241\n",
      "0.17306158290977486\n",
      "Epoch: 18\n",
      "Train:  0.2156466958778245\n",
      "Test 0.14960961137009587\n",
      "0.16830260449490828\n",
      "Epoch: 19\n",
      "Train:  0.21794942897619107\n",
      "Test 0.15223080184372081\n",
      "0.1650507526656331\n",
      "Epoch: 20\n",
      "Train:  0.21019506287222026\n",
      "Test 0.1441261128764668\n",
      "0.16082686623177897\n",
      "Epoch: 21\n",
      "Train:  0.19907581250118467\n",
      "Test 0.13868873933459813\n",
      "0.1563663278886441\n",
      "Epoch: 22\n",
      "Train:  0.19772758579816355\n",
      "Test 0.1386541105233706\n",
      "0.15280284935107913\n",
      "Epoch: 23\n",
      "Train:  0.1875671938056597\n",
      "Test 0.13817440624938998\n",
      "0.14986327900225194\n",
      "Epoch: 24\n",
      "Train:  0.18771548244092381\n",
      "Test 0.15193286692662225\n",
      "0.1502787662535818\n",
      "Epoch: 25\n",
      "Train:  0.1918882179149041\n",
      "Test 0.15120156442289387\n",
      "0.15046388537566016\n",
      "Epoch: 26\n",
      "Train:  0.1885953057461824\n",
      "Test 0.13577635572743926\n",
      "0.14751925977818822\n",
      "Epoch: 27\n",
      "Train:  0.17929917757528163\n",
      "Test 0.13582301546474954\n",
      "0.1451754773810117\n",
      "Epoch: 28\n",
      "Train:  0.17133049269790177\n",
      "Test 0.13401422589154224\n",
      "0.14293976748962936\n",
      "Epoch: 29\n",
      "Train:  0.1684518469196502\n",
      "Test 0.13710640353106318\n",
      "0.14177164863681757\n",
      "Epoch: 30\n",
      "Train:  0.16333580011631543\n",
      "Test 0.14523667394888892\n",
      "0.1424653406985744\n",
      "Epoch: 31\n",
      "Train:  0.16672782059031838\n",
      "Test 0.1422563551109789\n",
      "0.14242351043970983\n",
      "Epoch: 32\n",
      "Train:  0.16309027523211725\n",
      "Test 0.14491966349710694\n",
      "0.14292305767686678\n",
      "Epoch: 33\n",
      "Train:  0.15576765293617062\n",
      "Test 0.133500250110969\n",
      "0.1410375400926883\n",
      "Epoch: 34\n",
      "Train:  0.14648496993090754\n",
      "Test 0.140692012213962\n",
      "0.1409684064730152\n",
      "Epoch: 35\n",
      "Train:  0.1567593793838452\n",
      "Test 0.13656459535871232\n",
      "0.14008735833368674\n",
      "Epoch: 36\n",
      "Train:  0.14648365451793968\n",
      "Test 0.143392047056785\n",
      "0.14074846771211383\n",
      "Epoch: 37\n",
      "Train:  0.14131192709131665\n",
      "Test 0.14042405833254804\n",
      "0.14068357235796294\n",
      "Epoch: 38\n",
      "Train:  0.13623852419220048\n",
      "Test 0.1460408098780765\n",
      "0.14175519791632232\n",
      "Epoch: 39\n",
      "Train:  0.13586621095712942\n",
      "Test 0.15019925227968683\n",
      "0.14344423330030703\n",
      "Epoch: 40\n",
      "Train:  0.13391900859472952\n",
      "Test 0.14033163902639742\n",
      "0.14282164824092586\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:49:30,579]\u001b[0m Trial 18 finished with value: 0.14824013523381874 and parameters: {'layer_size1': 384, 'layer_size2': 384, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 192, 'learning_rate': 3.121705576686687e-05, 'b1': 0.9653470065496774}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.1289647078749659\n",
      "Test 0.169974832816029\n",
      "0.1482527471827472\n",
      "Epoch: 0\n",
      "Train:  0.6931355366340051\n",
      "Test 0.6930830028904227\n",
      "0.6930830028904227\n",
      "Epoch: 1\n",
      "Train:  1.0395809302836547\n",
      "Test 0.6930255964125469\n",
      "0.6930511104027139\n",
      "Epoch: 2\n",
      "Train:  1.03947344433257\n",
      "Test 0.6929705549072434\n",
      "0.69301809585539\n",
      "Epoch: 3\n",
      "Train:  1.0393473711205927\n",
      "Test 0.6929097330613887\n",
      "0.6929813875918395\n",
      "Epoch: 4\n",
      "Train:  1.0392374775130233\n",
      "Test 0.6928495404484508\n",
      "0.6929421660475188\n",
      "Epoch: 5\n",
      "Train:  1.0391331884887192\n",
      "Test 0.6927938808451642\n",
      "0.692901972513183\n",
      "Epoch: 6\n",
      "Train:  1.0390350503144248\n",
      "Test 0.6927387950184581\n",
      "0.6928606766424475\n",
      "Epoch: 7\n",
      "Train:  1.038934065090431\n",
      "Test 0.6926872297957704\n",
      "0.6928189941035223\n",
      "Epoch: 8\n",
      "Train:  1.03883926488541\n",
      "Test 0.6926358610719114\n",
      "0.6927766894646925\n",
      "Epoch: 9\n",
      "Train:  1.038738604866978\n",
      "Test 0.692585044728094\n",
      "0.6927337499187328\n",
      "Epoch: 10\n",
      "Train:  1.0386337430485875\n",
      "Test 0.6925324402449332\n",
      "0.6926897045123761\n",
      "Epoch: 11\n",
      "Train:  1.0385312293912028\n",
      "Test 0.6924792632951842\n",
      "0.6926445105644872\n",
      "Epoch: 12\n",
      "Train:  1.0384292026142499\n",
      "Test 0.6924255479386437\n",
      "0.6925981704654313\n",
      "Epoch: 13\n",
      "Train:  1.0383298274798272\n",
      "Test 0.6923731441026205\n",
      "0.6925510947824356\n",
      "Epoch: 14\n",
      "Train:  1.0382144862697238\n",
      "Test 0.6923183726740407\n",
      "0.6925028530040765\n",
      "Epoch: 15\n",
      "Train:  1.0381044631912595\n",
      "Test 0.6922617124550509\n",
      "0.6924532280767448\n",
      "Epoch: 16\n",
      "Train:  1.0379948205563612\n",
      "Test 0.6922052605248197\n",
      "0.6924024920935856\n",
      "Epoch: 17\n",
      "Train:  1.0378837777581407\n",
      "Test 0.6921462209233434\n",
      "0.6923502976072605\n",
      "Epoch: 18\n",
      "Train:  1.0377720906620933\n",
      "Test 0.6920864337529892\n",
      "0.6922967531798842\n",
      "Epoch: 19\n",
      "Train:  1.0376534090810643\n",
      "Test 0.6920233724754808\n",
      "0.6922414393135433\n",
      "Epoch: 20\n",
      "Train:  1.0375367905194068\n",
      "Test 0.6919578733025017\n",
      "0.6921841981548323\n",
      "Epoch: 21\n",
      "Train:  1.0374108179584964\n",
      "Test 0.6918877688519683\n",
      "0.6921244715899971\n",
      "Epoch: 22\n",
      "Train:  1.0372865251350751\n",
      "Test 0.6918167707684276\n",
      "0.6920625659995767\n",
      "Epoch: 23\n",
      "Train:  1.0371515922275656\n",
      "Test 0.6917403255190168\n",
      "0.6919978121118757\n",
      "Epoch: 24\n",
      "Train:  1.037016170583802\n",
      "Test 0.6916617137608511\n",
      "0.6919303375299074\n",
      "Epoch: 25\n",
      "Train:  1.036882648974548\n",
      "Test 0.6915855010350546\n",
      "0.6918611611581822\n",
      "Epoch: 26\n",
      "Train:  1.036748774977394\n",
      "Test 0.6915058098433219\n",
      "0.6917899186413741\n",
      "Epoch: 27\n",
      "Train:  1.036602524392334\n",
      "Test 0.6914216524515396\n",
      "0.691716122661222\n",
      "Epoch: 28\n",
      "Train:  1.0364539583960732\n",
      "Test 0.691333607439593\n",
      "0.6916395010506967\n",
      "Epoch: 29\n",
      "Train:  1.0362992513747442\n",
      "Test 0.6912401080568195\n",
      "0.6915595234444402\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:49:52,059]\u001b[0m Trial 19 finished with value: 0.6907912740154409 and parameters: {'layer_size1': 256, 'layer_size2': 384, 'layer_size3': 512, 'layer_size4': 192, 'layer_size5': 128, 'learning_rate': 1.3520674485370939e-06, 'b1': 0.9970249003130597}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  1.036144258120121\n",
      "Test 0.6911427131939284\n",
      "0.6914760787547197\n",
      "Epoch: 0\n",
      "Train:  0.69265091637552\n",
      "Test 0.6921991845626971\n",
      "0.6921991845626971\n",
      "Epoch: 1\n",
      "Train:  1.0373601416746776\n",
      "Test 0.6908246540761256\n",
      "0.6914355565146019\n",
      "Epoch: 2\n",
      "Train:  1.0350366920341938\n",
      "Test 0.6890190678201752\n",
      "0.6904451922955746\n",
      "Epoch: 3\n",
      "Train:  1.0313811234502128\n",
      "Test 0.6856947235572033\n",
      "0.6888359549180776\n",
      "Epoch: 4\n",
      "Train:  1.0253085010435992\n",
      "Test 0.679904715918796\n",
      "0.6861791132357592\n",
      "Epoch: 5\n",
      "Train:  1.0157142109049981\n",
      "Test 0.6713115033649263\n",
      "0.6821491643376457\n",
      "Epoch: 6\n",
      "Train:  1.0000869485484811\n",
      "Test 0.6559987814871819\n",
      "0.6755312000669261\n",
      "Epoch: 7\n",
      "Train:  0.9746714162302541\n",
      "Test 0.633440070099883\n",
      "0.6654159100119711\n",
      "Epoch: 8\n",
      "Train:  0.9336935871250027\n",
      "Test 0.5919439845032745\n",
      "0.6484435307233603\n",
      "Epoch: 9\n",
      "Train:  0.8648857753792089\n",
      "Test 0.525103632237885\n",
      "0.6208082335913326\n",
      "Epoch: 10\n",
      "Train:  0.7623517775819415\n",
      "Test 0.4376313954919249\n",
      "0.5807301880759257\n",
      "Epoch: 11\n",
      "Train:  0.6340181708554209\n",
      "Test 0.34014782822612444\n",
      "0.5290631868147813\n",
      "Epoch: 12\n",
      "Train:  0.5076162412271394\n",
      "Test 0.26827504002785946\n",
      "0.473871354381462\n",
      "Epoch: 13\n",
      "Train:  0.4179423972964287\n",
      "Test 0.22267962910316802\n",
      "0.4213218580351411\n",
      "Epoch: 14\n",
      "Train:  0.3638189442100979\n",
      "Test 0.2045501458557534\n",
      "0.37638649299577087\n",
      "Epoch: 15\n",
      "Train:  0.3295870813858378\n",
      "Test 0.1850232278634777\n",
      "0.3370053596090249\n",
      "Epoch: 16\n",
      "Train:  0.3100931750740105\n",
      "Test 0.17863167347488823\n",
      "0.3046009397154073\n",
      "Epoch: 17\n",
      "Train:  0.2943305907832397\n",
      "Test 0.1626965727916349\n",
      "0.27569942288901367\n",
      "Epoch: 18\n",
      "Train:  0.2709371748520232\n",
      "Test 0.15571341821889736\n",
      "0.25135132894113166\n",
      "Epoch: 19\n",
      "Train:  0.26072215159242845\n",
      "Test 0.15898443851278815\n",
      "0.23266248313318025\n",
      "Epoch: 20\n",
      "Train:  0.2609417311874501\n",
      "Test 0.15094713241735222\n",
      "0.21616727151644685\n",
      "Epoch: 21\n",
      "Train:  0.2542955503822901\n",
      "Test 0.14955621239330089\n",
      "0.20274602839702768\n",
      "Epoch: 22\n",
      "Train:  0.24685181279908933\n",
      "Test 0.1482582164607642\n",
      "0.19178375617613494\n",
      "Epoch: 23\n",
      "Train:  0.24404805287336692\n",
      "Test 0.14955549601178902\n",
      "0.1832980314411946\n",
      "Epoch: 24\n",
      "Train:  0.23944465296800102\n",
      "Test 0.14634148888426385\n",
      "0.1758786934634154\n",
      "Epoch: 25\n",
      "Train:  0.23551472613499277\n",
      "Test 0.1473559400044559\n",
      "0.17015684955954552\n",
      "Epoch: 26\n",
      "Train:  0.23327298929885834\n",
      "Test 0.14460803391991844\n",
      "0.16503470183835606\n",
      "Epoch: 27\n",
      "Train:  0.23028794626087878\n",
      "Test 0.1434080930146979\n",
      "0.16070099747025612\n",
      "Epoch: 28\n",
      "Train:  0.2292641439226084\n",
      "Test 0.14186624745623425\n",
      "0.15692820936062596\n",
      "Epoch: 29\n",
      "Train:  0.22536743007729942\n",
      "Test 0.14911712486392412\n",
      "0.15536405613337798\n",
      "Epoch: 30\n",
      "Train:  0.22824085421259804\n",
      "Test 0.14164838183930506\n",
      "0.1526182019122575\n",
      "Epoch: 31\n",
      "Train:  0.22371470780818017\n",
      "Test 0.14005596040587723\n",
      "0.15010376146601837\n",
      "Epoch: 32\n",
      "Train:  0.21861631284730557\n",
      "Test 0.13918119690793773\n",
      "0.14791786307669963\n",
      "Epoch: 33\n",
      "Train:  0.21287636775455196\n",
      "Test 0.13751724490643422\n",
      "0.14583668415956513\n",
      "Epoch: 34\n",
      "Train:  0.2104193408847292\n",
      "Test 0.13761593002805506\n",
      "0.14419186611579737\n",
      "Epoch: 35\n",
      "Train:  0.20540475275200337\n",
      "Test 0.1354716699365731\n",
      "0.1424472607231338\n",
      "Epoch: 36\n",
      "Train:  0.2031934815885383\n",
      "Test 0.14234931176466928\n",
      "0.1424276658443195\n",
      "Epoch: 37\n",
      "Train:  0.20298107355430503\n",
      "Test 0.1375398024534568\n",
      "0.1414498900900679\n",
      "Epoch: 38\n",
      "Train:  0.20028889973412503\n",
      "Test 0.14413450124601906\n",
      "0.14198690154759103\n",
      "Epoch: 39\n",
      "Train:  0.19895269176513367\n",
      "Test 0.13198745119702684\n",
      "0.13998674561115151\n",
      "Epoch: 40\n",
      "Train:  0.19243181068723128\n",
      "Test 0.13165627676488717\n",
      "0.13832047465357822\n",
      "Epoch: 41\n",
      "Train:  0.18737553889716502\n",
      "Test 0.13267652215538445\n",
      "0.13719158811889395\n",
      "Epoch: 42\n",
      "Train:  0.1866967696628291\n",
      "Test 0.13376622222834728\n",
      "0.13650646831394686\n",
      "Epoch: 43\n",
      "Train:  0.1875278715243829\n",
      "Test 0.12942019906986654\n",
      "0.13508913729829033\n",
      "Epoch: 44\n",
      "Train:  0.18274129667718494\n",
      "Test 0.13261355890895857\n",
      "0.1345940000541554\n",
      "Epoch: 45\n",
      "Train:  0.18056911000838646\n",
      "Test 0.13317565834183834\n",
      "0.13431032182694846\n",
      "Epoch: 46\n",
      "Train:  0.18417785595761332\n",
      "Test 0.12784326474963528\n",
      "0.1330168743554327\n",
      "Epoch: 47\n",
      "Train:  0.17444825678681716\n",
      "Test 0.12804401861060233\n",
      "0.1320222810262942\n",
      "Epoch: 48\n",
      "Train:  0.17821960563979525\n",
      "Test 0.1516192522814204\n",
      "0.135941745202897\n",
      "Epoch: 49\n",
      "Train:  0.18497573163346712\n",
      "Test 0.13411338778635684\n",
      "0.13557606850047668\n",
      "Epoch: 50\n",
      "Train:  0.17498790401020412\n",
      "Test 0.1274340376394354\n",
      "0.1339476437349445\n",
      "Epoch: 51\n",
      "Train:  0.16396853979335818\n",
      "Test 0.1252290173246092\n",
      "0.1322039025248735\n",
      "Epoch: 52\n",
      "Train:  0.16099625342822338\n",
      "Test 0.1254928748467903\n",
      "0.13086168718100724\n",
      "Epoch: 53\n",
      "Train:  0.15978440271192418\n",
      "Test 0.13319263669351736\n",
      "0.13132787980887442\n",
      "Epoch: 54\n",
      "Train:  0.1699333691921754\n",
      "Test 0.12717023671556932\n",
      "0.13049634730129783\n",
      "Epoch: 55\n",
      "Train:  0.15836236605227963\n",
      "Test 0.12429653559453212\n",
      "0.12925638032067743\n",
      "Epoch: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:50:30,460]\u001b[0m Trial 20 finished with value: 0.13279106281931669 and parameters: {'layer_size1': 384, 'layer_size2': 512, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 256, 'learning_rate': 1.4795359856149397e-05, 'b1': 0.9761791948189552}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.16276083712469472\n",
      "Test 0.14693172723600717\n",
      "0.1327914602847869\n",
      "Epoch: 0\n",
      "Train:  0.6924267260582893\n",
      "Test 0.6927471064822578\n",
      "0.6927471064822578\n",
      "Epoch: 1\n",
      "Train:  1.0373012242299733\n",
      "Test 0.6916681207143344\n",
      "0.6921476699445227\n",
      "Epoch: 2\n",
      "Train:  1.0346307901890723\n",
      "Test 0.6889781410440857\n",
      "0.6908486826902451\n",
      "Epoch: 3\n",
      "Train:  1.0292174117469088\n",
      "Test 0.683303333900787\n",
      "0.6882926702276916\n",
      "Epoch: 4\n",
      "Train:  1.01948017122108\n",
      "Test 0.6738104123772283\n",
      "0.683984525936145\n",
      "Epoch: 5\n",
      "Train:  1.0026279918221763\n",
      "Test 0.657147038987268\n",
      "0.67671007483759\n",
      "Epoch: 6\n",
      "Train:  0.9723518296475813\n",
      "Test 0.6270430974471264\n",
      "0.6641406878544509\n",
      "Epoch: 7\n",
      "Train:  0.9197125271126464\n",
      "Test 0.5782890501039806\n",
      "0.643508924862607\n",
      "Epoch: 8\n",
      "Train:  0.8318990952584333\n",
      "Test 0.492281185619997\n",
      "0.6085745668528811\n",
      "Epoch: 9\n",
      "Train:  0.6932357057328626\n",
      "Test 0.38523447666412747\n",
      "0.5585334217761574\n",
      "Epoch: 10\n",
      "Train:  0.5442924182930272\n",
      "Test 0.28777796302959596\n",
      "0.4992936744817931\n",
      "Epoch: 11\n",
      "Train:  0.4052269643807149\n",
      "Test 0.211512497929863\n",
      "0.4374903468349741\n",
      "Epoch: 12\n",
      "Train:  0.31642244436911177\n",
      "Test 0.1728752443478221\n",
      "0.3814885976154084\n",
      "Epoch: 13\n",
      "Train:  0.2779129426414659\n",
      "Test 0.15790261289329974\n",
      "0.3347142427905192\n",
      "Epoch: 14\n",
      "Train:  0.264210299909415\n",
      "Test 0.1520256599182802\n",
      "0.29684408862069905\n",
      "Epoch: 15\n",
      "Train:  0.2588262610579244\n",
      "Test 0.15100805434115203\n",
      "0.2668321199464264\n",
      "Epoch: 16\n",
      "Train:  0.251535700190635\n",
      "Test 0.14824628426041794\n",
      "0.24256858661077918\n",
      "Epoch: 17\n",
      "Train:  0.2476568816181941\n",
      "Test 0.14759248274040745\n",
      "0.22322490097502015\n",
      "Epoch: 18\n",
      "Train:  0.2428381095739293\n",
      "Test 0.14661646145481222\n",
      "0.2076791755567354\n",
      "Epoch: 19\n",
      "Train:  0.2382632704919047\n",
      "Test 0.14631323936316884\n",
      "0.1952628376886564\n",
      "Epoch: 20\n",
      "Train:  0.2369291062412217\n",
      "Test 0.14434399942939097\n",
      "0.1849842669549189\n",
      "Epoch: 21\n",
      "Train:  0.23090904399124912\n",
      "Test 0.1452262307902723\n",
      "0.17697355107169155\n",
      "Epoch: 22\n",
      "Train:  0.2284801191455879\n",
      "Test 0.14237833050362794\n",
      "0.17001342160544403\n",
      "Epoch: 23\n",
      "Train:  0.22255724499295482\n",
      "Test 0.1404550328983792\n",
      "0.16407369429486218\n",
      "Epoch: 24\n",
      "Train:  0.2189046737487213\n",
      "Test 0.13985052707540246\n",
      "0.1592106889361607\n",
      "Epoch: 25\n",
      "Train:  0.21459812715294815\n",
      "Test 0.13744398482116588\n",
      "0.1548441510622164\n",
      "Epoch: 26\n",
      "Train:  0.20985071746557404\n",
      "Test 0.13515150740797266\n",
      "0.15089607647274972\n",
      "Epoch: 27\n",
      "Train:  0.20801175501702468\n",
      "Test 0.1348499425826765\n",
      "0.1476806301169413\n",
      "Epoch: 28\n",
      "Train:  0.20359103012686738\n",
      "Test 0.13341445254755543\n",
      "0.14482297259222862\n",
      "Epoch: 29\n",
      "Train:  0.19936459257707492\n",
      "Test 0.13235854320637472\n",
      "0.14232699684674543\n",
      "Epoch: 30\n",
      "Train:  0.1943047460059434\n",
      "Test 0.13270849908016377\n",
      "0.14040139026503917\n",
      "Epoch: 31\n",
      "Train:  0.19245266524866741\n",
      "Test 0.12954518950165628\n",
      "0.1382284285146957\n",
      "Epoch: 32\n",
      "Train:  0.18886097994438567\n",
      "Test 0.12956609759793614\n",
      "0.1364948635540123\n",
      "Epoch: 33\n",
      "Train:  0.18961256162532958\n",
      "Test 0.1419017651039875\n",
      "0.13757679246714177\n",
      "Epoch: 34\n",
      "Train:  0.191382440501285\n",
      "Test 0.12844960707761757\n",
      "0.13575061460348817\n",
      "Epoch: 35\n",
      "Train:  0.18624488973730813\n",
      "Test 0.13378958582482386\n",
      "0.13535828152839322\n",
      "Epoch: 36\n",
      "Train:  0.18387989775403898\n",
      "Test 0.12886982732375696\n",
      "0.1340602537001752\n",
      "Epoch: 37\n",
      "Train:  0.17225127786439723\n",
      "Test 0.12437561979933535\n",
      "0.13212292455248537\n",
      "Epoch: 38\n",
      "Train:  0.17213267413387587\n",
      "Test 0.1352320306170254\n",
      "0.1327448491003334\n",
      "Epoch: 39\n",
      "Train:  0.17354360582126174\n",
      "Test 0.12310379332838914\n",
      "0.13081638160864664\n",
      "Epoch: 40\n",
      "Train:  0.16600926311161274\n",
      "Test 0.12403161852405621\n",
      "0.12945928468043016\n",
      "Epoch: 41\n",
      "Train:  0.16467279813596944\n",
      "Test 0.12973582865363295\n",
      "0.12951459818062294\n",
      "Epoch: 42\n",
      "Train:  0.16056085179556476\n",
      "Test 0.1216779554313076\n",
      "0.12794716295664627\n",
      "Epoch: 43\n",
      "Train:  0.15367157675556994\n",
      "Test 0.12479648070798798\n",
      "0.127316992197155\n",
      "Epoch: 44\n",
      "Train:  0.15513934406721386\n",
      "Test 0.12099204815398806\n",
      "0.12605194828808824\n",
      "Epoch: 45\n",
      "Train:  0.14742799699152973\n",
      "Test 0.12085438357331814\n",
      "0.12501239912213255\n",
      "Epoch: 46\n",
      "Train:  0.1451497128977007\n",
      "Test 0.12787696042340316\n",
      "0.12558532735329478\n",
      "Epoch: 47\n",
      "Train:  0.14985662449028467\n",
      "Test 0.11963557607524998\n",
      "0.12439535056031656\n",
      "Epoch: 48\n",
      "Train:  0.1394230784650469\n",
      "Test 0.11946986555275353\n",
      "0.12341023598377264\n",
      "Epoch: 49\n",
      "Train:  0.14124919740046502\n",
      "Test 0.12405748790873712\n",
      "0.12353968821636954\n",
      "Epoch: 50\n",
      "Train:  0.1419978917750356\n",
      "Test 0.11972975223956309\n",
      "0.12277769232055319\n",
      "Epoch: 51\n",
      "Train:  0.13211479604639959\n",
      "Test 0.12036042051874238\n",
      "0.1222942335440923\n",
      "Epoch: 52\n",
      "Train:  0.13233342261868955\n",
      "Test 0.12184256963233972\n",
      "0.12220390010162942\n",
      "Epoch: 53\n",
      "Train:  0.1280009544654084\n",
      "Test 0.12103826891044121\n",
      "0.12197077250052628\n",
      "Epoch: 54\n",
      "Train:  0.1256697582756425\n",
      "Test 0.12567922794993544\n",
      "0.12271246705916912\n",
      "Epoch: 55\n",
      "Train:  0.12532228335137768\n",
      "Test 0.12172129509745391\n",
      "0.1225142319251404\n",
      "Epoch: 56\n",
      "Train:  0.12716337697471292\n",
      "Test 0.12854163809218905\n",
      "0.12371971676675353\n",
      "Epoch: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:51:06,885]\u001b[0m Trial 21 finished with value: 0.12316961460719891 and parameters: {'layer_size1': 384, 'layer_size2': 512, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 256, 'learning_rate': 1.951628915439773e-05, 'b1': 0.9828087492117562}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.1257480359448618\n",
      "Test 0.12097068721831063\n",
      "0.12316990954053819\n",
      "Epoch: 0\n",
      "Train:  0.6925751957701239\n",
      "Test 0.6908955709401504\n",
      "0.6908955709401504\n",
      "Epoch: 1\n",
      "Train:  1.033427024280632\n",
      "Test 0.6851489958745656\n",
      "0.6877030292370478\n",
      "Epoch: 2\n",
      "Train:  1.0214772837939279\n",
      "Test 0.6705686041723677\n",
      "0.6806807238826708\n",
      "Epoch: 3\n",
      "Train:  0.9896464548704825\n",
      "Test 0.6288397576346065\n",
      "0.6631194209531096\n",
      "Epoch: 4\n",
      "Train:  0.9162273914604396\n",
      "Test 0.5471625686128497\n",
      "0.6286248789670732\n",
      "Epoch: 5\n",
      "Train:  0.7758440389519646\n",
      "Test 0.40587289593158626\n",
      "0.5682467067937802\n",
      "Epoch: 6\n",
      "Train:  0.5811930610474213\n",
      "Test 0.272526788515049\n",
      "0.49340788456697504\n",
      "Epoch: 7\n",
      "Train:  0.4350790350319265\n",
      "Test 0.22154441089693444\n",
      "0.4280739794503088\n",
      "Epoch: 8\n",
      "Train:  0.3852990230156498\n",
      "Test 0.20748685213017376\n",
      "0.37711725870097584\n",
      "Epoch: 9\n",
      "Train:  0.33954742968409923\n",
      "Test 0.1688735564222266\n",
      "0.33045858086020863\n",
      "Epoch: 10\n",
      "Train:  0.2803554228428519\n",
      "Test 0.16422367353681408\n",
      "0.2940873329934839\n",
      "Epoch: 11\n",
      "Train:  0.27350051928185365\n",
      "Test 0.1550780162488148\n",
      "0.264233961582373\n",
      "Epoch: 12\n",
      "Train:  0.25873922332848387\n",
      "Test 0.15731613564513106\n",
      "0.24160643496367096\n",
      "Epoch: 13\n",
      "Train:  0.2560045618304621\n",
      "Test 0.15718427757927023\n",
      "0.2239452566501533\n",
      "Epoch: 14\n",
      "Train:  0.25371698593557046\n",
      "Test 0.1652155060119818\n",
      "0.2117709615953931\n",
      "Epoch: 15\n",
      "Train:  0.25600534641429534\n",
      "Test 0.15292787071549413\n",
      "0.19966149215658666\n",
      "Epoch: 16\n",
      "Train:  0.2487478893038718\n",
      "Test 0.1654635899471658\n",
      "0.19266435008251528\n",
      "Epoch: 17\n",
      "Train:  0.2506503642079567\n",
      "Test 0.14955488666073308\n",
      "0.18388428989500374\n",
      "Epoch: 18\n",
      "Train:  0.22688122503050082\n",
      "Test 0.1455776219447263\n",
      "0.17611093038821807\n",
      "Epoch: 19\n",
      "Train:  0.22029431751799589\n",
      "Test 0.1381164542314061\n",
      "0.16842340401209302\n",
      "Epoch: 20\n",
      "Train:  0.212857247720858\n",
      "Test 0.13838339782398426\n",
      "0.1623594728816493\n",
      "Epoch: 21\n",
      "Train:  0.20895669257162555\n",
      "Test 0.14008576057905897\n",
      "0.15787161588132148\n",
      "Epoch: 22\n",
      "Train:  0.20208863154285667\n",
      "Test 0.13319360962198987\n",
      "0.15290670698022385\n",
      "Epoch: 23\n",
      "Train:  0.195747331784349\n",
      "Test 0.13888780091421835\n",
      "0.15008962246151217\n",
      "Epoch: 24\n",
      "Train:  0.2001860836715243\n",
      "Test 0.1344601815368557\n",
      "0.14695188022155217\n",
      "Epoch: 25\n",
      "Train:  0.1912240663802613\n",
      "Test 0.13173668397651925\n",
      "0.14389961607019341\n",
      "Epoch: 26\n",
      "Train:  0.1903156768428264\n",
      "Test 0.12661326144422805\n",
      "0.14043396571661193\n",
      "Epoch: 27\n",
      "Train:  0.17599797287048438\n",
      "Test 0.1317275299148245\n",
      "0.13868930388948755\n",
      "Epoch: 28\n",
      "Train:  0.17821186931032837\n",
      "Test 0.12666046296693248\n",
      "0.13627980718942714\n",
      "Epoch: 29\n",
      "Train:  0.1703283675936061\n",
      "Test 0.12219548672983498\n",
      "0.13345945166648182\n",
      "Epoch: 30\n",
      "Train:  0.1607511390150685\n",
      "Test 0.13042431639254967\n",
      "0.13285182284525796\n",
      "Epoch: 31\n",
      "Train:  0.16710421708054268\n",
      "Test 0.13771202024959384\n",
      "0.1338246330657876\n",
      "Epoch: 32\n",
      "Train:  0.1645310138456264\n",
      "Test 0.13269769180661592\n",
      "0.13359910186657326\n",
      "Epoch: 33\n",
      "Train:  0.15831923235767273\n",
      "Test 0.123606540269522\n",
      "0.13159957566692815\n",
      "Epoch: 34\n",
      "Train:  0.14994086591601918\n",
      "Test 0.12751809835106462\n",
      "0.13078294894060027\n",
      "Epoch: 35\n",
      "Train:  0.15821840570414022\n",
      "Test 0.12210851560914787\n",
      "0.1290474990886339\n",
      "Epoch: 36\n",
      "Train:  0.14365809095486992\n",
      "Test 0.1374834847974253\n",
      "0.1307351343655595\n",
      "Epoch: 37\n",
      "Train:  0.1538130165744682\n",
      "Test 0.12854967843877635\n",
      "0.1302979523810571\n",
      "Epoch: 38\n",
      "Train:  0.14313729672484618\n",
      "Test 0.11978193771967412\n",
      "0.12819439993618043\n",
      "Epoch: 39\n",
      "Train:  0.13490801578687825\n",
      "Test 0.13916140234382693\n",
      "0.1303880920094015\n",
      "Epoch: 40\n",
      "Train:  0.13565689689226468\n",
      "Test 0.1197586103151433\n",
      "0.12826196958243366\n",
      "Epoch: 41\n",
      "Train:  0.12074226981127846\n",
      "Test 0.12213081656358181\n",
      "0.12703563465362527\n",
      "Epoch: 42\n",
      "Train:  0.12157155288171856\n",
      "Test 0.13167767439569747\n",
      "0.12796410579051093\n",
      "Epoch: 43\n",
      "Train:  0.12235631148165413\n",
      "Test 0.15655580943666958\n",
      "0.13368275787277722\n",
      "Epoch: 44\n",
      "Train:  0.14069202783557624\n",
      "Test 0.14297702272623886\n",
      "0.13554169181146195\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:51:35,393]\u001b[0m Trial 22 finished with value: 0.13642638430151696 and parameters: {'layer_size1': 384, 'layer_size2': 512, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 256, 'learning_rate': 3.590562184864779e-05, 'b1': 0.9873982127383564}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.13197961237431663\n",
      "Test 0.1399887689549626\n",
      "0.13643113823284644\n",
      "Epoch: 0\n",
      "Train:  0.6930047762699616\n",
      "Test 0.6943555247215998\n",
      "0.6943555247215998\n",
      "Epoch: 1\n",
      "Train:  1.0397825146114432\n",
      "Test 0.6939955216187698\n",
      "0.6941555229978054\n",
      "Epoch: 2\n",
      "Train:  1.0393111284399208\n",
      "Test 0.6936195855175619\n",
      "0.6939358764895089\n",
      "Epoch: 3\n",
      "Train:  1.0388713006353203\n",
      "Test 0.6931687479927426\n",
      "0.6936760091125556\n",
      "Epoch: 4\n",
      "Train:  1.038262380130125\n",
      "Test 0.6927051539822813\n",
      "0.6933872016606653\n",
      "Epoch: 5\n",
      "Train:  1.0376124473718495\n",
      "Test 0.6921980070980477\n",
      "0.6930648638162573\n",
      "Epoch: 6\n",
      "Train:  1.0368627718080095\n",
      "Test 0.6916805160787952\n",
      "0.6927145223349428\n",
      "Epoch: 7\n",
      "Train:  1.0360464041049664\n",
      "Test 0.6911720967554784\n",
      "0.692343848462878\n",
      "Epoch: 8\n",
      "Train:  1.035221075400328\n",
      "Test 0.6905873810851967\n",
      "0.691938095784754\n",
      "Epoch: 9\n",
      "Train:  1.0341503940004133\n",
      "Test 0.6897519333458646\n",
      "0.6914482684918873\n",
      "Epoch: 10\n",
      "Train:  1.0328390545897432\n",
      "Test 0.688704082162389\n",
      "0.6908478562030984\n",
      "Epoch: 11\n",
      "Train:  1.0312553309040629\n",
      "Test 0.6874105279698913\n",
      "0.6901096622545855\n",
      "Epoch: 12\n",
      "Train:  1.0293306778202127\n",
      "Test 0.6860711574554443\n",
      "0.6892549743291504\n",
      "Epoch: 13\n",
      "Train:  1.027141286776616\n",
      "Test 0.6843929238371796\n",
      "0.6882378297385776\n",
      "Epoch: 14\n",
      "Train:  1.024454341703282\n",
      "Test 0.682385347701691\n",
      "0.6870246483042021\n",
      "Epoch: 15\n",
      "Train:  1.02129944951543\n",
      "Test 0.6800656187665332\n",
      "0.6855925319036181\n",
      "Epoch: 16\n",
      "Train:  1.0176730046778808\n",
      "Test 0.67726388999394\n",
      "0.6838884305710508\n",
      "Epoch: 17\n",
      "Train:  1.013238168679751\n",
      "Test 0.6739437748224307\n",
      "0.6818630127373216\n",
      "Epoch: 18\n",
      "Train:  1.00808500512179\n",
      "Test 0.6700298773063408\n",
      "0.6794617802438848\n",
      "Epoch: 19\n",
      "Train:  1.0017866522837908\n",
      "Test 0.6652298257464454\n",
      "0.6765821899284052\n",
      "Epoch: 20\n",
      "Train:  0.9945758417412475\n",
      "Test 0.6600541448418474\n",
      "0.6732458082213525\n",
      "Epoch: 21\n",
      "Train:  0.9862286638427566\n",
      "Test 0.653544177939167\n",
      "0.6692761915638952\n",
      "Epoch: 22\n",
      "Train:  0.9762835199142987\n",
      "Test 0.6455616732656737\n",
      "0.6645051244952352\n",
      "Epoch: 23\n",
      "Train:  0.9642299361281342\n",
      "Test 0.6367151483947977\n",
      "0.6589207578492707\n",
      "Epoch: 24\n",
      "Train:  0.9504220051206512\n",
      "Test 0.6258658321349175\n",
      "0.6522847023977258\n",
      "Epoch: 25\n",
      "Train:  0.9338665046753027\n",
      "Test 0.6133546820490352\n",
      "0.6444750952386484\n",
      "Epoch: 26\n",
      "Train:  0.9143809256972847\n",
      "Test 0.5986964318341824\n",
      "0.6352971717002833\n",
      "Epoch: 27\n",
      "Train:  0.8920454618695018\n",
      "Test 0.5811297255994636\n",
      "0.6244426868529345\n",
      "Epoch: 28\n",
      "Train:  0.8654981002266153\n",
      "Test 0.5616769397651756\n",
      "0.6118700822721218\n",
      "Epoch: 29\n",
      "Train:  0.8368374852688758\n",
      "Test 0.5402848072104401\n",
      "0.597535281636123\n",
      "Epoch: 30\n",
      "Train:  0.8044818684513315\n",
      "Test 0.5161356428167322\n",
      "0.5812392150295767\n",
      "Epoch: 31\n",
      "Train:  0.7699545658988394\n",
      "Test 0.49218646052119497\n",
      "0.5634145419669587\n",
      "Epoch: 32\n",
      "Train:  0.7342970835201906\n",
      "Test 0.46554432127065276\n",
      "0.5438280834347402\n",
      "Epoch: 33\n",
      "Train:  0.6943600483975567\n",
      "Test 0.4355134995647402\n",
      "0.5221541766843797\n",
      "Epoch: 34\n",
      "Train:  0.6511084828730468\n",
      "Test 0.4046308222489479\n",
      "0.49863996730076876\n",
      "Epoch: 35\n",
      "Train:  0.6072297615882678\n",
      "Test 0.3731532673259358\n",
      "0.47353448010940996\n",
      "Epoch: 36\n",
      "Train:  0.5626651146909692\n",
      "Test 0.34201294827810574\n",
      "0.44722334298141636\n",
      "Epoch: 37\n",
      "Train:  0.5200000761738627\n",
      "Test 0.3139119791242229\n",
      "0.42055553152223124\n",
      "Epoch: 38\n",
      "Train:  0.481700426301895\n",
      "Test 0.2882169381930278\n",
      "0.39408341442149575\n",
      "Epoch: 39\n",
      "Train:  0.44731444385134694\n",
      "Test 0.26568570962319005\n",
      "0.3684004596115798\n",
      "Epoch: 40\n",
      "Train:  0.41706406622579245\n",
      "Test 0.24627033181679556\n",
      "0.3439718363558285\n",
      "Epoch: 41\n",
      "Train:  0.39148107422140493\n",
      "Test 0.23063342218652313\n",
      "0.3213022250047155\n",
      "Epoch: 42\n",
      "Train:  0.37035739730238476\n",
      "Test 0.21749094761771598\n",
      "0.30053855642525756\n",
      "Epoch: 43\n",
      "Train:  0.3531858780226865\n",
      "Test 0.20619566209150322\n",
      "0.2816689501994236\n",
      "Epoch: 44\n",
      "Train:  0.33808205999952534\n",
      "Test 0.19706998246930021\n",
      "0.26474841966035173\n",
      "Epoch: 45\n",
      "Train:  0.3241762180741017\n",
      "Test 0.19127190833563332\n",
      "0.25005260532101575\n",
      "Epoch: 46\n",
      "Train:  0.3149272967880462\n",
      "Test 0.18415159773040604\n",
      "0.23687203638225696\n",
      "Epoch: 47\n",
      "Train:  0.30511814803430887\n",
      "Test 0.17796018173843076\n",
      "0.22508940269198002\n",
      "Epoch: 48\n",
      "Train:  0.2953858182325468\n",
      "Test 0.174454282109554\n",
      "0.2149621979001239\n",
      "Epoch: 49\n",
      "Train:  0.2883929724057952\n",
      "Test 0.17032816281521712\n",
      "0.20603526347367693\n",
      "Epoch: 50\n",
      "Train:  0.2811414361368496\n",
      "Test 0.16642244353945002\n",
      "0.1981126090261093\n",
      "Epoch: 51\n",
      "Train:  0.2757486202805252\n",
      "Test 0.16484529486833474\n",
      "0.1914590854187066\n",
      "Epoch: 52\n",
      "Train:  0.270812191628602\n",
      "Test 0.1622449517686725\n",
      "0.1856162159918836\n",
      "Epoch: 53\n",
      "Train:  0.26644352848740505\n",
      "Test 0.15920828375624213\n",
      "0.18033459866838586\n",
      "Epoch: 54\n",
      "Train:  0.2621984844242697\n",
      "Test 0.15820074916540922\n",
      "0.17590780806455303\n",
      "Epoch: 55\n",
      "Train:  0.25944489048923547\n",
      "Test 0.15771298287197566\n",
      "0.17226882941100202\n",
      "Epoch: 56\n",
      "Train:  0.2565542967212233\n",
      "Test 0.15583500320658142\n",
      "0.16898205433228947\n",
      "Epoch: 57\n",
      "Train:  0.2537286362232088\n",
      "Test 0.15515859123496784\n",
      "0.16621735509268568\n",
      "Epoch: 58\n",
      "Train:  0.25226011213542887\n",
      "Test 0.1556698963209823\n",
      "0.1641078592973539\n",
      "Epoch: 59\n",
      "Train:  0.25020089469877355\n",
      "Test 0.15385383136925243\n",
      "0.16205705056887837\n",
      "Epoch: 60\n",
      "Train:  0.24797692884701295\n",
      "Test 0.15299820496390262\n",
      "0.160245279226658\n",
      "Epoch: 61\n",
      "Train:  0.24597831911172022\n",
      "Test 0.1520933761865228\n",
      "0.15861489701955675\n",
      "Epoch: 62\n",
      "Train:  0.24463361445746143\n",
      "Test 0.15308488764878594\n",
      "0.1575088942775911\n",
      "Epoch: 63\n",
      "Train:  0.24322295742239053\n",
      "Test 0.15111451634229758\n",
      "0.15623001788776866\n",
      "Epoch: 64\n",
      "Train:  0.24083826091181446\n",
      "Test 0.15014481326162596\n",
      "0.15501297635138064\n",
      "Epoch: 65\n",
      "Train:  0.2395176663721874\n",
      "Test 0.1513109504084884\n",
      "0.15427257086535578\n",
      "Epoch: 66\n",
      "Train:  0.23830890257061618\n",
      "Test 0.1494738279053798\n",
      "0.15331282196490917\n",
      "Epoch: 67\n",
      "Train:  0.23634821444667958\n",
      "Test 0.14913287859805774\n",
      "0.1524768330765977\n",
      "Epoch: 68\n",
      "Train:  0.23541905994666912\n",
      "Test 0.14852745083907803\n",
      "0.15168695646662556\n",
      "Epoch: 69\n",
      "Train:  0.2335635982624395\n",
      "Test 0.14991257511652434\n",
      "0.15133208013821026\n",
      "Epoch: 70\n",
      "Train:  0.23353282001974818\n",
      "Test 0.1497223175952941\n",
      "0.15101012758724508\n",
      "Epoch: 71\n",
      "Train:  0.23235325338898888\n",
      "Test 0.14716885312572942\n",
      "0.15024187261403524\n",
      "Epoch: 72\n",
      "Train:  0.23003264268921628\n",
      "Test 0.1476322762922285\n",
      "0.14971995330570229\n",
      "Epoch: 73\n",
      "Train:  0.22870417882563826\n",
      "Test 0.1479703419374459\n",
      "0.1493700310084663\n",
      "Epoch: 74\n",
      "Train:  0.2274930052622989\n",
      "Test 0.1460642439105135\n",
      "0.1487088735532262\n",
      "Epoch: 75\n",
      "Train:  0.22600222643696782\n",
      "Test 0.14611393127474429\n",
      "0.14818988507514277\n",
      "Epoch: 76\n",
      "Train:  0.22436293796636164\n",
      "Test 0.1470259136823944\n",
      "0.14795709078855965\n",
      "Epoch: 77\n",
      "Train:  0.22400388293541396\n",
      "Test 0.1454148001068241\n",
      "0.14744863263817554\n",
      "Epoch: 78\n",
      "Train:  0.22179761327011682\n",
      "Test 0.14443766852779374\n",
      "0.1468464398027994\n",
      "Epoch: 79\n",
      "Train:  0.22051572313040987\n",
      "Test 0.1438278513022395\n",
      "0.14624272209202066\n",
      "Epoch: 80\n",
      "Train:  0.21920912398960127\n",
      "Test 0.14562660390204127\n",
      "0.14611949845228303\n",
      "Epoch: 81\n",
      "Train:  0.21871409237712294\n",
      "Test 0.14384518023375625\n",
      "0.14566463480343414\n",
      "Epoch: 82\n",
      "Train:  0.21653935332328844\n",
      "Test 0.14276564385973928\n",
      "0.14508483660945018\n",
      "Epoch: 83\n",
      "Train:  0.21530430836282372\n",
      "Test 0.14398466187082368\n",
      "0.1448648016601325\n",
      "Epoch: 84\n",
      "Train:  0.21461004981491374\n",
      "Test 0.14212274219799828\n",
      "0.14431638976453057\n",
      "Epoch: 85\n",
      "Train:  0.21228200009590759\n",
      "Test 0.14220299932000402\n",
      "0.14389371167366757\n",
      "Epoch: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:52:30,120]\u001b[0m Trial 23 finished with value: 0.1440330676906007 and parameters: {'layer_size1': 384, 'layer_size2': 512, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 192, 'learning_rate': 5.868108339245412e-06, 'b1': 0.9894026507662694}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.21233295889114176\n",
      "Test 0.14459049442421384\n",
      "0.14403306822429318\n",
      "Epoch: 0\n",
      "Train:  0.692618326608078\n",
      "Test 0.6930505388822311\n",
      "0.6930505388822311\n",
      "Epoch: 1\n",
      "Train:  1.0380496811735762\n",
      "Test 0.6919959879620171\n",
      "0.6924646772598901\n",
      "Epoch: 2\n",
      "Train:  1.0362604616325855\n",
      "Test 0.6904611395392226\n",
      "0.6916435552432232\n",
      "Epoch: 3\n",
      "Train:  1.033320162759159\n",
      "Test 0.6880008912348485\n",
      "0.6904095904707385\n",
      "Epoch: 4\n",
      "Train:  1.0287915869946882\n",
      "Test 0.6835204052837777\n",
      "0.6883602136302575\n",
      "Epoch: 5\n",
      "Train:  1.0206945614937024\n",
      "Test 0.676131274892297\n",
      "0.6850454913164292\n",
      "Epoch: 6\n",
      "Train:  1.0070658375273693\n",
      "Test 0.6628100112244323\n",
      "0.6794182844937756\n",
      "Epoch: 7\n",
      "Train:  0.9835690552498395\n",
      "Test 0.6392127995962625\n",
      "0.6697561504085922\n",
      "Epoch: 8\n",
      "Train:  0.9461301283521967\n",
      "Test 0.6070766370375078\n",
      "0.6552768718652024\n",
      "Epoch: 9\n",
      "Train:  0.8902038294317085\n",
      "Test 0.5530211202827565\n",
      "0.6323656475725015\n",
      "Epoch: 10\n",
      "Train:  0.8020224561403085\n",
      "Test 0.4749545924392812\n",
      "0.5979250081460595\n",
      "Epoch: 11\n",
      "Train:  0.6868726499788054\n",
      "Test 0.39070957003932294\n",
      "0.5534238223206592\n",
      "Epoch: 12\n",
      "Train:  0.5779485818230625\n",
      "Test 0.32267394738319594\n",
      "0.5045891318315878\n",
      "Epoch: 13\n",
      "Train:  0.49721197636572867\n",
      "Test 0.2824182588975508\n",
      "0.4581108194486004\n",
      "Epoch: 14\n",
      "Train:  0.4515246779763655\n",
      "Test 0.25997617738423767\n",
      "0.41703879774154634\n",
      "Epoch: 15\n",
      "Train:  0.42565460015265716\n",
      "Test 0.2466365411168053\n",
      "0.38197128364524235\n",
      "Epoch: 16\n",
      "Train:  0.3994092167297126\n",
      "Test 0.23652509699538077\n",
      "0.3522119251358005\n",
      "Epoch: 17\n",
      "Train:  0.3825070742353961\n",
      "Test 0.22712046556147464\n",
      "0.3267346759002813\n",
      "Epoch: 18\n",
      "Train:  0.36283362448734024\n",
      "Test 0.21931988414336037\n",
      "0.30493758841261803\n",
      "Epoch: 19\n",
      "Train:  0.34458214109388247\n",
      "Test 0.20763142073984112\n",
      "0.28524936511782195\n",
      "Epoch: 20\n",
      "Train:  0.3259795403360447\n",
      "Test 0.20579818600700014\n",
      "0.2692112033630057\n",
      "Epoch: 21\n",
      "Train:  0.31728332132210224\n",
      "Test 0.1889534986171967\n",
      "0.2530403425212844\n",
      "Epoch: 22\n",
      "Train:  0.29501274077992734\n",
      "Test 0.17958464661797324\n",
      "0.23826196721032245\n",
      "Epoch: 23\n",
      "Train:  0.27480762293596406\n",
      "Test 0.17184100133595448\n",
      "0.224914743553814\n",
      "Epoch: 24\n",
      "Train:  0.25704873830844194\n",
      "Test 0.16228289934277754\n",
      "0.2123408719678166\n",
      "Epoch: 25\n",
      "Train:  0.2425054558774545\n",
      "Test 0.15546723549346347\n",
      "0.20093166245303645\n",
      "Epoch: 26\n",
      "Train:  0.23202308321255685\n",
      "Test 0.15049314646275488\n",
      "0.19081950956955468\n",
      "Epoch: 27\n",
      "Train:  0.22485477373604373\n",
      "Test 0.14995102477925165\n",
      "0.18262997174152446\n",
      "Epoch: 28\n",
      "Train:  0.2176352175355176\n",
      "Test 0.14803244984084432\n",
      "0.17569974335238303\n",
      "Epoch: 29\n",
      "Train:  0.21334014763380146\n",
      "Test 0.14291237638888013\n",
      "0.16913414213905847\n",
      "Epoch: 30\n",
      "Train:  0.2070508502686444\n",
      "Test 0.14271845174578082\n",
      "0.16384576670705092\n",
      "Epoch: 31\n",
      "Train:  0.20507184580486992\n",
      "Test 0.13909139653374425\n",
      "0.1588909670756854\n",
      "Epoch: 32\n",
      "Train:  0.19719333032098335\n",
      "Test 0.13866873254706136\n",
      "0.15484395507136237\n",
      "Epoch: 33\n",
      "Train:  0.19457461334075846\n",
      "Test 0.13812790421987356\n",
      "0.15149904883210383\n",
      "Epoch: 34\n",
      "Train:  0.20440751941100227\n",
      "Test 0.13836425612424755\n",
      "0.14887102423710688\n",
      "Epoch: 35\n",
      "Train:  0.19985919967020824\n",
      "Test 0.138059183436654\n",
      "0.14670795412063065\n",
      "Epoch: 36\n",
      "Train:  0.19126725026266478\n",
      "Test 0.14967208060490533\n",
      "0.14730093336369862\n",
      "Epoch: 37\n",
      "Train:  0.19055156053373107\n",
      "Test 0.13563434669113422\n",
      "0.14496713131746441\n",
      "Epoch: 38\n",
      "Train:  0.18095865051838614\n",
      "Test 0.1348072799407082\n",
      "0.1429348233670352\n",
      "Epoch: 39\n",
      "Train:  0.17917208366723725\n",
      "Test 0.1351306691438287\n",
      "0.1413737850248072\n",
      "Epoch: 40\n",
      "Train:  0.17804183708606186\n",
      "Test 0.13329888339881057\n",
      "0.13975863294717916\n",
      "Epoch: 41\n",
      "Train:  0.1740785122954802\n",
      "Test 0.1408182570639138\n",
      "0.13997057580063005\n",
      "Epoch: 42\n",
      "Train:  0.17720804203919138\n",
      "Test 0.13791258882726082\n",
      "0.13955895039218252\n",
      "Epoch: 43\n",
      "Train:  0.1720346748181141\n",
      "Test 0.13557771527832682\n",
      "0.13876266001523951\n",
      "Epoch: 44\n",
      "Train:  0.16693602432752705\n",
      "Test 0.13646595126816205\n",
      "0.13830329825779766\n",
      "Epoch: 45\n",
      "Train:  0.1663817660507811\n",
      "Test 0.13050393230749138\n",
      "0.13674337071219467\n",
      "Epoch: 46\n",
      "Train:  0.1746077950184162\n",
      "Test 0.14368274346703575\n",
      "0.1381312839525373\n",
      "Epoch: 47\n",
      "Train:  0.17431691011086434\n",
      "Test 0.12827962331282786\n",
      "0.13616090788374074\n",
      "Epoch: 48\n",
      "Train:  0.16401277766341255\n",
      "Test 0.13587062193196772\n",
      "0.1361028496575928\n",
      "Epoch: 49\n",
      "Train:  0.15533059882511804\n",
      "Test 0.12770244998400246\n",
      "0.1344227457436304\n",
      "Epoch: 50\n",
      "Train:  0.15688724608088916\n",
      "Test 0.13120519964113123\n",
      "0.13377922917547028\n",
      "Epoch: 51\n",
      "Train:  0.15154117982725412\n",
      "Test 0.13414860911575238\n",
      "0.1338531058383446\n",
      "Epoch: 52\n",
      "Train:  0.15378524258864137\n",
      "Test 0.1280585101126751\n",
      "0.13269417822433766\n",
      "Epoch: 53\n",
      "Train:  0.14724035667521612\n",
      "Test 0.12826971978549556\n",
      "0.13180928136345638\n",
      "Epoch: 54\n",
      "Train:  0.14279870538129694\n",
      "Test 0.13219207859744792\n",
      "0.13188584116830998\n",
      "Epoch: 55\n",
      "Train:  0.1438994812941172\n",
      "Test 0.13063745246688416\n",
      "0.131636162493866\n",
      "Epoch: 56\n",
      "Train:  0.14141514737520627\n",
      "Test 0.12901174358600553\n",
      "0.1311112771412305\n",
      "Epoch: 57\n",
      "Train:  0.14598464876099493\n",
      "Test 0.14828029973602994\n",
      "0.13454508988253838\n",
      "Epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:53:08,277]\u001b[0m Trial 24 finished with value: 0.1332586563486111 and parameters: {'layer_size1': 384, 'layer_size2': 384, 'layer_size3': 384, 'layer_size4': 192, 'layer_size5': 256, 'learning_rate': 1.7228295491069393e-05, 'b1': 0.9735326958525038}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.15370660633166003\n",
      "Test 0.12811421089884126\n",
      "0.1332589116219709\n",
      "Epoch: 0\n",
      "Train:  0.6927887821372175\n",
      "Test 0.6932505591885074\n",
      "0.6932505591885074\n",
      "Epoch: 1\n",
      "Train:  1.0388459006508628\n",
      "Test 0.6928419534103337\n",
      "0.6930235559784111\n",
      "Epoch: 2\n",
      "Train:  1.0381788329763726\n",
      "Test 0.6924857239583473\n",
      "0.6928031330193685\n",
      "Epoch: 3\n",
      "Train:  1.0373696450130407\n",
      "Test 0.6918210970176445\n",
      "0.6924704649971042\n",
      "Epoch: 4\n",
      "Train:  1.036321093529572\n",
      "Test 0.6909268989667787\n",
      "0.6920112890004582\n",
      "Epoch: 5\n",
      "Train:  1.0348797540961605\n",
      "Test 0.6897700396212902\n",
      "0.6914037858076488\n",
      "Epoch: 6\n",
      "Train:  1.0329417946574453\n",
      "Test 0.6881136667160761\n",
      "0.6905711444379622\n",
      "Epoch: 7\n",
      "Train:  1.0304242769877117\n",
      "Test 0.6859752201771998\n",
      "0.689466657411726\n",
      "Epoch: 8\n",
      "Train:  1.0269948907824227\n",
      "Test 0.683235587654533\n",
      "0.688027249385318\n",
      "Epoch: 9\n",
      "Train:  1.0225593471701766\n",
      "Test 0.6796045381944258\n",
      "0.6861400731408445\n",
      "Epoch: 10\n",
      "Train:  1.0166019685975798\n",
      "Test 0.6745034591618911\n",
      "0.6835940484931179\n",
      "Epoch: 11\n",
      "Train:  1.0087250564997887\n",
      "Test 0.6683406521985819\n",
      "0.6803182586717921\n",
      "Epoch: 12\n",
      "Train:  0.9985930169676687\n",
      "Test 0.6597575438328278\n",
      "0.6759668970701139\n",
      "Epoch: 13\n",
      "Train:  0.9855460487442576\n",
      "Test 0.6495836287627726\n",
      "0.6704474976552462\n",
      "Epoch: 14\n",
      "Train:  0.9700007543459044\n",
      "Test 0.6369506269147545\n",
      "0.6635038143708011\n",
      "Epoch: 15\n",
      "Train:  0.9504953900099674\n",
      "Test 0.6211206685929072\n",
      "0.654781678928164\n",
      "Epoch: 16\n",
      "Train:  0.9258399913599203\n",
      "Test 0.6004273542117723\n",
      "0.6436603847022266\n",
      "Epoch: 17\n",
      "Train:  0.8941101857594081\n",
      "Test 0.5736418661180434\n",
      "0.62939978485679\n",
      "Epoch: 18\n",
      "Train:  0.8544739646352691\n",
      "Test 0.5417689613370231\n",
      "0.611617348232988\n",
      "Epoch: 19\n",
      "Train:  0.8082830435408778\n",
      "Test 0.5071320341620253\n",
      "0.590476548593506\n",
      "Epoch: 20\n",
      "Train:  0.7572121313421718\n",
      "Test 0.4647477918710464\n",
      "0.5650967095512923\n",
      "Epoch: 21\n",
      "Train:  0.6988724782899186\n",
      "Test 0.42337700779184756\n",
      "0.536542073171638\n",
      "Epoch: 22\n",
      "Train:  0.6419532075251415\n",
      "Test 0.3830694152322008\n",
      "0.5056652771504647\n",
      "Epoch: 23\n",
      "Train:  0.5912494115777068\n",
      "Test 0.3487113168933889\n",
      "0.47412554291521836\n",
      "Epoch: 24\n",
      "Train:  0.5463028531862703\n",
      "Test 0.3208990561274382\n",
      "0.44336403185462636\n",
      "Epoch: 25\n",
      "Train:  0.5118886404994861\n",
      "Test 0.2988052888340129\n",
      "0.414364637960424\n",
      "Epoch: 26\n",
      "Train:  0.48414448897043866\n",
      "Test 0.28201633074999727\n",
      "0.38783082168716737\n",
      "Epoch: 27\n",
      "Train:  0.463096705466618\n",
      "Test 0.2685133893138323\n",
      "0.3639210870596502\n",
      "Epoch: 28\n",
      "Train:  0.44465012396702835\n",
      "Test 0.25803353585603034\n",
      "0.3427107554204479\n",
      "Epoch: 29\n",
      "Train:  0.4290552881338221\n",
      "Test 0.24909125437666646\n",
      "0.32396364741607214\n",
      "Epoch: 30\n",
      "Train:  0.41439615932358054\n",
      "Test 0.2398369766417004\n",
      "0.3071216337387391\n",
      "Epoch: 31\n",
      "Train:  0.40067244187379497\n",
      "Test 0.232304070131246\n",
      "0.2921462563008669\n",
      "Epoch: 32\n",
      "Train:  0.38773994660857836\n",
      "Test 0.2256806743068573\n",
      "0.2788447090448835\n",
      "Epoch: 33\n",
      "Train:  0.3759302823998771\n",
      "Test 0.21824543290658965\n",
      "0.2667187052028052\n",
      "Epoch: 34\n",
      "Train:  0.36295856900117446\n",
      "Test 0.21162360873851147\n",
      "0.25569521425077146\n",
      "Epoch: 35\n",
      "Train:  0.35154402258741113\n",
      "Test 0.20494974783925346\n",
      "0.2455428263302237\n",
      "Epoch: 36\n",
      "Train:  0.33929912986117844\n",
      "Test 0.19884664905104008\n",
      "0.23620116564061436\n",
      "Epoch: 37\n",
      "Train:  0.3327196994421137\n",
      "Test 0.19372544167460976\n",
      "0.2277042561083466\n",
      "Epoch: 38\n",
      "Train:  0.3197683294614156\n",
      "Test 0.18881916546777927\n",
      "0.21992594558672\n",
      "Epoch: 39\n",
      "Train:  0.30848091518704274\n",
      "Test 0.1812300892758282\n",
      "0.21218574547547353\n",
      "Epoch: 40\n",
      "Train:  0.2971299176305642\n",
      "Test 0.1765900007125004\n",
      "0.2050658394046008\n",
      "Epoch: 41\n",
      "Train:  0.2888615629379893\n",
      "Test 0.17333015220942516\n",
      "0.19871816196488976\n",
      "Epoch: 42\n",
      "Train:  0.28241203163133\n",
      "Test 0.16864413448742457\n",
      "0.19270294709508604\n",
      "Epoch: 43\n",
      "Train:  0.27398163904418876\n",
      "Test 0.16565536251871577\n",
      "0.1872931356416606\n",
      "Epoch: 44\n",
      "Train:  0.26803220431883257\n",
      "Test 0.16431801602408125\n",
      "0.18269791156790804\n",
      "Epoch: 45\n",
      "Train:  0.26488182864291765\n",
      "Test 0.16117104207039315\n",
      "0.17839238764279253\n",
      "Epoch: 46\n",
      "Train:  0.2613277409989864\n",
      "Test 0.1593774044852117\n",
      "0.1745892849962475\n",
      "Epoch: 47\n",
      "Train:  0.25495772826529683\n",
      "Test 0.15813773553886692\n",
      "0.1712989017267725\n",
      "Epoch: 48\n",
      "Train:  0.25282009491772006\n",
      "Test 0.1566915775993805\n",
      "0.16837738477969008\n",
      "Epoch: 49\n",
      "Train:  0.2517728122435647\n",
      "Test 0.1562161772842809\n",
      "0.1659451085660021\n",
      "Epoch: 50\n",
      "Train:  0.2529937455587553\n",
      "Test 0.1545980208631837\n",
      "0.16367566511297496\n",
      "Epoch: 51\n",
      "Train:  0.24853833587055568\n",
      "Test 0.15417636728985407\n",
      "0.16177578819414307\n",
      "Epoch: 52\n",
      "Train:  0.24482707100691814\n",
      "Test 0.15339884403478968\n",
      "0.1601003871192653\n",
      "Epoch: 53\n",
      "Train:  0.24095316600368355\n",
      "Test 0.1522331231243008\n",
      "0.15852692512180325\n",
      "Epoch: 54\n",
      "Train:  0.23885200198589665\n",
      "Test 0.15309646329927795\n",
      "0.157440827677832\n",
      "Epoch: 55\n",
      "Train:  0.23839645408394136\n",
      "Test 0.15069182020622296\n",
      "0.15609102113328432\n",
      "Epoch: 56\n",
      "Train:  0.23442246579316073\n",
      "Test 0.15210165336537054\n",
      "0.1552931451915349\n",
      "Epoch: 57\n",
      "Train:  0.23351749978045294\n",
      "Test 0.14952193686376997\n",
      "0.15413890076211562\n",
      "Epoch: 58\n",
      "Train:  0.23102679553922717\n",
      "Test 0.1517529034775583\n",
      "0.15366170039106983\n",
      "Epoch: 59\n",
      "Train:  0.23039478353896747\n",
      "Test 0.14847739109080352\n",
      "0.15262483694202797\n",
      "Epoch: 60\n",
      "Train:  0.2275522723930441\n",
      "Test 0.14803871336382823\n",
      "0.15170761110187242\n",
      "Epoch: 61\n",
      "Train:  0.2254234611810673\n",
      "Test 0.14963830297901518\n",
      "0.15129374907138624\n",
      "Epoch: 62\n",
      "Train:  0.2261102863010906\n",
      "Test 0.14691938891078962\n",
      "0.1504188763528088\n",
      "Epoch: 63\n",
      "Train:  0.22262832216727427\n",
      "Test 0.14764242792235954\n",
      "0.14986358631815772\n",
      "Epoch: 64\n",
      "Train:  0.22115801005102284\n",
      "Test 0.1469151555754981\n",
      "0.14927389987350406\n",
      "Epoch: 65\n",
      "Train:  0.21908604204245322\n",
      "Test 0.14532632356161598\n",
      "0.1484843842939508\n",
      "Epoch: 66\n",
      "Train:  0.21768163734084958\n",
      "Test 0.14534330368041992\n",
      "0.14785616796934367\n",
      "Epoch: 67\n",
      "Train:  0.21686042640562897\n",
      "Test 0.14623389713084087\n",
      "0.14753171371822263\n",
      "Epoch: 68\n",
      "Train:  0.21680264332205493\n",
      "Test 0.14862555680257497\n",
      "0.1477504823800912\n",
      "Epoch: 69\n",
      "Train:  0.21673936350441678\n",
      "Test 0.14426600605576903\n",
      "0.14705358700055232\n",
      "Epoch: 70\n",
      "Train:  0.21680268252288903\n",
      "Test 0.14997723415466674\n",
      "0.14763831650834922\n",
      "Epoch: 71\n",
      "Train:  0.21555678053134744\n",
      "Test 0.142999468802819\n",
      "0.14671054686953763\n",
      "Epoch: 72\n",
      "Train:  0.2099529383200879\n",
      "Test 0.14319340007263662\n",
      "0.1460071174508936\n",
      "Epoch: 73\n",
      "Train:  0.2072777016559145\n",
      "Test 0.142892140963357\n",
      "0.14538412211139648\n",
      "Epoch: 74\n",
      "Train:  0.20614699488539837\n",
      "Test 0.14262909632544596\n",
      "0.14483311692449624\n",
      "Epoch: 75\n",
      "Train:  0.20572330288575355\n",
      "Test 0.14172937194287996\n",
      "0.1442123679013964\n",
      "Epoch: 76\n",
      "Train:  0.20324101134616157\n",
      "Test 0.14280806288068548\n",
      "0.14393150688756207\n",
      "Epoch: 77\n",
      "Train:  0.2028967233804556\n",
      "Test 0.1410092987911605\n",
      "0.14334706525214708\n",
      "Epoch: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:53:57,675]\u001b[0m Trial 25 finished with value: 0.14374058724157474 and parameters: {'layer_size1': 384, 'layer_size2': 384, 'layer_size3': 256, 'layer_size4': 256, 'layer_size5': 192, 'learning_rate': 7.379342839344882e-06, 'b1': 0.9628205448212606}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.2007785270011032\n",
      "Test 0.14531469102880676\n",
      "0.14374059041617024\n",
      "Epoch: 0\n",
      "Train:  0.6933893847378182\n",
      "Test 0.6921311970595475\n",
      "0.6921311970595474\n",
      "Epoch: 1\n",
      "Train:  1.0381491424399854\n",
      "Test 0.6914413879205893\n",
      "0.6917479697601263\n",
      "Epoch: 2\n",
      "Train:  1.0365685521464645\n",
      "Test 0.6904710670967242\n",
      "0.691224648996437\n",
      "Epoch: 3\n",
      "Train:  1.0343520132613269\n",
      "Test 0.6886927059718541\n",
      "0.6903669447198167\n",
      "Epoch: 4\n",
      "Train:  1.0310626711164201\n",
      "Test 0.6862313341308426\n",
      "0.6891366940686464\n",
      "Epoch: 5\n",
      "Train:  1.0265239064510052\n",
      "Test 0.6824208921565241\n",
      "0.6873163383590982\n",
      "Epoch: 6\n",
      "Train:  1.0195045514857812\n",
      "Test 0.6762194834349357\n",
      "0.6845080204149437\n",
      "Epoch: 7\n",
      "Train:  1.009010462970524\n",
      "Test 0.6669748528099759\n",
      "0.68029447052818\n",
      "Epoch: 8\n",
      "Train:  0.9938903673664554\n",
      "Test 0.6531418072871673\n",
      "0.6740220706144491\n",
      "Epoch: 9\n",
      "Train:  0.9703843680930225\n",
      "Test 0.6314887212309646\n",
      "0.6644921312950053\n",
      "Epoch: 10\n",
      "Train:  0.9343847190285777\n",
      "Test 0.5971904148112287\n",
      "0.6497669002860607\n",
      "Epoch: 11\n",
      "Train:  0.8792659484204792\n",
      "Test 0.5501744089982449\n",
      "0.6283786099052506\n",
      "Epoch: 12\n",
      "Train:  0.8060550872004513\n",
      "Test 0.4872420174734933\n",
      "0.598509203432311\n",
      "Epoch: 13\n",
      "Train:  0.714289767183227\n",
      "Test 0.4143329524731898\n",
      "0.5599793943148617\n",
      "Epoch: 14\n",
      "Train:  0.6129593229119158\n",
      "Test 0.3417611102481465\n",
      "0.5147441643385067\n",
      "Epoch: 15\n",
      "Train:  0.5180831364877931\n",
      "Test 0.2876887253243408\n",
      "0.4680178476453761\n",
      "Epoch: 16\n",
      "Train:  0.4550727528038916\n",
      "Test 0.24988395619741727\n",
      "0.42338605063383405\n",
      "Epoch: 17\n",
      "Train:  0.4104770112496156\n",
      "Test 0.22692665916222793\n",
      "0.3833733679278131\n",
      "Epoch: 18\n",
      "Train:  0.3774552527037296\n",
      "Test 0.2118877025641801\n",
      "0.34857473368319186\n",
      "Epoch: 19\n",
      "Train:  0.3571692460349628\n",
      "Test 0.19885097029226603\n",
      "0.318280714746071\n",
      "Epoch: 20\n",
      "Train:  0.3345357018894765\n",
      "Test 0.18890921277550113\n",
      "0.292165544420236\n",
      "Epoch: 21\n",
      "Train:  0.31243017764809805\n",
      "Test 0.1793298379760304\n",
      "0.2694306492140303\n",
      "Epoch: 22\n",
      "Train:  0.29575016988857544\n",
      "Test 0.17097235501030864\n",
      "0.24962206110760252\n",
      "Epoch: 23\n",
      "Train:  0.2803804877149316\n",
      "Test 0.1649813929115569\n",
      "0.2326136073162838\n",
      "Epoch: 24\n",
      "Train:  0.26883642044900863\n",
      "Test 0.16112390141456556\n",
      "0.21826144520047422\n",
      "Epoch: 25\n",
      "Train:  0.2607593341652072\n",
      "Test 0.1569084135658575\n",
      "0.2059536408172969\n",
      "Epoch: 26\n",
      "Train:  0.25316317910294395\n",
      "Test 0.15501476586847515\n",
      "0.1957411735969232\n",
      "Epoch: 27\n",
      "Train:  0.24843565272951956\n",
      "Test 0.1545233043736263\n",
      "0.1874816234587912\n",
      "Epoch: 28\n",
      "Train:  0.24548300197723258\n",
      "Test 0.15176680080947422\n",
      "0.18032758859617923\n",
      "Epoch: 29\n",
      "Train:  0.24327673082113702\n",
      "Test 0.15071449645764226\n",
      "0.17439762923434649\n",
      "Epoch: 30\n",
      "Train:  0.23891753445451075\n",
      "Test 0.15098893773424757\n",
      "0.16971124976890306\n",
      "Epoch: 31\n",
      "Train:  0.23684176939092713\n",
      "Test 0.14850075296279822\n",
      "0.16546578680538584\n",
      "Epoch: 32\n",
      "Train:  0.23199673182068345\n",
      "Test 0.15011437074707706\n",
      "0.16239355633632502\n",
      "Epoch: 33\n",
      "Train:  0.2316384010704323\n",
      "Test 0.14696254321943708\n",
      "0.1593057880284079\n",
      "Epoch: 34\n",
      "Train:  0.22775808626260513\n",
      "Test 0.1463447597403175\n",
      "0.1567125304205296\n",
      "Epoch: 35\n",
      "Train:  0.22634096391628677\n",
      "Test 0.14609241583845117\n",
      "0.15458781799551083\n",
      "Epoch: 36\n",
      "Train:  0.22542487277270673\n",
      "Test 0.14660916381921524\n",
      "0.15299167277726156\n",
      "Epoch: 37\n",
      "Train:  0.22204857929558544\n",
      "Test 0.144584727169939\n",
      "0.1513099343723956\n",
      "Epoch: 38\n",
      "Train:  0.21934048878540705\n",
      "Test 0.1431363345065833\n",
      "0.14967494273965173\n",
      "Epoch: 39\n",
      "Train:  0.21686915556589761\n",
      "Test 0.14315381074399303\n",
      "0.14837054295604898\n",
      "Epoch: 40\n",
      "Train:  0.2143761256143396\n",
      "Test 0.14238367743462652\n",
      "0.14717304251167526\n",
      "Epoch: 41\n",
      "Train:  0.21187986953750307\n",
      "Test 0.14230982749808185\n",
      "0.14620031675860118\n",
      "Epoch: 42\n",
      "Train:  0.21002355929218477\n",
      "Test 0.14151295408224449\n",
      "0.14526278041791282\n",
      "Epoch: 43\n",
      "Train:  0.20980775279876512\n",
      "Test 0.14280342654539988\n",
      "0.14477088286195988\n",
      "Epoch: 44\n",
      "Train:  0.21095344644285494\n",
      "Test 0.13980870101696405\n",
      "0.1437784032643775\n",
      "Epoch: 45\n",
      "Train:  0.20855664830286424\n",
      "Test 0.14208321355201387\n",
      "0.143439353507745\n",
      "Epoch: 46\n",
      "Train:  0.2037329616045559\n",
      "Test 0.13867770985021313\n",
      "0.14248699822844813\n",
      "Epoch: 47\n",
      "Train:  0.20394204864397836\n",
      "Test 0.13954811717891868\n",
      "0.14189920891040242\n",
      "Epoch: 48\n",
      "Train:  0.19995365943418536\n",
      "Test 0.13717379154903547\n",
      "0.14095410857697566\n",
      "Epoch: 49\n",
      "Train:  0.1963139096336378\n",
      "Test 0.13784830343155635\n",
      "0.1403329386822588\n",
      "Epoch: 50\n",
      "Train:  0.19388833944941616\n",
      "Test 0.13677611139231113\n",
      "0.13962156510181886\n",
      "Epoch: 51\n",
      "Train:  0.19135124248626467\n",
      "Test 0.13616419826453421\n",
      "0.13893008541812013\n",
      "Epoch: 52\n",
      "Train:  0.18941428326752596\n",
      "Test 0.1352801629693517\n",
      "0.13820009559395982\n",
      "Epoch: 53\n",
      "Train:  0.19021835243636434\n",
      "Test 0.13588612841189782\n",
      "0.13773729945203814\n",
      "Epoch: 54\n",
      "Train:  0.19306512532377063\n",
      "Test 0.13532494619870797\n",
      "0.13725482654494028\n",
      "Epoch: 55\n",
      "Train:  0.19189121243936239\n",
      "Test 0.1352719535996571\n",
      "0.1368582504721164\n",
      "Epoch: 56\n",
      "Train:  0.1843429389409721\n",
      "Test 0.13303746511620698\n",
      "0.1360940911136868\n",
      "Epoch: 57\n",
      "Train:  0.18151108726463366\n",
      "Test 0.1371404167414803\n",
      "0.13630335674033717\n",
      "Epoch: 58\n",
      "Train:  0.18431703938041633\n",
      "Test 0.13374796695324964\n",
      "0.13579227780388692\n",
      "Epoch: 59\n",
      "Train:  0.17889908441912122\n",
      "Test 0.13275873551875245\n",
      "0.1351855684170806\n",
      "Epoch: 60\n",
      "Train:  0.17585975053164113\n",
      "Test 0.1356564584177929\n",
      "0.13527974653268507\n",
      "Epoch: 61\n",
      "Train:  0.176622420450461\n",
      "Test 0.13127239330265766\n",
      "0.1344782751005987\n",
      "Epoch: 62\n",
      "Train:  0.16982272681149044\n",
      "Test 0.13343340102514942\n",
      "0.1342693001215392\n",
      "Epoch: 63\n",
      "Train:  0.17009101705727997\n",
      "Test 0.1324942341976673\n",
      "0.13391428671391928\n",
      "Epoch: 64\n",
      "Train:  0.16722325464555374\n",
      "Test 0.1308823232249026\n",
      "0.13330789371160473\n",
      "Epoch: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:54:42,386]\u001b[0m Trial 26 finished with value: 0.1336571568986712 and parameters: {'layer_size1': 256, 'layer_size2': 384, 'layer_size3': 512, 'layer_size4': 192, 'layer_size5': 256, 'learning_rate': 1.308095102756138e-05, 'b1': 0.9797503819274661}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.16669302700503624\n",
      "Test 0.13505447741884452\n",
      "0.13365721059338534\n",
      "Epoch: 0\n",
      "Train:  0.6921068678845416\n",
      "Test 0.6915792659088805\n",
      "0.6915792659088805\n",
      "Epoch: 1\n",
      "Train:  1.0339971453278929\n",
      "Test 0.6856706640222571\n",
      "0.6882967093052009\n",
      "Epoch: 2\n",
      "Train:  1.021463774499439\n",
      "Test 0.6706129015583695\n",
      "0.6810492471138766\n",
      "Epoch: 3\n",
      "Train:  0.9924448208931165\n",
      "Test 0.6374452127205147\n",
      "0.6662782327529816\n",
      "Epoch: 4\n",
      "Train:  0.9295722420835669\n",
      "Test 0.5642557449829884\n",
      "0.635928849194559\n",
      "Epoch: 5\n",
      "Train:  0.7995160933815952\n",
      "Test 0.43288346087976254\n",
      "0.5808922598560441\n",
      "Epoch: 6\n",
      "Train:  0.5946337999878349\n",
      "Test 0.2822440179276379\n",
      "0.5053123570340725\n",
      "Epoch: 7\n",
      "Train:  0.41465014939779765\n",
      "Test 0.1999952358640594\n",
      "0.43193891132718226\n",
      "Epoch: 8\n",
      "Train:  0.3349785949939337\n",
      "Test 0.19737047535595875\n",
      "0.377752438917818\n",
      "Epoch: 9\n",
      "Train:  0.3151861447499785\n",
      "Test 0.15833938020475946\n",
      "0.32859117685551437\n",
      "Epoch: 10\n",
      "Train:  0.27095401007170367\n",
      "Test 0.1512342286859076\n",
      "0.2897864900022688\n",
      "Epoch: 11\n",
      "Train:  0.2520634424736239\n",
      "Test 0.15993369698196977\n",
      "0.26189955587737496\n",
      "Epoch: 12\n",
      "Train:  0.25189409960375164\n",
      "Test 0.176083321863915\n",
      "0.2437378592432129\n",
      "Epoch: 13\n",
      "Train:  0.2584277781565766\n",
      "Test 0.14927151223351232\n",
      "0.22397542896595446\n",
      "Epoch: 14\n",
      "Train:  0.2363319507093875\n",
      "Test 0.14566990626709803\n",
      "0.2077432037752435\n",
      "Epoch: 15\n",
      "Train:  0.2305304260289931\n",
      "Test 0.15899719226927983\n",
      "0.1977116379997479\n",
      "Epoch: 16\n",
      "Train:  0.24455113239900206\n",
      "Test 0.1540649757471495\n",
      "0.18878121019250338\n",
      "Epoch: 17\n",
      "Train:  0.2221897283412052\n",
      "Test 0.1618439710763839\n",
      "0.1832949303376394\n",
      "Epoch: 18\n",
      "Train:  0.2278533214140315\n",
      "Test 0.13605706722751915\n",
      "0.17370921296947991\n",
      "Epoch: 19\n",
      "Train:  0.20134317661437715\n",
      "Test 0.13415665281834183\n",
      "0.16570643519330486\n",
      "Epoch: 20\n",
      "Train:  0.19465741496055555\n",
      "Test 0.13708493757597257\n",
      "0.15992884682282163\n",
      "Epoch: 21\n",
      "Train:  0.18985557812692483\n",
      "Test 0.13190972066105722\n",
      "0.15428336528925976\n",
      "Epoch: 22\n",
      "Train:  0.17936691754043865\n",
      "Test 0.14303337243955322\n",
      "0.15202000620547348\n",
      "Epoch: 23\n",
      "Train:  0.19506270572331635\n",
      "Test 0.1289387555390378\n",
      "0.14738185301300782\n",
      "Epoch: 24\n",
      "Train:  0.17791144458761254\n",
      "Test 0.14237108668346546\n",
      "0.14637589936165418\n",
      "Epoch: 25\n",
      "Train:  0.183300993736192\n",
      "Test 0.1409965775183815\n",
      "0.14529677353531445\n",
      "Epoch: 26\n",
      "Train:  0.1699410095544798\n",
      "Test 0.12495736221035758\n",
      "0.14121903189601615\n",
      "Epoch: 27\n",
      "Train:  0.15574505308390538\n",
      "Test 0.12431576934680616\n",
      "0.13783182758016818\n",
      "Epoch: 28\n",
      "Train:  0.15032048911988843\n",
      "Test 0.12333319999359466\n",
      "0.13492760800072814\n",
      "Epoch: 29\n",
      "Train:  0.14918292457776847\n",
      "Test 0.13915288797664993\n",
      "0.13577371142121408\n",
      "Epoch: 30\n",
      "Train:  0.1513482067484968\n",
      "Test 0.12325798998835868\n",
      "0.13326808568310328\n",
      "Epoch: 31\n",
      "Train:  0.1367047796313286\n",
      "Test 0.1245247116892329\n",
      "0.13151802434288648\n",
      "Epoch: 32\n",
      "Train:  0.13444961198083646\n",
      "Test 0.12571312154169048\n",
      "0.13035630745709348\n",
      "Epoch: 33\n",
      "Train:  0.12911129295280127\n",
      "Test 0.13235666306481284\n",
      "0.13075658154171077\n",
      "Epoch: 34\n",
      "Train:  0.12906204866656468\n",
      "Test 0.12670141336531124\n",
      "0.12994521877859289\n",
      "Epoch: 35\n",
      "Train:  0.12136877029731225\n",
      "Test 0.1373044008742199\n",
      "0.13141753299099704\n",
      "Epoch: 36\n",
      "Train:  0.12990597495254838\n",
      "Test 0.15117977620460665\n",
      "0.13537100801451618\n",
      "Epoch: 37\n",
      "Train:  0.129827214129467\n",
      "Test 0.13604958579217122\n",
      "0.13550675176292074\n",
      "Epoch: 38\n",
      "Train:  0.12135665330885749\n",
      "Test 0.12957352332620722\n",
      "0.13431990887747927\n",
      "Epoch: 39\n",
      "Train:  0.10801865000980514\n",
      "Test 0.1364481570659676\n",
      "0.13474561510124\n",
      "Epoch: 40\n",
      "Train:  0.10926854048323419\n",
      "Test 0.13455461117698242\n",
      "0.13470741025375227\n",
      "Epoch: 41\n",
      "Train:  0.1023367775135909\n",
      "Test 0.1335941310780082\n",
      "0.1344847354755283\n",
      "Epoch: 42\n",
      "Train:  0.10024281715076151\n",
      "Test 0.14484555259664225\n",
      "0.13655703993348425\n",
      "Epoch: 43\n",
      "Train:  0.10236754421101654\n",
      "Test 0.1375736218669039\n",
      "0.1367603673903679\n",
      "Epoch: 44\n",
      "Train:  0.0941447236066882\n",
      "Test "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:55:14,102]\u001b[0m Trial 27 finished with value: 0.1366274294367485 and parameters: {'layer_size1': 512, 'layer_size2': 512, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 256, 'learning_rate': 3.627058058904131e-05, 'b1': 0.9878118272372131}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13612546139284148\n",
      "0.13663338065981043\n",
      "Epoch: 0\n",
      "Train:  0.6944143536326649\n",
      "Test 0.6927124253122798\n",
      "0.6927124253122797\n",
      "Epoch: 1\n",
      "Train:  1.0405013613648466\n",
      "Test 0.6925721157601464\n",
      "0.6926344755610947\n",
      "Epoch: 2\n",
      "Train:  1.040121662201899\n",
      "Test 0.6924509434472947\n",
      "0.6925592574816685\n",
      "Epoch: 3\n",
      "Train:  1.0398548007448079\n",
      "Test 0.692334417458419\n",
      "0.6924830921621393\n",
      "Epoch: 4\n",
      "Train:  1.0395830454843822\n",
      "Test 0.692217522488409\n",
      "0.6924040911882786\n",
      "Epoch: 5\n",
      "Train:  1.0393202365973058\n",
      "Test 0.6921120689902114\n",
      "0.6923249369364822\n",
      "Epoch: 6\n",
      "Train:  1.0390806534351447\n",
      "Test 0.6920004283988869\n",
      "0.6922428124827169\n",
      "Epoch: 7\n",
      "Train:  1.0387491297809195\n",
      "Test 0.6918709740970598\n",
      "0.6921534527262211\n",
      "Epoch: 8\n",
      "Train:  1.0384693837864496\n",
      "Test 0.691724011967907\n",
      "0.6920542497805839\n",
      "Epoch: 9\n",
      "Train:  1.038152928644921\n",
      "Test 0.6915512591491252\n",
      "0.6919415506805712\n",
      "Epoch: 10\n",
      "Train:  1.0378131089193043\n",
      "Test 0.6913691093196799\n",
      "0.6918163037817013\n",
      "Epoch: 11\n",
      "Train:  1.037429860769174\n",
      "Test 0.6911761747611748\n",
      "0.6916788309140668\n",
      "Epoch: 12\n",
      "Train:  1.0370115574462946\n",
      "Test 0.6909466866171841\n",
      "0.6915238837439271\n",
      "Epoch: 13\n",
      "Train:  1.0365675361383528\n",
      "Test 0.6907158679577894\n",
      "0.6913548462385939\n",
      "Epoch: 14\n",
      "Train:  1.0360822533513163\n",
      "Test 0.690440160887582\n",
      "0.6911652379187138\n",
      "Epoch: 15\n",
      "Train:  1.0355906436294864\n",
      "Test 0.6901403576026469\n",
      "0.6909543251899589\n",
      "Epoch: 16\n",
      "Train:  1.0349855183900059\n",
      "Test 0.6897937092152271\n",
      "0.6907168546334638\n",
      "Epoch: 17\n",
      "Train:  1.0343578399974347\n",
      "Test 0.6894072064986596\n",
      "0.690450119941465\n",
      "Epoch: 18\n",
      "Train:  1.0336782081878229\n",
      "Test 0.6889945355963795\n",
      "0.6901547462895075\n",
      "Epoch: 19\n",
      "Train:  1.0330055672607141\n",
      "Test 0.6885556305721129\n",
      "0.689831192828599\n",
      "Epoch: 20\n",
      "Train:  1.0321797523306402\n",
      "Test 0.6880038256173605\n",
      "0.6894623171083479\n",
      "Epoch: 21\n",
      "Train:  1.0313197435476842\n",
      "Test 0.687425088969779\n",
      "0.6890518427141951\n",
      "Epoch: 22\n",
      "Train:  1.0304164731458867\n",
      "Test 0.686823430952135\n",
      "0.68860351389555\n",
      "Epoch: 23\n",
      "Train:  1.0294286108715631\n",
      "Test 0.6861677711263244\n",
      "0.68811405393238\n",
      "Epoch: 24\n",
      "Train:  1.0283895008293265\n",
      "Test 0.6854841390372196\n",
      "0.687586076310287\n",
      "Epoch: 25\n",
      "Train:  1.0272688946444473\n",
      "Test 0.6847030638338445\n",
      "0.6870077258580121\n",
      "Epoch: 26\n",
      "Train:  1.0260501066188672\n",
      "Test 0.6838840130484585\n",
      "0.6863814691001727\n",
      "Epoch: 27\n",
      "Train:  1.0247299141717918\n",
      "Test 0.6829639991997799\n",
      "0.6856966504882515\n",
      "Epoch: 28\n",
      "Train:  1.023199622884338\n",
      "Test 0.681944544280405\n",
      "0.6849450662263687\n",
      "Epoch: 29\n",
      "Train:  1.0216770895889826\n",
      "Test 0.6808830455982642\n",
      "0.6841316551466038\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:55:36,147]\u001b[0m Trial 28 finished with value: 0.6825611109237676 and parameters: {'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 384, 'layer_size4': 128, 'layer_size5': 192, 'learning_rate': 2.882858173076284e-06, 'b1': 0.970648239456188}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  1.019816477875133\n",
      "Test 0.6796665899046175\n",
      "0.683237756824187\n",
      "Epoch: 0\n",
      "Train:  0.6928410960204435\n",
      "Test 0.6936368612579373\n",
      "0.6936368612579373\n",
      "Epoch: 1\n",
      "Train:  1.0391838824574327\n",
      "Test 0.6930863167340066\n",
      "0.693331003189087\n",
      "Epoch: 2\n",
      "Train:  1.0383707282744048\n",
      "Test 0.6926849006296514\n",
      "0.6930662070581708\n",
      "Epoch: 3\n",
      "Train:  1.0375672736010708\n",
      "Test 0.6918971647709717\n",
      "0.6926701900232117\n",
      "Epoch: 4\n",
      "Train:  1.03632567238895\n",
      "Test 0.6908872970294603\n",
      "0.6921398196657178\n",
      "Epoch: 5\n",
      "Train:  1.0347451596033006\n",
      "Test 0.6894219262259347\n",
      "0.6914031194315846\n",
      "Epoch: 6\n",
      "Train:  1.0325479948476994\n",
      "Test 0.6878054849394075\n",
      "0.6904926541177693\n",
      "Epoch: 7\n",
      "Train:  1.0298099308223514\n",
      "Test 0.6855513870497763\n",
      "0.6893051747207828\n",
      "Epoch: 8\n",
      "Train:  1.0260059973259112\n",
      "Test 0.6821243409272079\n",
      "0.6876463664901669\n",
      "Epoch: 9\n",
      "Train:  1.0206982502133854\n",
      "Test 0.6778192114044022\n",
      "0.6854445132853857\n",
      "Epoch: 10\n",
      "Train:  1.0140084087193668\n",
      "Test 0.6725088702890026\n",
      "0.6826142685112143\n",
      "Epoch: 11\n",
      "Train:  1.005816719034216\n",
      "Test 0.6654796312143515\n",
      "0.67893446701879\n",
      "Epoch: 12\n",
      "Train:  0.9951811282189338\n",
      "Test 0.6569498002310812\n",
      "0.6742817477123371\n",
      "Epoch: 13\n",
      "Train:  0.9816885847093422\n",
      "Test 0.645746825160561\n",
      "0.6683122206241505\n",
      "Epoch: 14\n",
      "Train:  0.9643994138572679\n",
      "Test 0.6317910239810035\n",
      "0.6607416142644222\n",
      "Epoch: 15\n",
      "Train:  0.9417267548732269\n",
      "Test 0.6128376626269721\n",
      "0.6508833381324673\n",
      "Epoch: 16\n",
      "Train:  0.9131640115063706\n",
      "Test 0.5898524928878952\n",
      "0.6383959787482039\n",
      "Epoch: 17\n",
      "Train:  0.8779383354134612\n",
      "Test 0.5614134199890025\n",
      "0.6227170199849894\n",
      "Epoch: 18\n",
      "Train:  0.8343087550484654\n",
      "Test 0.5268106097048455\n",
      "0.6032552644733763\n",
      "Epoch: 19\n",
      "Train:  0.7830594017719611\n",
      "Test 0.48827871407344664\n",
      "0.5799917442661933\n",
      "Epoch: 20\n",
      "Train:  0.72593106509565\n",
      "Test 0.4439134522453769\n",
      "0.5525227289139502\n",
      "Epoch: 21\n",
      "Train:  0.6615588042216424\n",
      "Test 0.39847684113970605\n",
      "0.5214845298734175\n",
      "Epoch: 22\n",
      "Train:  0.595956577868252\n",
      "Test 0.35310372906726795\n",
      "0.4876084003388333\n",
      "Epoch: 23\n",
      "Train:  0.5336679766575495\n",
      "Test 0.3137480640586043\n",
      "0.4526713475155244\n",
      "Epoch: 24\n",
      "Train:  0.47991869410315713\n",
      "Test 0.28029303607486544\n",
      "0.4180649459386732\n",
      "Epoch: 25\n",
      "Train:  0.4355158603890038\n",
      "Test 0.25365357444836545\n",
      "0.38508298979470207\n",
      "Epoch: 26\n",
      "Train:  0.3989084045856427\n",
      "Test 0.23136704723476928\n",
      "0.354265288653494\n",
      "Epoch: 27\n",
      "Train:  0.36767420445606386\n",
      "Test 0.21470295127494868\n",
      "0.32629872597825865\n",
      "Epoch: 28\n",
      "Train:  0.34493429983382695\n",
      "Test 0.19987384936748406\n",
      "0.30097456341260204\n",
      "Epoch: 29\n",
      "Train:  0.3237421392248227\n",
      "Test 0.18849032478673117\n",
      "0.27844983141981977\n",
      "Epoch: 30\n",
      "Train:  0.308421058546165\n",
      "Test 0.17964312775340271\n",
      "0.2586689006015169\n",
      "Epoch: 31\n",
      "Train:  0.29586260573385836\n",
      "Test 0.17495248518583975\n",
      "0.2419123416045876\n",
      "Epoch: 32\n",
      "Train:  0.28865969058249025\n",
      "Test 0.16861179802607704\n",
      "0.2272429350478722\n",
      "Epoch: 33\n",
      "Train:  0.2784718399178305\n",
      "Test 0.16476120525500276\n",
      "0.21474024947454975\n",
      "Epoch: 34\n",
      "Train:  0.27143390785779925\n",
      "Test 0.16220609267880193\n",
      "0.20422915430864944\n",
      "Epoch: 35\n",
      "Train:  0.26639980355434584\n",
      "Test 0.1598429567156694\n",
      "0.19534903302593845\n",
      "Epoch: 36\n",
      "Train:  0.26284441727148744\n",
      "Test 0.15984889641131236\n",
      "0.18824716195186986\n",
      "Epoch: 37\n",
      "Train:  0.2599501200702601\n",
      "Test 0.15685882694991954\n",
      "0.18196819086020485\n",
      "Epoch: 38\n",
      "Train:  0.2554807807063008\n",
      "Test 0.15563190278116162\n",
      "0.17670005792567345\n",
      "Epoch: 39\n",
      "Train:  0.2530947330342981\n",
      "Test 0.15405822973084318\n",
      "0.17217109028364921\n",
      "Epoch: 40\n",
      "Train:  0.25113963892158025\n",
      "Test 0.15517246947988814\n",
      "0.1687710045637668\n",
      "Epoch: 41\n",
      "Train:  0.24888752445053214\n",
      "Test 0.1520476632925508\n",
      "0.16542605175240865\n",
      "Epoch: 42\n",
      "Train:  0.24531950528354762\n",
      "Test 0.15216778491661226\n",
      "0.16277421791079014\n",
      "Epoch: 43\n",
      "Train:  0.243482459404748\n",
      "Test 0.15169290408846878\n",
      "0.1605578344749336\n",
      "Epoch: 44\n",
      "Train:  0.24159283249301242\n",
      "Test 0.1504265120860203\n",
      "0.1585314817370414\n",
      "Epoch: 45\n",
      "Train:  0.23973038645918335\n",
      "Test 0.1504473110913357\n",
      "0.1569145912674903\n",
      "Epoch: 46\n",
      "Train:  0.23804618736162728\n",
      "Test 0.14852161410063397\n",
      "0.15523594904040328\n",
      "Epoch: 47\n",
      "Train:  0.2361728178350862\n",
      "Test 0.148982775134918\n",
      "0.15398528636859665\n",
      "Epoch: 48\n",
      "Train:  0.23504728168904127\n",
      "Test 0.14671241931426218\n",
      "0.15253068700680997\n",
      "Epoch: 49\n",
      "Train:  0.2320385210134171\n",
      "Test 0.1479649584426548\n",
      "0.15161752826094183\n",
      "Epoch: 50\n",
      "Train:  0.23041796605119774\n",
      "Test 0.14546935125202923\n",
      "0.15038787881904467\n",
      "Epoch: 51\n",
      "Train:  0.22792380415721908\n",
      "Test 0.14633828548939673\n",
      "0.1495779527549384\n",
      "Epoch: 52\n",
      "Train:  0.2281906640791631\n",
      "Test 0.14439512441282745\n",
      "0.14854137951174876\n",
      "Epoch: 53\n",
      "Train:  0.22559786093295056\n",
      "Test 0.1458016838690764\n",
      "0.14799343717993982\n",
      "Epoch: 54\n",
      "Train:  0.22539161284959058\n",
      "Test 0.143225951195309\n",
      "0.14703993552367212\n",
      "Epoch: 55\n",
      "Train:  0.22256405308378704\n",
      "Test 0.14507012361244404\n",
      "0.14664597166743273\n",
      "Epoch: 56\n",
      "Train:  0.22206342375867968\n",
      "Test 0.14230428881697602\n",
      "0.14577763249826736\n",
      "Epoch: 57\n",
      "Train:  0.21874923692954765\n",
      "Test 0.14403977515278282\n",
      "0.14543006019690013\n",
      "Epoch: 58\n",
      "Train:  0.22058230736753442\n",
      "Test 0.14134325745478\n",
      "0.14461269808272137\n",
      "Epoch: 59\n",
      "Train:  0.2167282529591477\n",
      "Test 0.14194260445515533\n",
      "0.14407867853882558\n",
      "Epoch: 60\n",
      "Train:  0.2156525198063189\n",
      "Test 0.14096352840763526\n",
      "0.143455647748754\n",
      "Epoch: 61\n",
      "Train:  0.21430640899313566\n",
      "Test 0.14025463416299103\n",
      "0.1428154444036918\n",
      "Epoch: 62\n",
      "Train:  0.21273128080417167\n",
      "Test 0.13951214423212102\n",
      "0.14215478385099842\n",
      "Epoch: 63\n",
      "Train:  0.2104842887070685\n",
      "Test 0.13957070182640474\n",
      "0.14163796712166857\n",
      "Epoch: 64\n",
      "Train:  0.20959603902457397\n",
      "Test 0.1389830069063784\n",
      "0.1411069748119631\n",
      "Epoch: 65\n",
      "Train:  0.21030260356409208\n",
      "Test 0.1378228350341211\n",
      "0.14045014659252417\n",
      "Epoch: 66\n",
      "Train:  0.20868760351801202\n",
      "Test 0.1373097931509053\n",
      "0.1398220757023462\n",
      "Epoch: 67\n",
      "Train:  0.20469670977457102\n",
      "Test 0.1388192038894409\n",
      "0.13962150128819542\n",
      "Epoch: 68\n",
      "Train:  0.20480686686284869\n",
      "Test 0.13738527488058958\n",
      "0.13917425591468122\n",
      "Epoch: 69\n",
      "Train:  0.20233839758818511\n",
      "Test 0.13592563641185945\n",
      "0.13852453190720448\n",
      "Epoch: 70\n",
      "Train:  0.19978315656452061\n",
      "Test 0.1366797714620392\n",
      "0.13815557976960244\n",
      "Epoch: 71\n",
      "Train:  0.19900247914846236\n",
      "Test 0.13502453110648163\n",
      "0.13752936997103068\n",
      "Epoch: 72\n",
      "Train:  0.19720439408861457\n",
      "Test 0.13608949923471653\n",
      "0.13724139579950606\n",
      "Epoch: 73\n",
      "Train:  0.19716850515359488\n",
      "Test 0.1349825246648474\n",
      "0.13678962154212482\n",
      "Epoch: 74\n",
      "Train:  0.19649955859551063\n",
      "Test 0.13339357945945238\n",
      "0.13611041308896746\n",
      "Epoch: 75\n",
      "Train:  0.19570409921390233\n",
      "Test 0.13587155973627454\n",
      "0.13606264241636823\n",
      "Epoch: 76\n",
      "Train:  0.19513857717653088\n",
      "Test 0.1332475436482947\n",
      "0.1354996226433244\n",
      "Epoch: 77\n",
      "Train:  0.19046881742563931\n",
      "Test 0.13220338326206793\n",
      "0.13484037474887328\n",
      "Epoch: 78\n",
      "Train:  0.1888474069003548\n",
      "Test 0.13292399858680617\n",
      "0.134457099507995\n",
      "Epoch: 79\n",
      "Train:  0.18798779881467204\n",
      "Test 0.1318608975573528\n",
      "0.13393785910869238\n",
      "Epoch: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 19:56:29,235]\u001b[0m Trial 29 finished with value: 0.13358419971399493 and parameters: {'layer_size1': 512, 'layer_size2': 256, 'layer_size3': 256, 'layer_size4': 192, 'layer_size5': 192, 'learning_rate': 8.349149027375222e-06, 'b1': 0.9684160965942011}. Best is trial 4 with value: 0.12012299756208797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.186501651107685\n",
      "Test 0.13216957160111367\n",
      "0.13358420160217777\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(),pruner=optuna.pruners.HyperbandPruner())\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wzyqDmk-S37F"
   },
   "outputs": [],
   "source": [
    "best_trial = study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGq-o8_5TJ79",
    "outputId": "6a318f9a-d35d-4501-c320-04b3acf3898b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_size1': 384, 'layer_size2': 256, 'layer_size3': 384, 'layer_size4': 256, 'layer_size5': 256, 'learning_rate': 1.6864191696897905e-05, 'b1': 0.9652220612376727}\n"
     ]
    }
   ],
   "source": [
    "print(best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bRmBgX9dTNCQ"
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rzTnkh0FTOsB"
   },
   "outputs": [],
   "source": [
    "with open('mydata.json', 'w') as f:\n",
    "    json.dump(best_trial.params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2TCJeYG3TUNd",
    "outputId": "0cd88359-9a70-430d-f4d2-09957b068113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train:  0.6926371863473466\n",
      "Test 0.6928813400722685\n",
      "0.6928813400722684\n",
      "Epoch: 1\n",
      "Train:  1.037999260774899\n",
      "Test 0.6917444578893892\n",
      "0.6922497388595579\n",
      "Epoch: 2\n",
      "Train:  1.0359904295577234\n",
      "Test 0.6899705507379749\n",
      "0.6913156453671058\n",
      "Epoch: 3\n",
      "Train:  1.031982572414936\n",
      "Test 0.6862316055175586\n",
      "0.6895934096457145\n",
      "Epoch: 4\n",
      "Train:  1.0243242744342749\n",
      "Test 0.6784995313965794\n",
      "0.6862932316801222\n",
      "Epoch: 5\n",
      "Train:  1.0086330810745994\n",
      "Test 0.6616282705422286\n",
      "0.6796076558664421\n",
      "Epoch: 6\n",
      "Train:  0.9758044331720024\n",
      "Test 0.626516233215402\n",
      "0.6661716331437375\n",
      "Epoch: 7\n",
      "Train:  0.9114698578804841\n",
      "Test 0.5612173318426251\n",
      "0.6409491408750069\n",
      "Epoch: 8\n",
      "Train:  0.8032648786083683\n",
      "Test 0.4634798083986555\n",
      "0.5999528446430713\n",
      "Epoch: 9\n",
      "Train:  0.6541563224443149\n",
      "Test 0.3577538015859904\n",
      "0.5456861993631307\n",
      "Epoch: 10\n",
      "Train:  0.5085341170048102\n",
      "Test 0.27070469712163064\n",
      "0.48552181789941623\n",
      "Epoch: 11\n",
      "Train:  0.4025209209857843\n",
      "Test 0.21629371005536874\n",
      "0.42770291132539207\n",
      "Epoch: 12\n",
      "Train:  0.33826767464915475\n",
      "Test 0.19461881868786865\n",
      "0.3783742192731673\n",
      "Epoch: 13\n",
      "Train:  0.30488441383718573\n",
      "Test 0.17333570470685486\n",
      "0.3354800090434302\n",
      "Epoch: 14\n",
      "Train:  0.28589968240714114\n",
      "Test 0.1862002065876028\n",
      "0.3045352776072243\n",
      "Epoch: 15\n",
      "Train:  0.2824315335669797\n",
      "Test 0.15878620927969178\n",
      "0.2745412058775613\n",
      "Epoch: 16\n",
      "Train:  0.26244313351045817\n",
      "Test 0.15638906736568217\n",
      "0.250366410170495\n",
      "Epoch: 17\n",
      "Train:  0.25509038229810665\n",
      "Test 0.1531941173564056\n",
      "0.23057542898572092\n",
      "Epoch: 18\n",
      "Train:  0.251182031885963\n",
      "Test 0.15420430557522583\n",
      "0.21507786080836205\n",
      "Epoch: 19\n",
      "Train:  0.2518419760241832\n",
      "Test 0.14979055472018518\n",
      "0.2018681014341951\n",
      "Epoch: 20\n",
      "Train:  0.24520503436198166\n",
      "Test 0.15382956552418162\n",
      "0.19217095385234872\n",
      "Epoch: 21\n",
      "Train:  0.24408379525301002\n",
      "Test 0.15178987466399269\n",
      "0.18403470308039363\n",
      "Epoch: 22\n",
      "Train:  0.23923417871592792\n",
      "Test 0.1472253284993626\n",
      "0.17662911327785066\n",
      "Epoch: 23\n",
      "Train:  0.23368870389166768\n",
      "Test 0.1479974129670487\n",
      "0.1708756030317452\n",
      "Epoch: 24\n",
      "Train:  0.23271088211391217\n",
      "Test 0.14877000975084828\n",
      "0.16643771852191455\n",
      "Epoch: 25\n",
      "Train:  0.23403400515680348\n",
      "Test 0.14513919046728602\n",
      "0.16216509971300017\n",
      "Epoch: 26\n",
      "Train:  0.2271881086458435\n",
      "Test 0.14488020742605456\n",
      "0.15869974253608032\n",
      "Epoch: 27\n",
      "Train:  0.2248136302176522\n",
      "Test 0.14544701652649122\n",
      "0.15604406049802733\n",
      "Epoch: 28\n",
      "Train:  0.2222181600637925\n",
      "Test 0.14170067683681026\n",
      "0.15317093782378863\n",
      "Epoch: 29\n",
      "Train:  0.2173316878822697\n",
      "Test 0.15140463231684087\n",
      "0.15281723886429524\n",
      "Epoch: 30\n",
      "Train:  0.22235242984233758\n",
      "Test 0.13950395627772852\n",
      "0.15015194276557617\n",
      "Epoch: 31\n",
      "Train:  0.21398984036329902\n",
      "Test 0.13839100197558002\n",
      "0.14779788953445733\n",
      "Epoch: 32\n",
      "Train:  0.2110728744294617\n",
      "Test 0.1385756499686657\n",
      "0.14595227182209858\n",
      "Epoch: 33\n",
      "Train:  0.20913157572256805\n",
      "Test 0.14486894854804971\n",
      "0.14573549724952198\n",
      "Epoch: 34\n",
      "Train:  0.2105250051210979\n",
      "Test 0.1418384517177994\n",
      "0.1449557718489784\n",
      "Epoch: 35\n",
      "Train:  0.20976566702072874\n",
      "Test 0.1394906100226846\n",
      "0.14386238465929027\n",
      "Epoch: 36\n",
      "Train:  0.20197786740112655\n",
      "Test 0.1347686075520166\n",
      "0.14204315693931677\n",
      "Epoch: 37\n",
      "Train:  0.19793923578528694\n",
      "Test 0.13430968583339736\n",
      "0.14049614141557915\n",
      "Epoch: 38\n",
      "Train:  0.1969540639688353\n",
      "Test 0.13468679668374986\n",
      "0.1393340793885409\n",
      "Epoch: 39\n",
      "Train:  0.19401979794377808\n",
      "Test 0.13386384138475843\n",
      "0.1382398863445817\n",
      "Epoch: 40\n",
      "Train:  0.19196437381808357\n",
      "Test 0.15090792937265649\n",
      "0.14077376439832842\n",
      "Epoch: 41\n",
      "Train:  0.20067274159727952\n",
      "Test 0.13102688843677768\n",
      "0.13882422335740832\n",
      "Epoch: 42\n",
      "Train:  0.1856966975721575\n",
      "Test 0.13134326064965993\n",
      "0.1373279289833404\n",
      "Epoch: 43\n",
      "Train:  0.1849916007884884\n",
      "Test 0.13077370489814452\n",
      "0.13601701279323497\n",
      "Epoch: 44\n",
      "Train:  0.18629292572845088\n",
      "Test 0.12971899279089638\n",
      "0.1347573539268856\n",
      "Epoch: 45\n",
      "Train:  0.181090655003166\n",
      "Test 0.1346751055560815\n",
      "0.1347409036795173\n",
      "Epoch: 46\n",
      "Train:  0.18357838868016835\n",
      "Test 0.13013130972236941\n",
      "0.13381895918802622\n",
      "Epoch: 47\n",
      "Train:  0.17616170601093725\n",
      "Test 0.12965280414582828\n",
      "0.13298570959749983\n",
      "Epoch: 48\n",
      "Train:  0.1807322813668749\n",
      "Test 0.1278282391118916\n",
      "0.13195419709758024\n",
      "Epoch: 49\n",
      "Train:  0.17213992552060783\n",
      "Test 0.12680601908555833\n",
      "0.13092454679951576\n",
      "Epoch: 50\n",
      "Train:  0.17081803273095753\n",
      "Test 0.1265552256498554\n",
      "0.1300506725917041\n",
      "Epoch: 51\n",
      "Train:  0.16785540397538234\n",
      "Test 0.13044863481470298\n",
      "0.13013026576333858\n",
      "Epoch: 52\n",
      "Train:  0.16844273023239095\n",
      "Test 0.12620665324039948\n",
      "0.12934553752434275\n",
      "Epoch: 53\n",
      "Train:  0.16634578600307523\n",
      "Test 0.12438689716051131\n",
      "0.12835380365389373\n",
      "Epoch: 54\n",
      "Train:  0.160695693319179\n",
      "Test 0.1258406620609127\n",
      "0.12785117298459178\n",
      "Epoch: 55\n",
      "Train:  0.16099495825872862\n",
      "Test 0.12341105217462058\n",
      "0.12696314550009227\n",
      "Epoch: 56\n",
      "Train:  0.15673564838402437\n",
      "Test 0.13868839048094803\n",
      "0.1293082015153804\n",
      "Epoch: 57\n",
      "Train:  0.16484275420670544\n",
      "Test 0.1253546981529875\n",
      "0.1285174989495453\n",
      "Epoch: 58\n",
      "Train:  0.15646206179545039\n",
      "Test 0.12302238029861079\n",
      "0.12741847311404317\n",
      "Epoch: 59\n",
      "Train:  0.15615515900612043\n",
      "Test 0.12226698362019472\n",
      "0.12638817363634414\n",
      "Epoch: 60\n",
      "Train:  0.15064922471841177\n",
      "Test 0.1231054987625352\n",
      "0.1257316378566718\n",
      "Epoch: 61\n",
      "Train:  0.14889219036281465\n",
      "Test 0.12335746654142173\n",
      "0.12525680312790524\n",
      "Epoch: 62\n",
      "Train:  0.1470098020389485\n",
      "Test 0.13787815835831801\n",
      "0.1277810761546276\n",
      "0.12778097589277576\n"
     ]
    }
   ],
   "source": [
    "model = Net(768,[384,256,512,64,192],1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1.713644852336342e-05,betas=(0.9308401877808863,0.99))\n",
    "lossff = torch.nn.BCELoss()\n",
    "\n",
    "total_loss = 0\n",
    "weighted_loss = 0\n",
    "exp_param = 0.8\n",
    "\n",
    "wloss = []\n",
    "\n",
    "for i in range(800):\n",
    "  print(\"Epoch:\", i)\n",
    "  model.train()\n",
    "  for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "  print(\"Train: \",total_loss / len(train_loader.dataset))\n",
    "\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  for data in val_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        \n",
    "  print(\"Test\", total_loss / len(val_loader.dataset))\n",
    "\n",
    "  weighted_loss = exp_param*(weighted_loss) + (1-exp_param)*(total_loss/ len(val_loader.dataset))\n",
    "  print(weighted_loss/(1-exp_param**(i+1)))\n",
    "  wloss.append(weighted_loss/(1-exp_param**(i+1)))\n",
    "\n",
    "  if(i-30>=0 and wloss[i-20]-weighted_loss<0.01):\n",
    "    break\n",
    "\n",
    "print(weighted_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MLyh6jLxox8I"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "G1V1iQuOo7jV"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val(model):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for data in val_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        # print(out)\n",
    "        loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
    "        # print(loss)\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        all_preds.append(torch.reshape(out, (-1,)))\n",
    "        all_labels.append(data.y.float())\n",
    "    # print(all_preds)\n",
    "    accuracy, f1 = metrics(all_preds, all_labels)\n",
    "    return total_loss / len(val_loader.dataset), accuracy, f1\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        # print(out)\n",
    "        loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
    "        # print(loss)\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "        all_preds.append(torch.reshape(out, (-1,)))\n",
    "        all_labels.append(data.y.float())\n",
    "    # print(all_preds)\n",
    "    accuracy, f1 = metrics(all_preds, all_labels)\n",
    "    return total_loss / len(test_loader.dataset), accuracy, f1\n",
    "\n",
    "\n",
    "def metrics(preds, gts):\n",
    "    preds = torch.round(torch.cat(preds))\n",
    "    gts = torch.cat(gts)\n",
    "    acc = accuracy_score(preds.cpu().numpy(), gts.cpu().numpy())\n",
    "    f1 = f1_score(preds.cpu().numpy(), gts.cpu().numpy())\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-bHMi3ypCNL",
    "outputId": "0796101c-4007-4386-ec8a-e2dce7bee6b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.13787816130238903, 0.9468864468864469, 0.9499136442141622),\n",
       " (0.14472380657259218, 0.9566126502875065, 0.9575881451200817))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val(model),test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Saa_Eh-8pIa6"
   },
   "outputs": [],
   "source": [
    "final = DataLoader(train_data_gos+val_data_gos, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1opf8jEkiOtS",
    "outputId": "9a9569ba-e6bd-47af-d57e-ec834acc05a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train:  0.6928797637149965\n",
      "Epoch: 1\n",
      "Train:  0.6903672137539902\n",
      "Epoch: 2\n",
      "Train:  0.6847721721808698\n",
      "Epoch: 3\n",
      "Train:  0.6707307261861725\n",
      "Epoch: 4\n",
      "Train:  0.6355784279959542\n",
      "Epoch: 5\n",
      "Train:  0.560017455774058\n",
      "Epoch: 6\n",
      "Train:  0.4390554442656055\n",
      "Epoch: 7\n",
      "Train:  0.32349471182031364\n",
      "Epoch: 8\n",
      "Train:  0.2537925738809455\n",
      "Epoch: 9\n",
      "Train:  0.21585180332954695\n",
      "Epoch: 10\n",
      "Train:  0.19806776112980312\n",
      "Epoch: 11\n",
      "Train:  0.18412879605405716\n",
      "Epoch: 12\n",
      "Train:  0.17411073347296616\n",
      "Epoch: 13\n",
      "Train:  0.17462209408354556\n",
      "Epoch: 14\n",
      "Train:  0.16454003193621525\n",
      "Epoch: 15\n",
      "Train:  0.16357310190887825\n",
      "Epoch: 16\n",
      "Train:  0.15783987660984417\n",
      "Epoch: 17\n",
      "Train:  0.15851857232086825\n",
      "Epoch: 18\n",
      "Train:  0.151304594617478\n",
      "Epoch: 19\n",
      "Train:  0.1543248496422037\n",
      "Epoch: 20\n",
      "Train:  0.14625036869293603\n",
      "Epoch: 21\n",
      "Train:  0.1465473059378337\n",
      "Epoch: 22\n",
      "Train:  0.14274161737480442\n",
      "Epoch: 23\n",
      "Train:  0.13940603605793364\n",
      "Epoch: 24\n",
      "Train:  0.13774213669719276\n",
      "Epoch: 25\n",
      "Train:  0.13473597507337073\n",
      "Epoch: 26\n",
      "Train:  0.13077596150183998\n",
      "Epoch: 27\n",
      "Train:  0.13042260703695563\n",
      "Epoch: 28\n",
      "Train:  0.1282321145651141\n",
      "Epoch: 29\n",
      "Train:  0.12449113225907779\n",
      "Epoch: 30\n",
      "Train:  0.1245688556605934\n",
      "Epoch: 31\n",
      "Train:  0.12275754259182857\n",
      "Epoch: 32\n",
      "Train:  0.11803293515619923\n",
      "Epoch: 33\n",
      "Train:  0.11573285321103494\n",
      "Epoch: 34\n",
      "Train:  0.11477917698877198\n",
      "Epoch: 35\n",
      "Train:  0.11317939263278384\n",
      "Epoch: 36\n",
      "Train:  0.11361379372877078\n",
      "Epoch: 37\n",
      "Train:  0.11038330601248549\n",
      "Epoch: 38\n",
      "Train:  0.10682019157169138\n",
      "Epoch: 39\n",
      "Train:  0.10393812021147346\n",
      "Epoch: 40\n",
      "Train:  0.10177754998543688\n",
      "Epoch: 41\n",
      "Train:  0.10136776780470824\n",
      "Epoch: 42\n",
      "Train:  0.09809836506916345\n",
      "Epoch: 43\n",
      "Train:  0.09781404350849007\n",
      "Epoch: 44\n",
      "Train:  0.09686503231170632\n",
      "Epoch: 45\n",
      "Train:  0.0937322728581481\n",
      "Epoch: 46\n",
      "Train:  0.0905981906740875\n",
      "Epoch: 47\n",
      "Train:  0.08916254549245185\n",
      "Epoch: 48\n",
      "Train:  0.0858017528504679\n",
      "Epoch: 49\n",
      "Train:  0.08886925919807001\n",
      "Epoch: 50\n",
      "Train:  0.08195872835915022\n",
      "Epoch: 51\n",
      "Train:  0.08042042987177805\n",
      "Epoch: 52\n",
      "Train:  0.08151531690545152\n",
      "Epoch: 53\n",
      "Train:  0.07744362631014415\n",
      "Epoch: 54\n",
      "Train:  0.07635505163816961\n",
      "Epoch: 55\n",
      "Train:  0.07767246239642375\n",
      "Epoch: 56\n",
      "Train:  0.07158642563336644\n",
      "Epoch: 57\n",
      "Train:  0.07269490015566786\n",
      "Epoch: 58\n",
      "Train:  0.07108018424484756\n",
      "Epoch: 59\n",
      "Train:  0.07021431842311689\n",
      "Epoch: 60\n",
      "Train:  0.0676902142542122\n",
      "Epoch: 61\n",
      "Train:  0.06415426869784574\n",
      "Epoch: 62\n",
      "Train:  0.062321190241273944\n",
      "Epoch: 63\n",
      "Train:  0.06405175579154593\n",
      "Epoch: 64\n",
      "Train:  0.05923963761154985\n",
      "Epoch: 65\n",
      "Train:  0.057699047330362095\n",
      "Epoch: 66\n",
      "Train:  0.06105538695977866\n",
      "Epoch: 67\n",
      "Train:  0.05774531905540471\n",
      "Epoch: 68\n",
      "Train:  0.05449682637544233\n",
      "Epoch: 69\n",
      "Train:  0.052563859584203426\n"
     ]
    }
   ],
   "source": [
    "model = Net(768,[384,256,512,64,192],1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1.713644852336342e-05,betas=(0.9308401877808863,0.99))\n",
    "lossff = torch.nn.BCELoss()\n",
    "\n",
    "total_loss = 0\n",
    "weighted_loss = 0\n",
    "exp_param = 0.8\n",
    "\n",
    "wloss = []\n",
    "\n",
    "for i in range(70):\n",
    "  print(\"Epoch:\", i)\n",
    "  model.train()\n",
    "  total_loss = 0\n",
    "  for data in final:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = lossff(torch.reshape(out,(-1,)), data.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "  print(\"Train: \",total_loss / len(final.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "fbdMBcCnT7vl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
